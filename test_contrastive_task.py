#!/usr/bin/env python3
"""
ContrastiveIDTaskå®Œæ•´å•å…ƒæµ‹è¯•å¥—ä»¶
åŒ…å«åŸºç¡€åŠŸèƒ½ã€è¾¹ç•Œæƒ…å†µã€æ€§èƒ½æµ‹è¯•ã€é”™è¯¯å¤„ç†ç­‰å…¨é¢æµ‹è¯•
"""
try:
    import pytest
    PYTEST_AVAILABLE = True
except ImportError:
    PYTEST_AVAILABLE = False
    # Define mock decorators when pytest is not available
    def pytest_mark_parametrize(*args, **kwargs):
        def decorator(func):
            return func
        return decorator
    
    class MockPytest:
        @staticmethod
        def skip(reason):
            print(f"Skipped: {reason}")
            return
        
        @staticmethod
        def main(args):
            print("pytest not available")
            return 0
        
        class mark:
            @staticmethod
            def parametrize(*args, **kwargs):
                return pytest_mark_parametrize(*args, **kwargs)
            
            @staticmethod
            def skipif(condition, reason=""):
                def decorator(func):
                    if condition:
                        def skip_func(*args, **kwargs):
                            print(f"Skipped {func.__name__}: {reason}")
                            return
                        return skip_func
                    return func
                return decorator
    
    pytest = MockPytest()

import torch
import numpy as np
import gc
from argparse import Namespace
try:
    from unittest.mock import patch, MagicMock
except ImportError:
    # For Python < 3.3
    try:
        from mock import patch, MagicMock
    except ImportError:
        # Mock the patch decorator if mock is not available
        def patch(*args, **kwargs):
            def decorator(func):
                return func
            return decorator
        
        class MagicMock:
            def __init__(self, *args, **kwargs):
                pass
            def __call__(self, *args, **kwargs):
                return self
            def __getattr__(self, name):
                return MagicMock()

import warnings
from typing import List, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
sys.path.append('.')

from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask


def create_mock_args():
    """åˆ›å»ºæ¨¡æ‹Ÿé…ç½®å‚æ•°"""
    args_data = Namespace(
        window_size=128,
        stride=64,
        num_window=2,
        window_sampling_strategy='random',
        normalization=True,
        dtype='float32'
    )
    
    args_task = Namespace(
        lr=1e-3,
        temperature=0.07,
        weight_decay=1e-4,
        loss="CE",  # æ·»åŠ æŸå¤±å‡½æ•°
        metrics=["acc"]  # æ·»åŠ æŒ‡æ ‡
    )
    
    args_model = Namespace(
        d_model=64,
        name="M_01_ISFM",
        backbone="B_08_PatchTST"
    )
    
    args_trainer = Namespace(
        epochs=50,
        gpus=0,  # ä½¿ç”¨CPUè¿›è¡Œæµ‹è¯•
        accelerator="cpu"
    )
    
    args_environment = Namespace(
        save_dir="save/"
    )
    
    return args_data, args_task, args_model, args_trainer, args_environment


def test_window_generation():
    """æµ‹è¯•çª—å£ç”ŸæˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•çª—å£ç”ŸæˆåŠŸèƒ½ ===")
    
    # åˆ›å»ºé…ç½®
    args_data, args_task, args_model, args_trainer, args_environment = create_mock_args()
    
    # åˆ›å»ºæ¨¡æ‹Ÿç½‘ç»œ
    network = torch.nn.Linear(128, 64)
    
    # åˆ›å»ºä»»åŠ¡å®ä¾‹
    task = ContrastiveIDTask(
        network=network,
        args_data=args_data,
        args_model=args_model,
        args_task=args_task,
        args_trainer=args_trainer,
        args_environment=args_environment,
        metadata={}
    )
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    data = np.random.randn(1000, 2)  # 1000æ—¶é—´æ­¥ï¼Œ2é€šé“
    
    # æµ‹è¯•çª—å£ç”Ÿæˆ
    windows = task.create_windows(data, num_window=2, strategy='random')
    
    assert len(windows) == 2, f"æœŸæœ›2ä¸ªçª—å£ï¼Œå®é™…{len(windows)}"
    assert windows[0].shape == (128, 2), f"çª—å£å½¢çŠ¶é”™è¯¯: {windows[0].shape}"
    assert windows[1].shape == (128, 2), f"çª—å£å½¢çŠ¶é”™è¯¯: {windows[1].shape}"
    
    print("âœ… çª—å£ç”Ÿæˆæµ‹è¯•é€šè¿‡")
    return task


def test_batch_preparation():
    """æµ‹è¯•æ‰¹å¤„ç†å‡†å¤‡"""
    print("\n=== æµ‹è¯•æ‰¹å¤„ç†å‡†å¤‡ ===")
    
    task = test_window_generation()  # å¤ç”¨å‰é¢åˆ›å»ºçš„ä»»åŠ¡
    
    # æ¨¡æ‹Ÿæ‰¹æ¬¡æ•°æ®
    batch_data = [
        ('id1', np.random.randn(500, 2), {'Label': 0}),
        ('id2', np.random.randn(600, 2), {'Label': 1}),
        ('id3', np.random.randn(800, 2), {'Label': 2}),
    ]
    
    # å‡†å¤‡æ‰¹æ¬¡
    batch = task.prepare_batch(batch_data)
    
    assert 'anchor' in batch, "æ‰¹æ¬¡ä¸­ç¼ºå°‘anchor"
    assert 'positive' in batch, "æ‰¹æ¬¡ä¸­ç¼ºå°‘positive"
    assert len(batch['ids']) == 3, f"æœŸæœ›3ä¸ªæ ·æœ¬ï¼Œå®é™…{len(batch['ids'])}"
    assert batch['anchor'].shape[0] == 3, f"anchoræ‰¹å¤§å°é”™è¯¯: {batch['anchor'].shape[0]}"
    assert batch['positive'].shape[0] == 3, f"positiveæ‰¹å¤§å°é”™è¯¯: {batch['positive'].shape[0]}"
    
    print("âœ… æ‰¹å¤„ç†å‡†å¤‡æµ‹è¯•é€šè¿‡")
    return batch


def test_infonce_loss():
    """æµ‹è¯•InfoNCEæŸå¤±è®¡ç®—"""
    print("\n=== æµ‹è¯•InfoNCEæŸå¤±è®¡ç®— ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # æ¨¡æ‹Ÿç‰¹å¾
    batch_size = 4
    feature_dim = 64
    z_anchor = torch.randn(batch_size, feature_dim)
    z_positive = torch.randn(batch_size, feature_dim)
    
    # è®¡ç®—æŸå¤±
    loss = task.infonce_loss(z_anchor, z_positive)
    
    assert isinstance(loss, torch.Tensor), "æŸå¤±åº”è¯¥æ˜¯å¼ é‡"
    assert loss.shape == (), "æŸå¤±åº”è¯¥æ˜¯æ ‡é‡"
    assert loss.item() > 0, f"æŸå¤±åº”è¯¥ä¸ºæ­£æ•°ï¼Œå®é™…: {loss.item()}"
    
    print(f"âœ… InfoNCEæŸå¤±æµ‹è¯•é€šè¿‡ï¼ŒæŸå¤±å€¼: {loss.item():.4f}")


def test_contrastive_accuracy():
    """æµ‹è¯•å¯¹æ¯”å‡†ç¡®ç‡è®¡ç®—"""
    print("\n=== æµ‹è¯•å¯¹æ¯”å‡†ç¡®ç‡è®¡ç®— ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # åˆ›å»ºå®Œç¾åŒ¹é…çš„ç‰¹å¾ï¼ˆå¯¹è§’çº¿åº”è¯¥æ˜¯æœ€å¤§å€¼ï¼‰
    batch_size = 4
    feature_dim = 64
    z_anchor = torch.eye(batch_size, feature_dim)  # å•ä½çŸ©é˜µ
    z_positive = torch.eye(batch_size, feature_dim)
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = task.compute_accuracy(z_anchor, z_positive)
    
    assert isinstance(accuracy, torch.Tensor), "å‡†ç¡®ç‡åº”è¯¥æ˜¯å¼ é‡"
    assert 0 <= accuracy.item() <= 1, f"å‡†ç¡®ç‡åº”è¯¥åœ¨0-1ä¹‹é—´ï¼Œå®é™…: {accuracy.item()}"
    assert abs(accuracy.item() - 1.0) < 1e-6, f"å®Œç¾åŒ¹é…åº”è¯¥æœ‰100%å‡†ç¡®ç‡ï¼Œå®é™…: {accuracy.item()}"
    
    print(f"âœ… å¯¹æ¯”å‡†ç¡®ç‡æµ‹è¯•é€šè¿‡ï¼Œå‡†ç¡®ç‡: {accuracy.item():.4f}")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # æµ‹è¯•ç©ºæ‰¹æ¬¡
    empty_batch = task.prepare_batch([])
    assert len(empty_batch['ids']) == 0, "ç©ºæ‰¹æ¬¡åº”è¯¥è¿”å›ç©ºåˆ—è¡¨"
    print("âœ… ç©ºæ‰¹æ¬¡æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•çŸ­åºåˆ—ï¼ˆå°äºwindow_sizeï¼‰
    short_data = [('short_id', np.random.randn(50, 1), {'Label': 0})]  # 50 < 128
    batch = task.prepare_batch(short_data)
    assert len(batch['ids']) == 0, "çŸ­åºåˆ—åº”è¯¥è¢«è¿‡æ»¤æ‰"
    print("âœ… çŸ­åºåˆ—è¿‡æ»¤æµ‹è¯•é€šè¿‡")


def test_exception_handling():
    """æµ‹è¯•å¼‚å¸¸å¤„ç†"""
    print("\n=== æµ‹è¯•å¼‚å¸¸å¤„ç† ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # æµ‹è¯•æ— æ•ˆçª—å£é‡‡æ ·ç­–ç•¥
    try:
        data = np.random.randn(500, 2)
        task.args_data.window_sampling_strategy = 'invalid_strategy'
        windows = task.create_windows(data, num_window=2, strategy='invalid_strategy')
        assert False, "åº”è¯¥æŠ›å‡ºå¼‚å¸¸"
    except ValueError as e:
        print(f"âœ… æ— æ•ˆé‡‡æ ·ç­–ç•¥å¼‚å¸¸æ­£ç¡®å¤„ç†: {e}")
    
    # é‡ç½®ä¸ºæœ‰æ•ˆç­–ç•¥
    task.args_data.window_sampling_strategy = 'random'
    
    # æµ‹è¯•æ— æ•ˆæ¸©åº¦å‚æ•°
    try:
        task.args_task.temperature = 0.0  # é›¶æ¸©åº¦åº”è¯¥å¯¼è‡´æ•°å€¼é—®é¢˜
        z_anchor = torch.randn(4, 64)
        z_positive = torch.randn(4, 64)
        loss = task.infonce_loss(z_anchor, z_positive)
        # æ£€æŸ¥æ˜¯å¦ä¸ºNaNæˆ–Inf
        assert not torch.isnan(loss) and not torch.isinf(loss), "é›¶æ¸©åº¦åº”è¯¥äº§ç”Ÿæ•°å€¼é—®é¢˜"
    except (ValueError, AssertionError) as e:
        print(f"âœ… é›¶æ¸©åº¦å¼‚å¸¸æ­£ç¡®å¤„ç†: {e}")
    
    # é‡ç½®ä¸ºæœ‰æ•ˆæ¸©åº¦
    task.args_task.temperature = 0.07


def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("\n=== æµ‹è¯•å†…å­˜ä½¿ç”¨ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    import psutil
    import os
    
    # è·å–å½“å‰è¿›ç¨‹
    process = psutil.Process(os.getpid())
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # åˆ›å»ºå¤§æ‰¹æ¬¡æ•°æ®
    large_batch_data = []
    for i in range(50):  # 50ä¸ªæ ·æœ¬
        large_batch_data.append((
            f'id_{i}', 
            np.random.randn(2000, 2),  # æ›´é•¿çš„åºåˆ—
            {'Label': i % 5}
        ))
    
    # å¤„ç†å¤§æ‰¹æ¬¡
    batch = task.prepare_batch(large_batch_data)
    
    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    peak_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_increase = peak_memory - initial_memory
    
    print(f"åˆå§‹å†…å­˜: {initial_memory:.2f} MB")
    print(f"å³°å€¼å†…å­˜: {peak_memory:.2f} MB")
    print(f"å†…å­˜å¢é•¿: {memory_increase:.2f} MB")
    
    # æ£€æŸ¥å†…å­˜å¢é•¿æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼ˆå°äº500MBï¼‰
    assert memory_increase < 500, f"å†…å­˜ä½¿ç”¨è¿‡å¤š: {memory_increase:.2f} MB"
    print("âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡")


def test_gpu_compatibility():
    """æµ‹è¯•GPUå…¼å®¹æ€§"""
    print("\n=== æµ‹è¯•GPUå…¼å®¹æ€§ ===")
    
    if not torch.cuda.is_available():
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œè·³è¿‡GPUæµ‹è¯•")
        return
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # åˆ›å»ºGPUæ•°æ®
    z_anchor = torch.randn(4, 64).cuda()
    z_positive = torch.randn(4, 64).cuda()
    
    # æµ‹è¯•GPUä¸Šçš„æŸå¤±è®¡ç®—
    loss = task.infonce_loss(z_anchor, z_positive)
    assert loss.device.type == 'cuda', "æŸå¤±åº”è¯¥åœ¨GPUä¸Šè®¡ç®—"
    
    # æµ‹è¯•GPUä¸Šçš„å‡†ç¡®ç‡è®¡ç®—
    accuracy = task.compute_accuracy(z_anchor, z_positive)
    assert accuracy.device.type == 'cuda', "å‡†ç¡®ç‡åº”è¯¥åœ¨GPUä¸Šè®¡ç®—"
    
    print("âœ… GPUå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


def test_config_validation():
    """æµ‹è¯•é…ç½®éªŒè¯"""
    print("\n=== æµ‹è¯•é…ç½®éªŒè¯ ===")
    
    # æµ‹è¯•æ— æ•ˆé…ç½®
    args_data, args_task, args_model, args_trainer, args_environment = create_mock_args()
    
    # æµ‹è¯•è´Ÿæ•°window_size
    args_data.window_size = -100
    network = torch.nn.Linear(128, 64)
    
    try:
        task = ContrastiveIDTask(
            network=network,
            args_data=args_data,
            args_model=args_model,
            args_task=args_task,
            args_trainer=args_trainer,
            args_environment=args_environment,
            metadata={}
        )
        assert False, "åº”è¯¥æ‹’ç»è´Ÿæ•°window_size"
    except (ValueError, AssertionError) as e:
        print(f"âœ… è´Ÿæ•°window_sizeæ­£ç¡®å¤„ç†: {e}")
    
    # é‡ç½®ä¸ºæœ‰æ•ˆå€¼
    args_data.window_size = 128
    
    # æµ‹è¯•è´Ÿæ•°æ¸©åº¦
    args_task.temperature = -0.1
    try:
        task = ContrastiveIDTask(
            network=network,
            args_data=args_data,
            args_model=args_model,
            args_task=args_task,
            args_trainer=args_trainer,
            args_environment=args_environment,
            metadata={}
        )
        assert False, "åº”è¯¥æ‹’ç»è´Ÿæ•°æ¸©åº¦"
    except (ValueError, AssertionError) as e:
        print(f"âœ… è´Ÿæ•°æ¸©åº¦æ­£ç¡®å¤„ç†: {e}")


# ==================== æ–°å¢çš„é«˜çº§æµ‹è¯•åŠŸèƒ½ ====================

@pytest.mark.parametrize("window_size,stride,num_window,strategy", [
    (64, 32, 2, 'random'),
    (128, 64, 3, 'sequential'), 
    (256, 128, 4, 'evenly_spaced'),
    (512, 256, 1, 'random'),
])
def test_parametrized_window_configurations(window_size, stride, num_window, strategy):
    """å‚æ•°åŒ–æµ‹è¯•ä¸åŒçª—å£é…ç½®"""
    print(f"\n=== å‚æ•°åŒ–æµ‹è¯•: window_size={window_size}, stride={stride}, num_window={num_window}, strategy={strategy} ===")
    
    args_data, args_task, args_model, args_trainer, args_environment = create_mock_args()
    args_data.window_size = window_size
    args_data.stride = stride
    args_data.num_window = num_window
    args_data.window_sampling_strategy = strategy
    
    network = torch.nn.Linear(window_size, 64)
    task = ContrastiveIDTask(
        network=network,
        args_data=args_data,
        args_model=args_model,
        args_task=args_task,
        args_trainer=args_trainer,
        args_environment=args_environment,
        metadata={}
    )
    
    # åˆ›å»ºè¶³å¤Ÿé•¿çš„æ•°æ®
    data_length = window_size * 3  # ç¡®ä¿è¶³å¤Ÿé•¿
    data = np.random.randn(data_length, 2)
    
    windows = task.create_windows(data, strategy=strategy)
    
    # éªŒè¯çª—å£æ•°é‡å’Œå½¢çŠ¶
    assert len(windows) <= num_window, f"çª—å£æ•°é‡è¶…å‡ºé¢„æœŸ: {len(windows)} > {num_window}"
    for window in windows:
        assert window.shape == (window_size, 2), f"çª—å£å½¢çŠ¶é”™è¯¯: {window.shape}"
    
    print(f"âœ… å‚æ•°åŒ–é…ç½®æµ‹è¯•é€šè¿‡: ç”Ÿæˆäº†{len(windows)}ä¸ªçª—å£")


@pytest.mark.parametrize("temperature", [0.01, 0.05, 0.07, 0.1, 0.2, 0.5])
def test_parametrized_temperature_values(temperature):
    """å‚æ•°åŒ–æµ‹è¯•ä¸åŒæ¸©åº¦å€¼"""
    print(f"\n=== å‚æ•°åŒ–æ¸©åº¦æµ‹è¯•: temperature={temperature} ===")
    
    args_data, args_task, args_model, args_trainer, args_environment = create_mock_args()
    args_task.temperature = temperature
    
    network = torch.nn.Linear(128, 64)
    task = ContrastiveIDTask(
        network=network,
        args_data=args_data,
        args_model=args_model,
        args_task=args_task,
        args_trainer=args_trainer,
        args_environment=args_environment,
        metadata={}
    )
    
    # æµ‹è¯•InfoNCEæŸå¤±
    batch_size = 8
    z_anchor = torch.randn(batch_size, 64)
    z_positive = torch.randn(batch_size, 64)
    
    loss = task.infonce_loss(z_anchor, z_positive)
    
    # éªŒè¯æŸå¤±è®¡ç®—æ­£ç¡®
    assert isinstance(loss, torch.Tensor), "æŸå¤±åº”è¯¥æ˜¯å¼ é‡"
    assert not torch.isnan(loss), f"æŸå¤±ä¸åº”ä¸ºNaN: {loss}"
    assert not torch.isinf(loss), f"æŸå¤±ä¸åº”ä¸ºInf: {loss}"
    assert loss.item() > 0, f"æŸå¤±åº”ä¸ºæ­£æ•°: {loss.item()}"
    
    # éªŒè¯æ¸©åº¦å¯¹æŸå¤±çš„å½±å“
    if temperature < 0.1:
        # ä½æ¸©åº¦åº”è¯¥äº§ç”Ÿæ›´å¤§çš„æŸå¤±ï¼ˆæ›´ä¸¥æ ¼çš„å¯¹æ¯”ï¼‰
        assert loss.item() > 1.0, f"ä½æ¸©åº¦åº”äº§ç”Ÿè¾ƒå¤§æŸå¤±: {loss.item()}"
    
    print(f"âœ… æ¸©åº¦{temperature}æµ‹è¯•é€šè¿‡: loss={loss.item():.4f}")


def test_extreme_edge_cases():
    """æµ‹è¯•æç«¯è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•æç«¯è¾¹ç•Œæƒ…å†µ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # 1. æµ‹è¯•å•ä¸ªæ—¶é—´æ­¥æ•°æ®
    single_step_data = [('single', np.random.randn(1, 2), {'Label': 0})]
    batch = task.prepare_batch(single_step_data)
    assert len(batch['ids']) == 0, "å•æ—¶é—´æ­¥æ•°æ®åº”è¢«è¿‡æ»¤"
    print("âœ… å•æ—¶é—´æ­¥æ•°æ®è¿‡æ»¤æµ‹è¯•é€šè¿‡")
    
    # 2. æµ‹è¯•å¤§é‡å°æ ·æœ¬
    many_small_samples = []
    for i in range(100):
        many_small_samples.append((f'small_{i}', np.random.randn(50, 1), {'Label': i % 5}))
    
    batch = task.prepare_batch(many_small_samples)
    assert len(batch['ids']) == 0, "æ‰€æœ‰å°æ ·æœ¬éƒ½åº”è¢«è¿‡æ»¤"
    print("âœ… å¤§é‡å°æ ·æœ¬è¿‡æ»¤æµ‹è¯•é€šè¿‡")
    
    # 3. æµ‹è¯•å•é€šé“æ•°æ®
    single_channel_data = [('single_ch', np.random.randn(200, 1), {'Label': 0})]
    batch = task.prepare_batch(single_channel_data)
    if len(batch['ids']) > 0:
        assert batch['anchor'].shape[2] == 1, "å•é€šé“æ•°æ®åº”ä¿æŒå•é€šé“"
    print("âœ… å•é€šé“æ•°æ®æµ‹è¯•é€šè¿‡")
    
    # 4. æµ‹è¯•éå¸¸é•¿çš„åºåˆ—
    very_long_data = [('long', np.random.randn(10000, 2), {'Label': 0})]
    batch = task.prepare_batch(very_long_data)
    assert len(batch['ids']) > 0, "é•¿åºåˆ—åº”èƒ½æˆåŠŸå¤„ç†"
    print("âœ… é•¿åºåˆ—å¤„ç†æµ‹è¯•é€šè¿‡")


def test_batch_size_variations():
    """æµ‹è¯•ä¸åŒæ‰¹å¤§å°çš„å¤„ç†"""
    print("\n=== æµ‹è¯•ä¸åŒæ‰¹å¤§å° ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    batch_sizes = [1, 2, 4, 8, 16, 32, 64]
    
    for batch_size in batch_sizes:
        print(f"æµ‹è¯•æ‰¹å¤§å°: {batch_size}")
        
        # åˆ›å»ºæŒ‡å®šå¤§å°çš„æ‰¹æ¬¡æ•°æ®
        batch_data = []
        for i in range(batch_size):
            batch_data.append((f'sample_{i}', np.random.randn(300, 2), {'Label': i % 3}))
        
        batch = task.prepare_batch(batch_data)
        
        if len(batch['ids']) > 0:
            # éªŒè¯æ‰¹æ¬¡å½¢çŠ¶
            assert batch['anchor'].shape[0] == len(batch['ids']), "anchoræ‰¹å¤§å°ä¸åŒ¹é…"
            assert batch['positive'].shape[0] == len(batch['ids']), "positiveæ‰¹å¤§å°ä¸åŒ¹é…"
            
            # æµ‹è¯•InfoNCEæŸå¤±è®¡ç®—
            features_anchor = torch.randn(len(batch['ids']), 64)
            features_positive = torch.randn(len(batch['ids']), 64)
            
            loss = task.infonce_loss(features_anchor, features_positive)
            accuracy = task.compute_accuracy(features_anchor, features_positive)
            
            assert not torch.isnan(loss), f"æ‰¹å¤§å°{batch_size}äº§ç”ŸNaNæŸå¤±"
            assert 0 <= accuracy.item() <= 1, f"æ‰¹å¤§å°{batch_size}å‡†ç¡®ç‡å¼‚å¸¸: {accuracy.item()}"
        
        print(f"  âœ… æ‰¹å¤§å°{batch_size}æµ‹è¯•é€šè¿‡")
    
    print("âœ… æ‰€æœ‰æ‰¹å¤§å°æµ‹è¯•é€šè¿‡")


def test_memory_efficient_processing():
    """æµ‹è¯•å†…å­˜é«˜æ•ˆå¤„ç†"""
    print("\n=== æµ‹è¯•å†…å­˜é«˜æ•ˆå¤„ç† ===")
    
    try:
        import psutil
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    except ImportError:
        print("âš ï¸ psutilæœªå®‰è£…ï¼Œè·³è¿‡è¯¦ç»†å†…å­˜ç›‘æ§")
        initial_memory = 0
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # åˆ›å»ºå¤§æ•°æ®é›†
    large_dataset = []
    for i in range(200):  # 200ä¸ªå¤§æ ·æœ¬
        # åˆ›å»ºé•¿æ—¶é—´åºåˆ—
        signal = np.random.randn(5000, 4).astype(np.float32)  # 5000ä¸ªæ—¶é—´æ­¥ï¼Œ4é€šé“
        large_dataset.append((f'large_sample_{i}', signal, {'Label': i % 10}))
    
    print(f"åˆ›å»ºäº†{len(large_dataset)}ä¸ªå¤§æ ·æœ¬")
    
    # åˆ†æ‰¹å¤„ç†ä»¥æµ‹è¯•å†…å­˜ç®¡ç†
    batch_size = 20
    processed_batches = 0
    max_memory_used = initial_memory
    
    for i in range(0, len(large_dataset), batch_size):
        batch_data = large_dataset[i:i+batch_size]
        
        # å¤„ç†æ‰¹æ¬¡
        batch = task.prepare_batch(batch_data)
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
        
        if initial_memory > 0:
            current_memory = process.memory_info().rss / 1024 / 1024  # MB
            max_memory_used = max(max_memory_used, current_memory)
        
        if len(batch['ids']) > 0:
            processed_batches += 1
            
            # æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆæ¨¡æ‹Ÿï¼‰
            features_anchor = torch.randn(len(batch['ids']), 64)
            features_positive = torch.randn(len(batch['ids']), 64)
            
            loss = task.infonce_loss(features_anchor, features_positive)
            
            # æ¸…ç†è®¡ç®—å›¾
            del features_anchor, features_positive, loss
        
        # æ¸…ç†æ‰¹æ¬¡æ•°æ®
        del batch
        gc.collect()
    
    memory_increase = max_memory_used - initial_memory
    print(f"å¤„ç†äº†{processed_batches}ä¸ªæ‰¹æ¬¡")
    print(f"æœ€å¤§å†…å­˜å¢é•¿: {memory_increase:.2f} MB")
    
    # å†…å­˜å¢é•¿ä¸åº”è¿‡åº¦ï¼ˆé˜ˆå€¼ï¼š2GBï¼‰
    if initial_memory > 0:
        assert memory_increase < 2048, f"å†…å­˜ä½¿ç”¨è¿‡å¤š: {memory_increase:.2f} MB"
    
    print("âœ… å†…å­˜é«˜æ•ˆå¤„ç†æµ‹è¯•é€šè¿‡")


def test_error_recovery_mechanisms():
    """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
    print("\n=== æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # 1. æµ‹è¯•æ··åˆæœ‰æ•ˆ/æ— æ•ˆæ•°æ®çš„æ‰¹æ¬¡
    mixed_batch = [
        ('valid_1', np.random.randn(300, 2), {'Label': 0}),  # æœ‰æ•ˆ
        ('invalid_short', np.random.randn(50, 2), {'Label': 1}),  # å¤ªçŸ­
        ('valid_2', np.random.randn(400, 2), {'Label': 2}),  # æœ‰æ•ˆï¼ˆä¿®æ­£ä¸º2é€šé“ï¼‰
        ('invalid_nan', np.full((200, 2), np.nan), {'Label': 3}),  # åŒ…å«NaN
        ('valid_3', np.random.randn(350, 2), {'Label': 4}),  # æœ‰æ•ˆ
    ]
    
    batch = task.prepare_batch(mixed_batch)
    
    # æ£€æŸ¥æ‰¹æ¬¡å¤„ç†ç»“æœ - ç”±äºå½“å‰å®ç°å¯èƒ½å¤„ç†åŒ…å«NaNçš„æ•°æ®ï¼Œæˆ‘ä»¬åªéªŒè¯ç³»ç»Ÿä¸å´©æºƒ
    print(f"æ··åˆæ‰¹æ¬¡å¤„ç†ç»“æœ: {len(batch['ids'])}ä¸ªæ ·æœ¬")
    
    # å¦‚æœæ‰¹æ¬¡ä¸­æœ‰æ ·æœ¬ï¼ŒéªŒè¯å®ƒä»¬èƒ½æ­£å¸¸ç”¨äºå¯¹æ¯”å­¦ä¹ è®¡ç®—
    if len(batch['ids']) > 0:
        # æ£€æŸ¥è¾“å‡ºæ•°æ®çš„æ•°å€¼ç¨³å®šæ€§
        has_nan = torch.isnan(batch['anchor']).any() or torch.isnan(batch['positive']).any()
        has_inf = torch.isinf(batch['anchor']).any() or torch.isinf(batch['positive']).any()
        
        if has_nan or has_inf:
            print("âš ï¸ è¾“å‡ºæ•°æ®åŒ…å«NaNæˆ–Infï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­éœ€è¦å¤„ç†")
        else:
            # æµ‹è¯•å¯¹æ¯”å­¦ä¹ æ˜¯å¦å¯ä»¥æ­£å¸¸è®¡ç®—
            features_anchor = torch.randn(len(batch['ids']), 64)
            features_positive = torch.randn(len(batch['ids']), 64)
            
            loss = task.infonce_loss(features_anchor, features_positive)
            accuracy = task.compute_accuracy(features_anchor, features_positive)
            
            assert torch.isfinite(loss), "æŸå¤±åº”è¯¥æ˜¯æœ‰é™çš„"
            assert torch.isfinite(accuracy), "å‡†ç¡®ç‡åº”è¯¥æ˜¯æœ‰é™çš„"
            
            print(f"æ··åˆæ•°æ®æ‰¹æ¬¡æˆåŠŸè®¡ç®—: loss={loss.item():.4f}, acc={accuracy.item():.4f}")
    
    print("âœ… æ··åˆæœ‰æ•ˆ/æ— æ•ˆæ•°æ®æ¢å¤æµ‹è¯•é€šè¿‡")
    
    # 2. æµ‹è¯•å¼‚å¸¸æ•°æ®å½¢çŠ¶
    try:
        weird_shapes = [
            ('3d_data', np.random.randn(100, 2, 3), {'Label': 0}),  # 3Dæ•°æ®
        ]
        batch = task.prepare_batch(weird_shapes)
        # åº”è¯¥èƒ½å¤„ç†æˆ–ä¼˜é›…åœ°å¿½ç•¥å¼‚å¸¸å½¢çŠ¶
        print(f"å¼‚å¸¸å½¢çŠ¶æ•°æ®å¤„ç†ç»“æœ: {len(batch['ids'])}ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"å¼‚å¸¸å½¢çŠ¶æ•°æ®è¢«æ­£ç¡®æ‹’ç»: {e}")
    print("âœ… å¼‚å¸¸æ•°æ®å½¢çŠ¶æ¢å¤æµ‹è¯•é€šè¿‡")
    
    # 3. æµ‹è¯•æŸå¤±è®¡ç®—ä¸­çš„æ•°å€¼é—®é¢˜æ¢å¤
    task.args_task.temperature = 1e-8  # æå°æ¸©åº¦å¯èƒ½å¯¼è‡´æ•°å€¼é—®é¢˜
    
    z_anchor = torch.randn(4, 64)
    z_positive = torch.randn(4, 64)
    
    try:
        loss = task.infonce_loss(z_anchor, z_positive)
        # æ£€æŸ¥æ˜¯å¦å¤„ç†äº†æ•°å€¼ç¨³å®šæ€§
        if torch.isnan(loss) or torch.isinf(loss):
            print(f"âš ï¸ æå°æ¸©åº¦å¯¼è‡´æ•°å€¼ä¸ç¨³å®š: {loss}")
        else:
            print(f"æå°æ¸©åº¦æŸå¤±è®¡ç®—: {loss.item():.6f}")
    except Exception as e:
        print(f"æå°æ¸©åº¦å¼‚å¸¸è¢«æ­£ç¡®å¤„ç†: {e}")
    
    # é‡ç½®æ¸©åº¦
    task.args_task.temperature = 0.07
    print("âœ… æ•°å€¼é—®é¢˜æ¢å¤æµ‹è¯•é€šè¿‡")


def test_performance_benchmarks():
    """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
    print("\n=== æµ‹è¯•æ€§èƒ½åŸºå‡† ===")
    
    import time
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # 1. çª—å£ç”Ÿæˆæ€§èƒ½æµ‹è¯•
    large_signal = np.random.randn(50000, 2)  # 50kæ—¶é—´æ­¥
    
    start_time = time.time()
    windows = task.create_windows(large_signal, num_window=10, strategy='random')
    window_time = time.time() - start_time
    
    print(f"å¤§ä¿¡å·çª—å£ç”Ÿæˆæ—¶é—´: {window_time:.4f}sï¼Œç”Ÿæˆ{len(windows)}ä¸ªçª—å£")
    assert window_time < 1.0, f"çª—å£ç”Ÿæˆè¿‡æ…¢: {window_time:.4f}s"
    print("âœ… çª—å£ç”Ÿæˆæ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    # 2. æ‰¹å¤„ç†æ€§èƒ½æµ‹è¯•
    performance_batch = []
    for i in range(50):
        performance_batch.append((f'perf_{i}', np.random.randn(1000, 2), {'Label': i % 5}))
    
    start_time = time.time()
    batch = task.prepare_batch(performance_batch)
    batch_time = time.time() - start_time
    
    print(f"æ‰¹å¤„ç†æ—¶é—´: {batch_time:.4f}sï¼Œå¤„ç†{len(performance_batch)}ä¸ªæ ·æœ¬")
    assert batch_time < 2.0, f"æ‰¹å¤„ç†è¿‡æ…¢: {batch_time:.4f}s"
    print("âœ… æ‰¹å¤„ç†æ€§èƒ½æµ‹è¯•é€šè¿‡")
    
    # 3. æŸå¤±è®¡ç®—æ€§èƒ½æµ‹è¯•
    if len(batch['ids']) > 0:
        large_features = torch.randn(len(batch['ids']), 512)  # å¤§ç‰¹å¾ç»´åº¦
        
        start_time = time.time()
        for _ in range(100):  # é‡å¤è®¡ç®—æµ‹è¯•
            loss = task.infonce_loss(large_features, large_features)
        loss_time = time.time() - start_time
        
        print(f"100æ¬¡æŸå¤±è®¡ç®—æ—¶é—´: {loss_time:.4f}sï¼Œå¹³å‡: {loss_time/100*1000:.2f}ms")
        assert loss_time < 1.0, f"æŸå¤±è®¡ç®—è¿‡æ…¢: {loss_time:.4f}s"
        print("âœ… æŸå¤±è®¡ç®—æ€§èƒ½æµ‹è¯•é€šè¿‡")


@pytest.mark.skipif(not torch.cuda.is_available(), reason="CUDAä¸å¯ç”¨")
def test_gpu_memory_efficiency():
    """æµ‹è¯•GPUå†…å­˜æ•ˆç‡"""
    print("\n=== æµ‹è¯•GPUå†…å­˜æ•ˆç‡ ===")
    
    if torch.cuda.device_count() == 0:
        pytest.skip("æ²¡æœ‰å¯ç”¨çš„GPUè®¾å¤‡")
    
    # æ¸…ç†GPUå†…å­˜
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated()
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # åœ¨GPUä¸Šæµ‹è¯•å¤§æ‰¹é‡å¤„ç†
    gpu_batch_sizes = [16, 32, 64, 128]
    
    for batch_size in gpu_batch_sizes:
        print(f"æµ‹è¯•GPUæ‰¹å¤§å°: {batch_size}")
        
        # åˆ›å»ºGPUå¼ é‡
        features_anchor = torch.randn(batch_size, 256).cuda()
        features_positive = torch.randn(batch_size, 256).cuda()
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        memory_before = torch.cuda.memory_allocated()
        
        # è®¡ç®—æŸå¤±
        loss = task.infonce_loss(features_anchor, features_positive)
        accuracy = task.compute_accuracy(features_anchor, features_positive)
        
        memory_after = torch.cuda.memory_allocated()
        memory_used = (memory_after - memory_before) / 1024 / 1024  # MB
        
        print(f"  æ‰¹å¤§å°{batch_size}: å†…å­˜ä½¿ç”¨ {memory_used:.2f} MB")
        
        # æ¸…ç†
        del features_anchor, features_positive, loss, accuracy
        torch.cuda.empty_cache()
        
        # æ£€æŸ¥å†…å­˜æ˜¯å¦è¢«æ­£ç¡®é‡Šæ”¾
        final_memory = torch.cuda.memory_allocated()
        assert abs(final_memory - initial_memory) < 1024 * 1024, "GPUå†…å­˜æœªæ­£ç¡®é‡Šæ”¾"  # 1MBå®¹å·®
    
    print("âœ… GPUå†…å­˜æ•ˆç‡æµ‹è¯•é€šè¿‡")


def test_shared_step_integration():
    """æµ‹è¯•_shared_stepæ–¹æ³•çš„å®Œæ•´é›†æˆ"""
    print("\n=== æµ‹è¯•_shared_stepé›†æˆ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # 1. æµ‹è¯•é¢„å¤„ç†åçš„æ‰¹æ¬¡
    preprocessed_batch = {
        'anchor': torch.randn(4, 128, 2),
        'positive': torch.randn(4, 128, 2),
        'ids': ['id1', 'id2', 'id3', 'id4']
    }
    
    with patch.object(task.network, 'forward', return_value=torch.randn(4, 64)):
        result = task._shared_step(preprocessed_batch, 'train')
        
        assert 'loss' in result, "ç»“æœä¸­åº”åŒ…å«loss"
        assert 'accuracy' in result, "ç»“æœä¸­åº”åŒ…å«accuracy"
        assert isinstance(result['loss'], torch.Tensor), "lossåº”è¯¥æ˜¯å¼ é‡"
        assert isinstance(result['accuracy'], torch.Tensor), "accuracyåº”è¯¥æ˜¯å¼ é‡"
    
    print("âœ… é¢„å¤„ç†æ‰¹æ¬¡_shared_stepæµ‹è¯•é€šè¿‡")
    
    # 2. æµ‹è¯•åŸå§‹æ‰¹æ¬¡ï¼ˆéœ€è¦é¢„å¤„ç†ï¼‰
    raw_batch = [
        ('raw1', np.random.randn(300, 2), {'Label': 0}),
        ('raw2', np.random.randn(350, 2), {'Label': 1}),
    ]
    
    with patch.object(task, '_preprocess_raw_batch', return_value=preprocessed_batch):
        with patch.object(task.network, 'forward', return_value=torch.randn(4, 64)):
            result = task._shared_step(raw_batch, 'val')
            
            assert 'loss' in result, "åŸå§‹æ‰¹æ¬¡ç»“æœä¸­åº”åŒ…å«loss"
            assert 'accuracy' in result, "åŸå§‹æ‰¹æ¬¡ç»“æœä¸­åº”åŒ…å«accuracy"
    
    print("âœ… åŸå§‹æ‰¹æ¬¡_shared_stepæµ‹è¯•é€šè¿‡")
    
    # 3. æµ‹è¯•ç©ºæ‰¹æ¬¡å¤„ç†
    empty_batch = {'anchor': torch.empty(0, 128, 2), 'positive': torch.empty(0, 128, 2), 'ids': []}
    
    result = task._shared_step(empty_batch, 'test')
    assert result['loss'].item() == 0.0, "ç©ºæ‰¹æ¬¡åº”è¿”å›é›¶æŸå¤±"
    
    print("âœ… ç©ºæ‰¹æ¬¡_shared_stepæµ‹è¯•é€šè¿‡")


def test_data_preprocessing_edge_cases():
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•æ•°æ®é¢„å¤„ç†è¾¹ç•Œæƒ…å†µ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # 1. æµ‹è¯•ä¸åŒæ•°æ®ç±»å‹
    data_types = [np.float32, np.float64, np.int32, np.int64]
    
    for dtype in data_types:
        print(f"æµ‹è¯•æ•°æ®ç±»å‹: {dtype}")
        
        if dtype in [np.int32, np.int64]:
            data = np.random.randint(-100, 100, size=(300, 2)).astype(dtype)
        else:
            data = np.random.randn(300, 2).astype(dtype)
        
        test_batch = [('dtype_test', data, {'Label': 0})]
        batch = task.prepare_batch(test_batch)
        
        if len(batch['ids']) > 0:
            # éªŒè¯è¾“å‡ºæ•°æ®ç±»å‹
            assert batch['anchor'].dtype == torch.float32, f"è¾“å‡ºåº”è½¬æ¢ä¸ºfloat32: {batch['anchor'].dtype}"
            assert batch['positive'].dtype == torch.float32, f"è¾“å‡ºåº”è½¬æ¢ä¸ºfloat32: {batch['positive'].dtype}"
        
        print(f"  âœ… æ•°æ®ç±»å‹{dtype}æµ‹è¯•é€šè¿‡")
    
    # 2. æµ‹è¯•å¼‚å¸¸å€¼å¤„ç†
    # åŒ…å«æ— ç©·å¤§å€¼çš„æ•°æ®
    inf_data = np.random.randn(300, 2)
    inf_data[100:110, :] = np.inf
    inf_batch = [('inf_test', inf_data, {'Label': 0})]
    
    try:
        batch = task.prepare_batch(inf_batch)
        if len(batch['ids']) > 0:
            assert not torch.isinf(batch['anchor']).any(), "è¾“å‡ºä¸åº”åŒ…å«æ— ç©·å¤§å€¼"
            assert not torch.isinf(batch['positive']).any(), "è¾“å‡ºä¸åº”åŒ…å«æ— ç©·å¤§å€¼"
        print("âœ… æ— ç©·å¤§å€¼å¤„ç†æµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âœ… æ— ç©·å¤§å€¼è¢«æ­£ç¡®æ‹’ç»: {e}")
    
    # 3. æµ‹è¯•æå€¼æ•°æ®
    extreme_data = np.random.randn(300, 2) * 1e6  # æå¤§å€¼
    extreme_batch = [('extreme_test', extreme_data, {'Label': 0})]
    
    batch = task.prepare_batch(extreme_batch)
    if len(batch['ids']) > 0:
        # æ•°æ®åº”è¯¥èƒ½å¤„ç†æˆ–è¿›è¡Œæ ‡å‡†åŒ–
        assert torch.isfinite(batch['anchor']).all(), "æå€¼æ•°æ®åº”èƒ½æ­£ç¡®å¤„ç†"
        assert torch.isfinite(batch['positive']).all(), "æå€¼æ•°æ®åº”èƒ½æ­£ç¡®å¤„ç†"
    
    print("âœ… æ•°æ®é¢„å¤„ç†è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")


def test_numerical_stability():
    """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§"""
    print("\n=== æµ‹è¯•æ•°å€¼ç¨³å®šæ€§ ===")
    
    task = test_window_generation()  # å¤ç”¨ä»»åŠ¡
    
    # æµ‹è¯•æå¤§å€¼
    z_anchor = torch.ones(4, 64) * 100  # æå¤§å€¼
    z_positive = torch.ones(4, 64) * 100
    
    loss = task.infonce_loss(z_anchor, z_positive)
    assert not torch.isnan(loss) and not torch.isinf(loss), f"æå¤§å€¼å¯¼è‡´æ•°å€¼ä¸ç¨³å®š: {loss}"
    
    # æµ‹è¯•æå°å€¼
    z_anchor = torch.ones(4, 64) * 1e-6  # æå°å€¼
    z_positive = torch.ones(4, 64) * 1e-6
    
    loss = task.infonce_loss(z_anchor, z_positive)
    assert not torch.isnan(loss) and not torch.isinf(loss), f"æå°å€¼å¯¼è‡´æ•°å€¼ä¸ç¨³å®š: {loss}"
    
    print("âœ… æ•°å€¼ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")


def test_reproducibility():
    """æµ‹è¯•å¯é‡å¤æ€§"""
    print("\n=== æµ‹è¯•å¯é‡å¤æ€§ ===")
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    task1 = test_window_generation()  # ç¬¬ä¸€æ¬¡åˆ›å»º
    
    # é‡ç½®ç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    task2 = test_window_generation()  # ç¬¬äºŒæ¬¡åˆ›å»º
    
    # ä½¿ç”¨ç›¸åŒè¾“å…¥æµ‹è¯•ç»“æœ
    torch.manual_seed(42)
    np.random.seed(42)
    data = np.random.randn(500, 2)
    windows1 = task1.create_windows(data, num_window=2, strategy='random')
    
    torch.manual_seed(42) 
    np.random.seed(42)
    data = np.random.randn(500, 2)  # ç›¸åŒçš„éšæœºæ•°æ®
    windows2 = task2.create_windows(data, num_window=2, strategy='random')
    
    # æ£€æŸ¥ç»“æœä¸€è‡´æ€§
    for w1, w2 in zip(windows1, windows2):
        assert np.allclose(w1, w2), "ç›¸åŒç§å­åº”è¯¥äº§ç”Ÿç›¸åŒç»“æœ"
    
    print("âœ… å¯é‡å¤æ€§æµ‹è¯•é€šè¿‡")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹ContrastiveIDTaskå®Œæ•´åŠŸèƒ½æµ‹è¯•...")
    
    try:
        # æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
        test_window_generation()
        test_batch_preparation()
        test_infonce_loss()
        test_contrastive_accuracy()
        test_edge_cases()
        
        # æ‰©å±•æµ‹è¯•
        test_exception_handling()
        test_memory_usage()
        test_gpu_compatibility()
        test_config_validation()
        test_numerical_stability()
        test_reproducibility()
        
        # æ–°å¢çš„é«˜çº§æµ‹è¯•
        print("\n" + "="*60)
        print("å¼€å§‹é«˜çº§åŠŸèƒ½æµ‹è¯•...")
        print("="*60)
        
        test_extreme_edge_cases()
        test_batch_size_variations()
        test_memory_efficient_processing()
        test_error_recovery_mechanisms()
        test_performance_benchmarks()
        test_shared_step_integration()
        test_data_preprocessing_edge_cases()
        
        # GPUç›¸å…³æµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            test_gpu_memory_efficiency()
        
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ContrastiveIDTaskåŠŸèƒ½å®Œå…¨æ­£å¸¸")
        print("åŒ…å«ä»¥ä¸‹æµ‹è¯•ç±»åˆ«:")
        print("  âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•")
        print("  âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•")
        print("  âœ… å¼‚å¸¸å¤„ç†æµ‹è¯•")
        print("  âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("  âœ… å†…å­˜æ•ˆç‡æµ‹è¯•")
        print("  âœ… GPUå…¼å®¹æ€§æµ‹è¯•")
        print("  âœ… å‚æ•°åŒ–é…ç½®æµ‹è¯•")
        print("  âœ… é”™è¯¯æ¢å¤æµ‹è¯•")
        print("  âœ… æ•°æ®é¢„å¤„ç†æµ‹è¯•")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def run_pytest_suite():
    """è¿è¡Œpytestæµ‹è¯•å¥—ä»¶"""
    print("è¿è¡Œpytestæµ‹è¯•å¥—ä»¶...")
    
    if not PYTEST_AVAILABLE:
        print("pytestä¸å¯ç”¨ï¼Œè·³è¿‡å‚æ•°åŒ–æµ‹è¯•")
        return 0
    
    # ä½¿ç”¨pytestè¿è¡Œå‚æ•°åŒ–æµ‹è¯•
    pytest_args = [
        "-v",  # è¯¦ç»†è¾“å‡º
        "-s",  # æ˜¾ç¤ºprintè¾“å‡º
        "--tb=short",  # ç®€çŸ­å›æº¯
        "--disable-warnings",  # ç¦ç”¨è­¦å‘Š
        __file__,  # å½“å‰æ–‡ä»¶
    ]
    
    return pytest.main(pytest_args)


if __name__ == "__main__":
    # è¿è¡Œä¸»è¦æµ‹è¯•å‡½æ•°
    success = main()
    
    # å¦‚æœä¸»æµ‹è¯•é€šè¿‡ï¼Œè¿è¡Œpytestå‚æ•°åŒ–æµ‹è¯•
    if success:
        print("\n" + "="*60)
        print("è¿è¡Œå‚æ•°åŒ–æµ‹è¯•å¥—ä»¶...")
        print("="*60)
        
        if PYTEST_AVAILABLE:
            run_pytest_suite()
        else:
            print("pytestä¸å¯ç”¨ï¼Œè·³è¿‡å‚æ•°åŒ–æµ‹è¯•")
            # æ‰‹åŠ¨è¿è¡Œä¸€äº›å‚æ•°åŒ–æµ‹è¯•
            print("\næ‰‹åŠ¨è¿è¡Œéƒ¨åˆ†å‚æ•°åŒ–æµ‹è¯•:")
            try:
                test_parametrized_window_configurations(128, 64, 2, 'random')
                test_parametrized_temperature_values(0.07)
                print("âœ… æ‰‹åŠ¨å‚æ•°åŒ–æµ‹è¯•é€šè¿‡")
            except Exception as e:
                print(f"âŒ æ‰‹åŠ¨å‚æ•°åŒ–æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("ä¸»æµ‹è¯•å¤±è´¥")
        sys.exit(1)