# ğŸš€ Flowé¢„è®­ç»ƒæ¨¡å—è®ºæ–‡çº§å®éªŒæŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†ä½¿ç”¨Flowé¢„è®­ç»ƒæ¨¡å—è¿›è¡Œ**å‘è¡¨çº§ç ”ç©¶å®éªŒ**çš„å®Œæ•´æµç¨‹ï¼Œæ¶µç›–ä»å®éªŒè®¾è®¡åˆ°è®ºæ–‡å†™ä½œçš„å…¨è¿‡ç¨‹ã€‚

---

## 1. å®éªŒå‡†å¤‡ (Experiment Preparation)

### 1.1 ç¯å¢ƒéªŒè¯
```bash
# éªŒè¯Flowæ¨¡å—è®¾ç½®
python validate_flow_setup.py

# æ£€æŸ¥GPUèµ„æº
nvidia-smi

# ç¡®è®¤æ•°æ®å®Œæ•´æ€§
ls -la data/metadata_6_11.xlsx
```

### 1.2 æ•°æ®é›†å‡†å¤‡

#### æ ‡å‡†æ•°æ®é›†é…ç½®
```yaml
# æ¨èç”¨äºè®ºæ–‡çš„æ•°æ®é›†ç»„åˆ
datasets:
  train: [CWRU, XJTU, FEMTO]     # å¤šæ ·åŒ–è®­ç»ƒé›†
  val: [THU, SEU]                # ç‹¬ç«‹éªŒè¯é›†  
  test: [IMS, PU]                # å®Œå…¨ç‹¬ç«‹æµ‹è¯•é›†
```

#### æ•°æ®é¢„å¤„ç†æ ‡å‡†
```yaml
preprocessing:
  window_size: 1024              # æ ‡å‡†çª—å£å¤§å°
  stride: 256                    # 25%é‡å 
  normalization: 'standardization'
  truncate_length: 2000          # ç»Ÿä¸€åºåˆ—é•¿åº¦
  sampling_rate: 12000           # ç»Ÿä¸€é‡‡æ ·ç‡
```

### 1.3 è®¡ç®—èµ„æºè§„åˆ’
```bash
# å»ºè®®èµ„æºé…ç½®
GPU: RTX 3090/4090 (24GB) Ã— 1-2
RAM: 64GB+
å­˜å‚¨: 500GB+ SSD
é¢„ä¼°æ—¶é—´: 24-48å°æ—¶ (å®Œæ•´å®éªŒ)
```

---

## 2. åŸºçº¿å®éªŒ (Baseline Experiments)

### 2.1 FlowåŸºçº¿æ¨¡å‹
```bash
# æ ‡å‡†Flowé¢„è®­ç»ƒåŸºçº¿
./run_flow_experiments.sh research --gpu 0 --wandb --notes "Paper_Baseline_Flow"

# é…ç½®: flow_research_experiment.yaml
# - 200 epochs
# - batch_size: 64
# - lr: 5e-4
# - num_steps: 100
```

### 2.2 ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”åŸºçº¿

#### a) CNN-basedé¢„è®­ç»ƒ
```yaml
model:
  name: "ResNet1D"
  layers: [64, 128, 256, 512]
  
task:
  name: "masked_reconstruction" 
  mask_ratio: 0.15
  loss: "MSE"
```

#### b) Transformeré¢„è®­ç»ƒ
```yaml
model:
  name: "B_08_PatchTST"
  d_model: 512
  n_heads: 8
  n_layers: 6

task:
  name: "masked_reconstruction"
  patch_len: 16
  stride: 8
```

#### c) VAEåŸºçº¿
```yaml
model:
  name: "VAE_Baseline"
  latent_dim: 256
  encoder_layers: [512, 256, 128]
  decoder_layers: [128, 256, 512]
```

### 2.3 è¯„ä¼°æŒ‡æ ‡æ ‡å‡†
```python
# ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æŒ‡æ ‡
primary_metrics = {
    'classification': ['accuracy', 'f1_macro', 'precision', 'recall'],
    'few_shot': ['5_shot_acc', '10_shot_acc', '20_shot_acc'],
    'domain_transfer': ['target_domain_acc', 'adaptation_speed']
}

# é¢„è®­ç»ƒè´¨é‡æŒ‡æ ‡
pretraining_metrics = {
    'reconstruction': ['mse', 'mae', 'ssim'],
    'representation': ['feature_diversity', 'linear_separability'],
    'efficiency': ['params_count', 'training_time', 'inference_time']
}
```

---

## 3. æ¶ˆèç ”ç©¶ (Ablation Studies)

### 3.1 Flowç»„ä»¶æ¶ˆè

#### a) é‡‡æ ·æ­¥æ•°æ¶ˆè
```bash
# ä¸åŒé‡‡æ ·æ­¥æ•°å¯¹æ¯”
for steps in 20 50 100 200 500; do
  python run_flow_experiment_batch.py custom \
    --experiments baseline \
    --config_override "task.num_steps=$steps" \
    --notes "Ablation_Steps_$steps" \
    --wandb
done
```

#### b) å™ªå£°è°ƒåº¦æ¶ˆè
```bash
# ä¸åŒsigmaèŒƒå›´
configs=(
  "sigma_min=0.001,sigma_max=1.0"
  "sigma_min=0.01,sigma_max=2.0" 
  "sigma_min=0.0001,sigma_max=0.5"
)

for config in "${configs[@]}"; do
  python run_flow_experiment_batch.py custom \
    --experiments baseline \
    --config_override "$config" \
    --notes "Ablation_Sigma_$config"
done
```

#### c) æ—¶é—´ç¼–ç æ¶ˆè
```yaml
# ç§»é™¤æ—¶é—´ç¼–ç 
model:
  use_time_embedding: false
  
# ä¸åŒæ—¶é—´ç¼–ç æ–¹å¼
time_encoding_types: ['sinusoidal', 'learned', 'none']
```

### 3.2 å¯¹æ¯”å­¦ä¹ æƒé‡æ¶ˆè
```bash
# å¯¹æ¯”å­¦ä¹ æƒé‡æ‰«æ
weights=(0.0 0.1 0.3 0.5 0.7 1.0)

for w in "${weights[@]}"; do
  ./run_flow_experiments.sh contrastive \
    --config_override "task.contrastive_weight=$w" \
    --notes "Ablation_Contrastive_$w" \
    --wandb
done
```

### 3.3 æ¶æ„æ·±åº¦æ¶ˆè
```yaml
# ä¸åŒæ¨¡å‹æ·±åº¦é…ç½®
model_configs:
  small:
    hidden_dim: 128
    n_layers: 4
    
  medium:  
    hidden_dim: 256
    n_layers: 6
    
  large:
    hidden_dim: 512
    n_layers: 8
```

---

## 4. å¯¹æ¯”å®éªŒ (Comparative Experiments)

### 4.1 ç”Ÿæˆæ¨¡å‹å¯¹æ¯”

#### Flow vs VAE
```bash
# Flowè®­ç»ƒ
./run_flow_experiments.sh research --notes "Comparison_Flow"

# VAEè®­ç»ƒ 
python main.py --config configs/comparison/vae_baseline.yaml --notes "Comparison_VAE"

# å¯¹æ¯”è¯„ä¼°
python scripts/compare_generative_models.py --models flow,vae
```

#### Flow vs Diffusion
```bash
# DiffusionåŸºçº¿
python main.py --config configs/comparison/ddpm_baseline.yaml --notes "Comparison_DDPM"

# æ€§èƒ½å¯¹æ¯”
python scripts/benchmark_sampling_speed.py --models flow,ddpm
```

### 4.2 é¢„è®­ç»ƒæ–¹æ³•å¯¹æ¯”

#### Flow vs Contrastive Learning
```yaml
# çº¯å¯¹æ¯”å­¦ä¹ åŸºçº¿
task:
  name: "contrastive_pretrain"
  temperature: 0.1
  projection_dim: 256
  augmentation: ['noise', 'scaling', 'permutation']
```

#### Flow vs Masked Modeling
```yaml  
# MAE-styleé¢„è®­ç»ƒ
task:
  name: "masked_reconstruction"
  mask_ratio: 0.25
  mask_strategy: 'random'
  reconstruction_target: 'original'
```

---

## 5. æ³›åŒ–æ€§å®éªŒ (Generalization Studies)

### 5.1 è·¨æ•°æ®é›†è¯„ä¼°

#### è®¾ç½®1: å•æºåŸŸâ†’å¤šç›®æ ‡åŸŸ
```bash
# è®­ç»ƒé…ç½®
source_dataset="CWRU"
target_datasets=("XJTU" "THU" "SEU" "IMS")

# Flowé¢„è®­ç»ƒ
./run_flow_experiments.sh pipeline02 \
  --config_override "data.train_datasets=[$source_dataset]" \
  --notes "CrossDataset_Flow_${source_dataset}"

# è¯„ä¼°æ‰€æœ‰ç›®æ ‡åŸŸ
for target in "${target_datasets[@]}"; do
  python evaluate_cross_domain.py \
    --source $source_dataset \
    --target $target \
    --model flow_pretrained
done
```

#### è®¾ç½®2: å¤šæºåŸŸâ†’å•ç›®æ ‡åŸŸ
```bash
# å¤šæºé¢„è®­ç»ƒ
python run_multi_source_training.py \
  --sources "CWRU,XJTU,THU" \
  --target "SEU" \
  --model flow \
  --notes "MultiSource_Flow"
```

### 5.2 Few-Shotå­¦ä¹ è¯„ä¼°
```python
# Few-shotè¯„ä¼°åè®®
def evaluate_few_shot(model, dataset, shots=[1, 5, 10, 20]):
    results = {}
    for n_shot in shots:
        # éšæœºé‡‡æ ·support set
        support_acc = []
        for trial in range(10):  # 10æ¬¡é‡å¤å®éªŒ
            acc = run_few_shot_trial(model, dataset, n_shot, seed=trial)
            support_acc.append(acc)
        
        results[f"{n_shot}_shot"] = {
            'mean': np.mean(support_acc),
            'std': np.std(support_acc),
            'ci_95': confidence_interval(support_acc)
        }
    return results
```

### 5.3 å™ªå£°é²æ£’æ€§æµ‹è¯•
```python
# å™ªå£°é²æ£’æ€§è¯„ä¼°
noise_levels = [0.0, 0.05, 0.1, 0.2, 0.3, 0.5]
noise_types = ['gaussian', 'uniform', 'salt_pepper']

for noise_type in noise_types:
    for level in noise_levels:
        results = evaluate_with_noise(
            model='flow_pretrained',
            noise_type=noise_type,
            noise_level=level,
            dataset='test_clean'
        )
```

---

## 6. è§„æ¨¡åŒ–å®éªŒ (Scaling Experiments)

### 6.1 æ¨¡å‹å¤§å°Scaling
```yaml
# ä¸åŒæ¨¡å‹è§„æ¨¡
model_scales:
  nano:    {hidden_dim: 64,  n_layers: 2}   # ~10K params
  tiny:    {hidden_dim: 128, n_layers: 4}   # ~50K params  
  small:   {hidden_dim: 256, n_layers: 6}   # ~200K params
  medium:  {hidden_dim: 512, n_layers: 8}   # ~1M params
  large:   {hidden_dim: 1024, n_layers: 10} # ~4M params
```

### 6.2 æ•°æ®é‡Scaling
```bash
# ä¸åŒæ•°æ®é‡è®­ç»ƒ
data_ratios=(0.1 0.25 0.5 0.75 1.0)

for ratio in "${data_ratios[@]}"; do
  python train_with_data_ratio.py \
    --ratio $ratio \
    --model flow \
    --notes "DataScaling_${ratio}"
done
```

### 6.3 è®­ç»ƒæ—¶é•¿å½±å“
```bash
# ä¸åŒè®­ç»ƒepochæ•°å¯¹æ¯”
epochs=(10 25 50 100 200 500)

for ep in "${epochs[@]}"; do
  ./run_flow_experiments.sh baseline \
    --config_override "task.epochs=$ep" \
    --notes "EpochScaling_$ep"
done
```

---

## 7. ç»“æœæ”¶é›†ä¸åˆ†æ (Result Analysis)

### 7.1 è‡ªåŠ¨ç»“æœæ±‡æ€»è„šæœ¬
```python
#!/usr/bin/env python3
# scripts/collect_results.py

import pandas as pd
import json
from pathlib import Path

def collect_experiment_results(experiment_dir="results/"):
    """æ±‡æ€»æ‰€æœ‰å®éªŒç»“æœ"""
    results = []
    
    for exp_path in Path(experiment_dir).glob("*/"):
        if exp_path.is_dir():
            metrics_file = exp_path / "metrics.json"
            if metrics_file.exists():
                with open(metrics_file) as f:
                    metrics = json.load(f)
                
                results.append({
                    'experiment': exp_path.name,
                    'accuracy': metrics.get('test_accuracy', 0),
                    'f1_score': metrics.get('test_f1', 0),
                    'training_time': metrics.get('training_time', 0),
                    'params_count': metrics.get('model_params', 0)
                })
    
    df = pd.DataFrame(results)
    df.to_csv('experiment_results_summary.csv', index=False)
    return df

# ä½¿ç”¨
results_df = collect_experiment_results()
print(results_df.describe())
```

### 7.2 ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
```python
# ç»Ÿè®¡æ£€éªŒè„šæœ¬
import scipy.stats as stats

def statistical_comparison(method1_scores, method2_scores):
    """æ¯”è¾ƒä¸¤ç§æ–¹æ³•çš„ç»Ÿè®¡æ˜¾è‘—æ€§"""
    
    # Shapiro-Wilkæ­£æ€æ€§æ£€éªŒ
    _, p1 = stats.shapiro(method1_scores)
    _, p2 = stats.shapiro(method2_scores)
    
    if p1 > 0.05 and p2 > 0.05:
        # æ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨tæ£€éªŒ
        t_stat, p_value = stats.ttest_ind(method1_scores, method2_scores)
        test_type = "t-test"
    else:
        # éæ­£æ€åˆ†å¸ƒï¼Œä½¿ç”¨Mann-Whitney Uæ£€éªŒ
        u_stat, p_value = stats.mannwhitneyu(method1_scores, method2_scores)
        test_type = "Mann-Whitney U"
    
    # æ•ˆåº”å¤§å° (Cohen's d)
    pooled_std = np.sqrt(((len(method1_scores)-1)*np.var(method1_scores) + 
                         (len(method2_scores)-1)*np.var(method2_scores)) / 
                        (len(method1_scores)+len(method2_scores)-2))
    cohens_d = (np.mean(method1_scores) - np.mean(method2_scores)) / pooled_std
    
    return {
        'test_type': test_type,
        'p_value': p_value,
        'significant': p_value < 0.05,
        'effect_size': cohens_d,
        'effect_magnitude': interpret_cohens_d(cohens_d)
    }
```

### 7.3 å­¦ä¹ æ›²çº¿åˆ†æ
```python
# å­¦ä¹ æ›²çº¿ç»˜åˆ¶
import matplotlib.pyplot as plt
import seaborn as sns

def plot_learning_curves(experiments):
    """ç»˜åˆ¶å¤šä¸ªå®éªŒçš„å­¦ä¹ æ›²çº¿å¯¹æ¯”"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # è®­ç»ƒæŸå¤±
    for exp_name, metrics in experiments.items():
        axes[0,0].plot(metrics['train_loss'], label=exp_name)
    axes[0,0].set_title('Training Loss')
    axes[0,0].set_xlabel('Epoch')
    axes[0,0].set_ylabel('Loss')
    axes[0,0].legend()
    
    # éªŒè¯å‡†ç¡®ç‡
    for exp_name, metrics in experiments.items():
        axes[0,1].plot(metrics['val_accuracy'], label=exp_name)
    axes[0,1].set_title('Validation Accuracy')
    axes[0,1].set_xlabel('Epoch')
    axes[0,1].set_ylabel('Accuracy')
    axes[0,1].legend()
    
    plt.tight_layout()
    plt.savefig('learning_curves_comparison.pdf', dpi=300, bbox_inches='tight')
```

---

## 8. è®ºæ–‡å›¾è¡¨ç”Ÿæˆ (Paper Figures)

### 8.1 æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ç”Ÿæˆ
```python
# LaTeXè¡¨æ ¼ç”Ÿæˆè„šæœ¬
def generate_latex_table(results_df, caption="", label=""):
    """ç”ŸæˆLaTeXæ ¼å¼çš„ç»“æœè¡¨æ ¼"""
    
    latex_table = f"""
\\begin{{table}}[h]
\\centering
\\caption{{{caption}}}
\\label{{{label}}}
\\begin{{tabular}}{{lcccc}}
\\toprule
Method & Accuracy (\\%) & F1-Score & Parameters & Time (min) \\\\
\\midrule
"""
    
    for _, row in results_df.iterrows():
        method = row['method'].replace('_', '\\_')
        acc = f"{row['accuracy']:.2f} $\\pm$ {row['acc_std']:.2f}"
        f1 = f"{row['f1_score']:.3f}"
        params = f"{row['params']/1000:.0f}K" if row['params'] < 1e6 else f"{row['params']/1e6:.1f}M"
        time = f"{row['training_time']:.1f}"
        
        latex_table += f"{method} & {acc} & {f1} & {params} & {time} \\\\\n"
    
    latex_table += """\\bottomrule
\\end{tabular}
\\end{table}
"""
    
    return latex_table

# ä½¿ç”¨
table = generate_latex_table(
    results_df, 
    caption="Performance comparison of different pretraining methods on vibration signal classification",
    label="tab:performance_comparison"
)
print(table)
```

### 8.2 æ¶ˆèç ”ç©¶å¯è§†åŒ–
```python
# æ¶ˆèç ”ç©¶çƒ­åŠ›å›¾
def plot_ablation_heatmap(ablation_results):
    """ç»˜åˆ¶æ¶ˆèç ”ç©¶çƒ­åŠ›å›¾"""
    
    # å‡†å¤‡æ•°æ®
    components = ['Flow', 'Contrastive', 'Time_Embed', 'Multi_Scale']
    metrics = ['Accuracy', 'F1_Score', 'Transfer_Acc']
    
    # åˆ›å»ºç»“æœçŸ©é˜µ
    results_matrix = np.array(ablation_results).reshape(len(components), len(metrics))
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    plt.figure(figsize=(8, 6))
    sns.heatmap(results_matrix, 
                annot=True, 
                fmt='.3f',
                xticklabels=metrics,
                yticklabels=components,
                cmap='RdYlBu_r',
                center=0.5)
    
    plt.title('Ablation Study Results')
    plt.xlabel('Evaluation Metrics')
    plt.ylabel('Model Components')
    plt.tight_layout()
    plt.savefig('ablation_heatmap.pdf', dpi=300, bbox_inches='tight')
```

### 8.3 t-SNEç‰¹å¾å¯è§†åŒ–
```python
# ç‰¹å¾ç©ºé—´å¯è§†åŒ–
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

def visualize_learned_features(model, dataloader, save_path):
    """å¯è§†åŒ–å­¦ä¹ åˆ°çš„ç‰¹å¾è¡¨ç¤º"""
    
    features = []
    labels = []
    
    model.eval()
    with torch.no_grad():
        for batch in dataloader:
            x, y = batch
            # æå–ç‰¹å¾è¡¨ç¤º
            feat = model.extract_features(x)  # å‡è®¾æ¨¡å‹æœ‰æ­¤æ–¹æ³•
            features.append(feat.cpu().numpy())
            labels.append(y.cpu().numpy())
    
    features = np.concatenate(features, axis=0)
    labels = np.concatenate(labels, axis=0)
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42)
    features_2d = tsne.fit_transform(features)
    
    # ç»˜åˆ¶
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], 
                         c=labels, cmap='tab10', alpha=0.6)
    plt.colorbar(scatter)
    plt.title('t-SNE Visualization of Learned Features')
    plt.xlabel('t-SNE Dimension 1')
    plt.ylabel('t-SNE Dimension 2')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
```

---

## 9. å®éªŒè„šæœ¬æ¨¡æ¿ (Experiment Templates)

### 9.1 å®Œæ•´å®éªŒPipeline
```bash
#!/bin/bash
# full_paper_experiments.sh

set -e  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢

# 1. ç¯å¢ƒéªŒè¯
echo "=== éªŒè¯å®éªŒç¯å¢ƒ ==="
python validate_flow_setup.py || exit 1

# 2. åŸºçº¿å®éªŒ
echo "=== è¿è¡ŒåŸºçº¿å®éªŒ ==="
experiments=("flow_research" "vae_baseline" "contrastive_baseline")

for exp in "${experiments[@]}"; do
    echo "Running $exp..."
    ./run_flow_experiments.sh $exp --wandb --notes "Paper_Baseline_$exp"
    
    # æ£€æŸ¥å®éªŒæ˜¯å¦æˆåŠŸ
    if [ $? -ne 0 ]; then
        echo "å®éªŒ $exp å¤±è´¥ï¼"
        exit 1
    fi
done

# 3. æ¶ˆèç ”ç©¶
echo "=== æ¶ˆèç ”ç©¶ ==="
bash scripts/run_ablation_studies.sh

# 4. å¯¹æ¯”å®éªŒ  
echo "=== å¯¹æ¯”å®éªŒ ==="
bash scripts/run_comparative_studies.sh

# 5. ç»“æœæ±‡æ€»
echo "=== ç»“æœæ±‡æ€» ==="
python scripts/collect_results.py
python scripts/generate_paper_figures.py

echo "=== æ‰€æœ‰å®éªŒå®Œæˆï¼ ==="
```

### 9.2 è¶…å‚æ•°æ‰«æè„šæœ¬
```python
#!/usr/bin/env python3
# hyperparameter_sweep.py

import itertools
import subprocess
import yaml

def hyperparameter_sweep():
    """è¶…å‚æ•°ç½‘æ ¼æœç´¢"""
    
    # å®šä¹‰æœç´¢ç©ºé—´
    param_grid = {
        'task.lr': [1e-4, 5e-4, 1e-3],
        'task.flow_lr': [1e-4, 5e-4, 1e-3],
        'task.contrastive_weight': [0.1, 0.3, 0.5],
        'model.hidden_dim': [256, 512],
        'task.num_steps': [50, 100, 200]
    }
    
    # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
    param_names = list(param_grid.keys())
    param_values = list(param_grid.values())
    
    for combination in itertools.product(*param_values):
        params = dict(zip(param_names, combination))
        
        # æ„å»ºå‘½ä»¤
        overrides = [f"{k}={v}" for k, v in params.items()]
        override_str = ",".join(overrides)
        
        experiment_name = "_".join([f"{k.split('.')[-1]}{v}" for k, v in params.items()])
        
        cmd = [
            "python", "run_flow_experiment_batch.py", "custom",
            "--experiments", "baseline",
            "--config_override", override_str,
            "--notes", f"HyperSweep_{experiment_name}",
            "--wandb"
        ]
        
        print(f"è¿è¡Œ: {' '.join(cmd)}")
        subprocess.run(cmd)

if __name__ == "__main__":
    hyperparameter_sweep()
```

---

## 10. è®ºæ–‡å†™ä½œæ¨¡æ¿ (Writing Templates)

### 10.1 å®éªŒè®¾ç½®æ®µè½æ¨¡æ¿
```latex
\subsection{Experimental Setup}

We evaluate our Flow-based pretraining approach on X industrial vibration datasets, including CWRU bearing dataset~\cite{cwru}, XJTU-SY bearing dataset~\cite{xjtu}, and THU gearbox dataset~\cite{thu}. 

\textbf{Data Preprocessing:} Following standard practices~\cite{previous_work}, we segment each signal into windows of length 1024 with 75\% overlap, resulting in XXX training samples across Y fault categories. All signals are normalized using standardization.

\textbf{Model Configuration:} Our Flow model consists of a Z-layer transformer encoder with hidden dimension D=512. We use T=100 denoising steps during training and S=20 steps for fast sampling during inference. The contrastive learning component uses temperature Ï„=0.1 and projection dimension P=256.

\textbf{Training Details:} We train all models for E=200 epochs using Adam optimizer with learning rate lr=5Ã—10â»â´. The batch size is set to B=64, and we apply early stopping with patience P=20 based on validation loss. All experiments are conducted using PyTorch on NVIDIA RTX 3090 GPUs.

\textbf{Evaluation Protocol:} We assess model performance using K-fold cross-validation (K=5) and report mean accuracy along with 95\% confidence intervals. For few-shot evaluation, we randomly sample N={1,5,10,20} examples per class and repeat each experiment R=10 times.
```

### 10.2 ç»“æœè®¨è®ºè¦ç‚¹
```latex
\subsection{Results and Analysis}

\textbf{Main Results:} Table~\ref{tab:main_results} shows that our Flow-based pretraining achieves state-of-the-art performance across all benchmark datasets. Specifically, our method obtains XX.X\% accuracy on CWRU, outperforming the previous best method by Y.Y\% (p<0.01, Cohen's d=Z.Z).

\textbf{Ablation Study:} The ablation results in Table~\ref{tab:ablation} demonstrate the importance of each component. Removing the Flow mechanism leads to A\% performance drop, while disabling contrastive learning reduces accuracy by B\%. This indicates that both generative modeling and contrastive learning contribute synergistically.

\textbf{Cross-Dataset Generalization:} Figure~\ref{fig:cross_domain} illustrates the superior generalization capability of our approach. When trained on dataset X and tested on dataset Y, our method maintains Z\% of its original performance, significantly outperforming baseline methods.

\textbf{Few-Shot Performance:} Our Flow pretraining enables effective few-shot learning as shown in Figure~\ref{fig:few_shot}. With only N=5 examples per class, our method achieves XX\% accuracy, approaching the performance of fully supervised methods.

\textbf{Computational Efficiency:} Despite the iterative sampling process, our method achieves competitive inference speed (X ms per sample) while maintaining superior accuracy. The pretraining phase requires Y hours on a single GPU, making it practically feasible.
```

### 10.3 å±€é™æ€§åˆ†ææ¡†æ¶
```latex
\subsection{Limitations and Future Work}

While our Flow-based pretraining shows promising results, several limitations should be acknowledged:

\textbf{Dataset Bias:} Our evaluation focuses primarily on bearing fault diagnosis. The generalizability to other types of mechanical systems (e.g., pumps, motors) requires further investigation.

\textbf{Computational Cost:} The iterative denoising process increases inference time compared to single-forward methods. Future work could explore faster sampling techniques or distillation approaches.

\textbf{Hyperparameter Sensitivity:} The performance depends on careful tuning of Flow-specific hyperparameters (Ïƒ_min, Ïƒ_max, num_steps). More robust automatic hyperparameter selection methods would be beneficial.

\textbf{Theoretical Analysis:} While empirical results are strong, deeper theoretical understanding of why Flow models work well for vibration signals would strengthen the contribution.

Future research directions include: (1) extending to multimodal signals, (2) incorporating physical constraints into the generative model, and (3) developing specialized Flow architectures for time series data.
```

---

## 11. è´¨é‡æ§åˆ¶æ£€æŸ¥æ¸…å• (Quality Control)

### 11.1 å®éªŒå‰æ£€æŸ¥
- [ ] **ç¯å¢ƒé…ç½®**
  - [ ] CUDAç‰ˆæœ¬å…¼å®¹æ€§ç¡®è®¤
  - [ ] ä¾èµ–åº“ç‰ˆæœ¬é”å®š
  - [ ] éšæœºç§å­å›ºå®š (reproducibility)
  
- [ ] **æ•°æ®å‡†å¤‡**
  - [ ] è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†åˆ’åˆ†åˆç†
  - [ ] æ•°æ®æ³„éœ²æ£€æŸ¥ (no data leakage)
  - [ ] æ ·æœ¬å¹³è¡¡æ€§åˆ†æ

- [ ] **å®éªŒè®¾è®¡**
  - [ ] å¯¹ç…§ç»„è®¾ç½®åˆç†  
  - [ ] å˜é‡æ§åˆ¶ (åªæ”¹å˜ä¸€ä¸ªå› ç´ )
  - [ ] è¶³å¤Ÿçš„é‡å¤å®éªŒæ¬¡æ•°

### 11.2 å®éªŒä¸­ç›‘æ§
- [ ] **è®­ç»ƒè¿‡ç¨‹**
  - [ ] Lossæ”¶æ•›æ€§æ£€æŸ¥
  - [ ] æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±ç›‘æ§
  - [ ] å†…å­˜ä½¿ç”¨é‡è·Ÿè¸ª
  
- [ ] **éªŒè¯ç»“æœ**
  - [ ] è¿‡æ‹Ÿåˆæ£€æµ‹
  - [ ] æ¨¡å‹æ”¶æ•›ç¡®è®¤
  - [ ] ä¸­é—´ç»“æœåˆç†æ€§

### 11.3 ç»“æœåˆ†ææ£€æŸ¥
- [ ] **ç»Ÿè®¡æœ‰æ•ˆæ€§**
  - [ ] æ˜¾è‘—æ€§æ£€éªŒå®Œæˆ
  - [ ] æ•ˆåº”å¤§å°è®¡ç®—
  - [ ] ç½®ä¿¡åŒºé—´æŠ¥å‘Š
  
- [ ] **å¯é‡ç°æ€§**
  - [ ] ä»£ç ç‰ˆæœ¬è®°å½•
  - [ ] é…ç½®æ–‡ä»¶ä¿å­˜
  - [ ] ç¯å¢ƒä¿¡æ¯è®°å½•

---

## 12. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: å®éªŒç»“æœä¸ç¨³å®šæ€ä¹ˆåŠï¼Ÿ
**A:** 
1. å›ºå®šæ‰€æœ‰éšæœºç§å­ (Python, NumPy, PyTorch, CUDA)
2. å¢åŠ å®éªŒé‡å¤æ¬¡æ•° (å»ºè®®â‰¥5æ¬¡)
3. æ£€æŸ¥æ•°æ®åŠ è½½é¡ºåºæ˜¯å¦å›ºå®š
4. ä½¿ç”¨ç¡®å®šæ€§ç®—æ³• (`torch.use_deterministic_algorithms(True)`)

### Q2: å†…å­˜ä¸è¶³å¦‚ä½•å¤„ç†ï¼Ÿ
**A:**
1. å‡å°‘batch_size
2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ (`accumulate_grad_batches`)
3. å¯ç”¨mixed precisionè®­ç»ƒ (`precision=16`)
4. ä½¿ç”¨checkpointæŠ€æœ¯

### Q3: è®­ç»ƒæ—¶é—´è¿‡é•¿æ€ä¹ˆä¼˜åŒ–ï¼Ÿ
**A:**
1. ä½¿ç”¨å¤šGPUè®­ç»ƒ
2. å‡å°‘Flowé‡‡æ ·æ­¥æ•°
3. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ä½œä¸ºåˆæ­¥éªŒè¯
4. é‡‡ç”¨learning rate warmupåŠ é€Ÿæ”¶æ•›

### Q4: å¦‚ä½•ç¡®ä¿å…¬å¹³å¯¹æ¯”ï¼Ÿ
**A:**
1. ä½¿ç”¨ç›¸åŒçš„æ•°æ®åˆ’åˆ†
2. ç›¸åŒçš„è¯„ä¼°æŒ‡æ ‡å’Œåè®®
3. ç›¸åŒçš„è®¡ç®—èµ„æºé™åˆ¶
4. æŠ¥å‘Šæ‰€æœ‰å°è¯•çš„è¶…å‚æ•°ç»„åˆ

---

## ğŸ“Š æ€»ç»“

æœ¬æŒ‡å—æä¾›äº†ä½¿ç”¨Flowé¢„è®­ç»ƒæ¨¡å—è¿›è¡Œ**è®ºæ–‡çº§ç ”ç©¶**çš„å®Œæ•´æ–¹æ³•è®ºï¼Œä»å®éªŒè®¾è®¡åˆ°ç»“æœåˆ†æçš„å…¨æµç¨‹è¦†ç›–ã€‚

### ğŸ¯ å…³é”®æˆåŠŸè¦ç´ 
1. **ä¸¥æ ¼çš„å®éªŒè®¾è®¡** - æ§åˆ¶å˜é‡ï¼Œåˆç†å¯¹ç…§
2. **å……åˆ†çš„ç»Ÿè®¡åˆ†æ** - æ˜¾è‘—æ€§æ£€éªŒï¼Œæ•ˆåº”å¤§å°
3. **å…¨é¢çš„æ¶ˆèç ”ç©¶** - ç†è§£æ¯ä¸ªç»„ä»¶çš„è´¡çŒ®
4. **robustçš„è¯„ä¼°åè®®** - å¤šæ•°æ®é›†ï¼Œå¤šæŒ‡æ ‡éªŒè¯
5. **å¯é‡ç°çš„å®éªŒæµç¨‹** - è¯¦ç»†è®°å½•ï¼Œç‰ˆæœ¬æ§åˆ¶

### ğŸš€ å¼€å§‹ç ”ç©¶å®éªŒ
```bash
# å¿«é€Ÿå¼€å§‹
git clone <your-repo>
cd PHM-Vibench-flow
python validate_flow_setup.py
bash full_paper_experiments.sh
```

**é¢„æœŸäº§å‡º**: é«˜è´¨é‡çš„å®éªŒç»“æœï¼Œå¯å‘è¡¨çš„å›¾è¡¨ï¼Œå®Œæ•´çš„æ¶ˆèç ”ç©¶ï¼Œä»¥åŠrobustçš„ç»Ÿè®¡åˆ†æã€‚