#!/usr/bin/env python3
"""
ContrastiveIDTaskå¢å¼ºæµ‹è¯•å¥—ä»¶
åŒ…å«å•å…ƒæµ‹è¯•ã€æ¢¯åº¦æµ‹è¯•ã€å†…å­˜æµ‹è¯•ç­‰
"""
import torch
import numpy as np
import unittest
import time
import psutil
import os
from argparse import Namespace

# æ·»åŠ é¡¹ç›®è·¯å¾„
import sys
sys.path.append('.')

from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask


class TestContrastiveIDTaskEnhanced(unittest.TestCase):
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.args_data = Namespace(
            window_size=128,
            stride=64,
            num_window=2,
            window_sampling_strategy='random',
            normalization=True,
            dtype='float32'
        )
        
        self.args_task = Namespace(
            lr=1e-3,
            temperature=0.07,
            weight_decay=1e-4,
            loss="CE",
            metrics=["acc"]
        )
        
        self.args_model = Namespace(
            d_model=64,
            name="M_01_ISFM",
            backbone="B_08_PatchTST"
        )
        
        self.args_trainer = Namespace(
            epochs=50,
            gpus=0,
            accelerator="cpu"
        )
        
        self.args_environment = Namespace(
            save_dir="tests/test_results/"
        )
    
    def create_task(self):
        """åˆ›å»ºæµ‹è¯•ä»»åŠ¡å®ä¾‹"""
        # åˆ›å»ºé€‚é…çª—å£å¤§å°çš„ç½‘ç»œ (window_size * channels -> d_model)
        network = torch.nn.Sequential(
            torch.nn.Flatten(),  # å±•å¹³è¾“å…¥
            torch.nn.Linear(128 * 2, 64)  # 128çª—å£å¤§å° * 2é€šé“
        )
        return ContrastiveIDTask(
            network=network,
            args_data=self.args_data,
            args_model=self.args_model,
            args_task=self.args_task,
            args_trainer=self.args_trainer,
            args_environment=self.args_environment,
            metadata={}
        )
    
    def test_basic_functionality(self):
        """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
        print("\n=== æµ‹è¯•åŸºæœ¬åŠŸèƒ½ ===")
        task = self.create_task()
        
        # æµ‹è¯•ä»»åŠ¡åˆ›å»º
        self.assertIsInstance(task, ContrastiveIDTask)
        self.assertEqual(task.temperature, 0.07)
        
        # æµ‹è¯•çª—å£ç”Ÿæˆ
        data = np.random.randn(1000, 2)
        windows = task.create_windows(data, num_window=2, strategy='random')
        self.assertEqual(len(windows), 2)
        self.assertEqual(windows[0].shape, (128, 2))
        
        print("âœ… åŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    
    def test_batch_processing_variations(self):
        """æµ‹è¯•ä¸åŒæ‰¹å¤„ç†æƒ…å†µ"""
        print("\n=== æµ‹è¯•æ‰¹å¤„ç†å˜ä½“ ===")
        task = self.create_task()
        
        # æµ‹è¯•ä¸åŒæ‰¹å¤§å°
        for batch_size in [1, 2, 4, 8]:
            batch_data = [
                (f'id{i}', np.random.randn(500 + i * 100, 2), {'Label': i % 3})
                for i in range(batch_size)
            ]
            
            batch = task.prepare_batch(batch_data)
            
            self.assertEqual(len(batch['ids']), batch_size)
            self.assertEqual(batch['anchor'].shape[0], batch_size)
            self.assertEqual(batch['positive'].shape[0], batch_size)
        
        print("âœ… æ‰¹å¤„ç†å˜ä½“æµ‹è¯•é€šè¿‡")
    
    def test_gradient_flow(self):
        """æµ‹è¯•æ¢¯åº¦æµ"""
        print("\n=== æµ‹è¯•æ¢¯åº¦æµ ===")
        task = self.create_task()
        
        # åˆ›å»ºéœ€è¦æ¢¯åº¦çš„è¾“å…¥
        batch_size = 4
        feature_dim = 64
        z_anchor = torch.randn(batch_size, feature_dim, requires_grad=True)
        z_positive = torch.randn(batch_size, feature_dim, requires_grad=True)
        
        # è®¡ç®—æŸå¤±
        loss = task.infonce_loss(z_anchor, z_positive)
        
        # åå‘ä¼ æ’­
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        self.assertIsNotNone(z_anchor.grad)
        self.assertIsNotNone(z_positive.grad)
        self.assertFalse(torch.isnan(z_anchor.grad).any())
        self.assertFalse(torch.isnan(z_positive.grad).any())
        
        print(f"âœ… æ¢¯åº¦æµæµ‹è¯•é€šè¿‡ï¼ŒæŸå¤±å€¼: {loss.item():.4f}")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        print("\n=== æµ‹è¯•å†…å­˜ä½¿ç”¨ ===")
        
        process = psutil.Process(os.getpid())
        memory_before = process.memory_info().rss / 1024 / 1024  # MB
        
        task = self.create_task()
        
        # å¤„ç†å¤§æ‰¹é‡æ•°æ®ï¼ˆä½¿ç”¨2é€šé“åŒ¹é…ç½‘ç»œï¼‰
        large_batch_data = [
            (f'id{i}', np.random.randn(2000, 2), {'Label': i % 5})
            for i in range(20)
        ]
        
        batch = task.prepare_batch(large_batch_data)
        
        # å‰å‘ä¼ æ’­
        if len(batch['ids']) > 0:
            z_anchor = task.network(batch['anchor'])
            z_positive = task.network(batch['positive'])
            loss = task.infonce_loss(z_anchor, z_positive)
        
        memory_after = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = memory_after - memory_before
        
        self.assertLess(memory_increase, 500, f"å†…å­˜å¢é•¿è¿‡å¤§: {memory_increase:.2f}MB")
        
        print(f"âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡ï¼Œå†…å­˜å¢é•¿: {memory_increase:.2f}MB")
    
    def test_performance_benchmarking(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        print("\n=== æµ‹è¯•æ€§èƒ½åŸºå‡† ===")
        task = self.create_task()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        batch_data = [
            (f'id{i}', np.random.randn(1000, 2), {'Label': i % 3})
            for i in range(16)
        ]
        
        # æµ‹é‡æ‰¹å¤„ç†æ—¶é—´
        start_time = time.time()
        for _ in range(10):
            batch = task.prepare_batch(batch_data)
            if len(batch['ids']) > 0:
                z_anchor = task.network(batch['anchor'])
                z_positive = task.network(batch['positive'])
                loss = task.infonce_loss(z_anchor, z_positive)
        
        total_time = time.time() - start_time
        avg_time = total_time / 10
        batches_per_second = 1.0 / avg_time
        
        self.assertGreater(batches_per_second, 1.0, "æ‰¹å¤„ç†é€Ÿåº¦è¿‡æ…¢")
        
        print(f"âœ… æ€§èƒ½æµ‹è¯•é€šè¿‡ï¼Œé€Ÿåº¦: {batches_per_second:.2f} batches/sec")
    
    def test_different_window_strategies(self):
        """æµ‹è¯•ä¸åŒçª—å£é‡‡æ ·ç­–ç•¥"""
        print("\n=== æµ‹è¯•çª—å£é‡‡æ ·ç­–ç•¥ ===")
        task = self.create_task()
        
        data = np.random.randn(2000, 2)
        strategies = ['random', 'sequential', 'evenly_spaced']
        
        for strategy in strategies:
            windows = task.create_windows(
                data, 
                num_window=3, 
                strategy=strategy
            )
            
            self.assertEqual(len(windows), 3)
            self.assertEqual(windows[0].shape, (128, 2))
            
            # æ£€æŸ¥çª—å£ä¸å®Œå…¨ç›¸åŒï¼ˆé™¤äº†evenly_spacedå¯èƒ½é‡å¤ï¼‰
            if strategy != 'evenly_spaced':
                self.assertFalse(np.array_equal(windows[0], windows[1]))
        
        print("âœ… çª—å£ç­–ç•¥æµ‹è¯•é€šè¿‡")
    
    def test_temperature_sensitivity(self):
        """æµ‹è¯•æ¸©åº¦å‚æ•°æ•æ„Ÿæ€§"""
        print("\n=== æµ‹è¯•æ¸©åº¦å‚æ•°æ•æ„Ÿæ€§ ===")
        
        # æµ‹è¯•ä¸åŒæ¸©åº¦å€¼
        temperatures = [0.01, 0.07, 0.5, 1.0]
        losses = []
        
        for temp in temperatures:
            self.args_task.temperature = temp
            task = self.create_task()
            
            # ç›¸åŒçš„è¾“å…¥ç‰¹å¾
            z_anchor = torch.randn(4, 64)
            z_positive = torch.randn(4, 64)
            
            loss = task.infonce_loss(z_anchor, z_positive)
            losses.append(loss.item())
        
        # æ¸©åº¦è¶Šä½ï¼ŒæŸå¤±é€šå¸¸è¶Šå¤§ï¼ˆæ›´ä¸¥æ ¼çš„å¯¹æ¯”ï¼‰
        self.assertGreater(losses[0], losses[-1], "æ¸©åº¦å‚æ•°å½±å“ä¸ç¬¦åˆé¢„æœŸ")
        
        print("âœ… æ¸©åº¦æ•æ„Ÿæ€§æµ‹è¯•é€šè¿‡")
    
    def test_edge_cases_comprehensive(self):
        """å…¨é¢æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
        print("\n=== æµ‹è¯•è¾¹ç•Œæƒ…å†µ ===")
        task = self.create_task()
        
        # æµ‹è¯•1: ç©ºæ‰¹æ¬¡
        empty_batch = task.prepare_batch([])
        self.assertEqual(len(empty_batch['ids']), 0)
        
        # æµ‹è¯•2: å•æ ·æœ¬
        single_sample = [('single', np.random.randn(300, 1), {'Label': 0})]
        batch = task.prepare_batch(single_sample)
        self.assertEqual(len(batch['ids']), 1)
        
        # æµ‹è¯•3: æçŸ­åºåˆ—
        short_sample = [('short', np.random.randn(50, 1), {'Label': 0})]
        batch = task.prepare_batch(short_sample)
        self.assertEqual(len(batch['ids']), 0)  # åº”è¯¥è¢«è¿‡æ»¤
        
        # æµ‹è¯•4: æé•¿åºåˆ—
        long_sample = [('long', np.random.randn(10000, 1), {'Label': 0})]
        batch = task.prepare_batch(long_sample)
        self.assertEqual(len(batch['ids']), 1)  # åº”è¯¥æˆåŠŸå¤„ç†
        
        # æµ‹è¯•5: NaNæ•°æ®
        nan_data = np.random.randn(1000, 1)
        nan_data[100:200] = np.nan
        nan_sample = [('nan', nan_data, {'Label': 0})]
        batch = task.prepare_batch(nan_sample)
        # æ ¹æ®å®ç°ï¼Œå¯èƒ½è¢«è¿‡æ»¤æˆ–å¤„ç†
        
        print("âœ… è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
    
    def test_device_compatibility(self):
        """æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§"""
        print("\n=== æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§ ===")
        
        # CPUæµ‹è¯•
        task_cpu = self.create_task()
        z_anchor = torch.randn(2, 64)
        z_positive = torch.randn(2, 64)
        loss_cpu = task_cpu.infonce_loss(z_anchor, z_positive)
        self.assertFalse(loss_cpu.is_cuda)
        
        # GPUæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            self.args_trainer.gpus = 1
            task_gpu = self.create_task()
            z_anchor_gpu = z_anchor.cuda()
            z_positive_gpu = z_positive.cuda()
            loss_gpu = task_gpu.infonce_loss(z_anchor_gpu, z_positive_gpu)
            self.assertTrue(loss_gpu.is_cuda)
        
        print("âœ… è®¾å¤‡å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")


def run_enhanced_tests():
    """è¿è¡Œå¢å¼ºæµ‹è¯•å¥—ä»¶"""
    print("å¼€å§‹ContrastiveIDTaskå¢å¼ºæµ‹è¯•...")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    suite = unittest.TestLoader().loadTestsFromTestCase(TestContrastiveIDTaskEnhanced)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print("\n" + "=" * 60)
    if result.wasSuccessful():
        print("ğŸ‰ æ‰€æœ‰å¢å¼ºæµ‹è¯•é€šè¿‡ï¼")
        print(f"è¿è¡Œæµ‹è¯•: {result.testsRun}")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
        print(f"å¤±è´¥: {len(result.failures)}, é”™è¯¯: {len(result.errors)}")
        return False


if __name__ == "__main__":
    success = run_enhanced_tests()
    exit(0 if success else 1)