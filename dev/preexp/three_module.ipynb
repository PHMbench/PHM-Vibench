{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc5cfee",
   "metadata": {},
   "source": [
    "# Dit\n",
    "ref：\n",
    "- https://github.com/haidog-yaqub/MeanFlow\n",
    "- https://github.com/facebookresearch/DiT/blob/main/models.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dce214",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0212f00",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Embedding Demo ---\n",
      "输入图像形状: torch.Size([4, 4, 32, 32])\n",
      "输出 Token 序列形状: torch.Size([4, 256, 1152])\n",
      "输出条件向量 c 形状: torch.Size([4, 1152])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/P/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from timm.models.vision_transformer import PatchEmbed\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取) ---\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "        self.nfreq = nfreq\n",
    "\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):  # TODO ROPE\n",
    "        half_dim = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period)\n",
    "            * torch.arange(start=0, end=half_dim, dtype=torch.float32)\n",
    "            / half_dim\n",
    "        ).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat(\n",
    "                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n",
    "            )\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t * 1000\n",
    "        t_freq = self.timestep_embedding(t, self.nfreq)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, labels):\n",
    "        embeddings = self.embedding(labels)\n",
    "        return embeddings\n",
    "\n",
    "# --- 主要的 Embedding 模块 ---\n",
    "\n",
    "class MfditEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    将输入图像 x, 时间步 t, r, 和可选的类别标签 y 转换为\n",
    "    token 序列 x 和条件向量 c。\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=32, patch_size=2, in_channels=4, dim=1152, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "\n",
    "        # 图像和位置嵌入\n",
    "        self.x_embedder = PatchEmbed(input_size, patch_size, in_channels, dim)\n",
    "        num_patches = self.x_embedder.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, dim), requires_grad=False) # 通常在初始化后固定\n",
    "\n",
    "        # 时间步和标签嵌入\n",
    "        self.t_embedder = TimestepEmbedder(dim)\n",
    "        self.r_embedder = TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "\n",
    "    def forward(self, x, t, r, y=None):\n",
    "        # 1. 图像和位置嵌入\n",
    "        x = self.x_embedder(x) + self.pos_embed # init?\n",
    "\n",
    "        # 2. 条件嵌入\n",
    "        t_emb = self.t_embedder(t)\n",
    "        r_emb = self.r_embedder(r)\n",
    "        c = t_emb + r_emb # 合并时间步嵌入\n",
    "\n",
    "        if self.use_cond and y is not None:\n",
    "            y_emb = self.y_embedder(y)\n",
    "            c = c + y_emb # 添加类别嵌入\n",
    "\n",
    "        return x, c\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Embedding Demo ---\")\n",
    "    # 模型参数\n",
    "    B, C, H, W = 4, 4, 32, 32\n",
    "    DIM = 1152\n",
    "    NUM_CLASSES = 1000\n",
    "\n",
    "    # 创建 Embedding 模块实例\n",
    "    embedding_layer = MfditEmbedding(\n",
    "        input_size=H,\n",
    "        in_channels=C,\n",
    "        dim=DIM,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    # 创建模拟输入数据\n",
    "    x_in = torch.randn(B, C, H, W)\n",
    "    t_in = torch.rand(B)\n",
    "    r_in = torch.rand(B)\n",
    "    y_in = torch.randint(0, NUM_CLASSES, (B,))\n",
    "\n",
    "    # 前向传播\n",
    "    x_tokens, c_vector = embedding_layer(x_in, t_in, r_in, y_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入图像形状: {x_in.shape}\")\n",
    "    print(f\"输出 Token 序列形状: {x_tokens.shape}\")\n",
    "    print(f\"输出条件向量 c 形状: {c_vector.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62680b",
   "metadata": {},
   "source": [
    "### backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa153ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/P/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Backbone Demo ---\n",
      "输入 Token 序列形状: torch.Size([4, 256, 1152])\n",
      "输入条件向量 c 形状: torch.Size([4, 1152])\n",
      "输出特征序列形状: torch.Size([4, 256, 1152])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import Mlp, Attention\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取) ---\n",
    "def modulate(x, scale, shift):\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "\n",
    "class DiTBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=True, qk_norm=True, norm_layer=RMSNorm)\n",
    "        self.attn.fused_attn = False # 禁用融合注意力 (flash attention)，因为它不能与 JVP 一起使用\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        mlp_dim = int(dim * mlp_ratio)\n",
    "        approx_gelu = lambda: nn.GELU(approximate=\"tanh\")\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_dim, act_layer=approx_gelu, drop=0)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 6 * dim))\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (\n",
    "            self.adaLN_modulation(c).chunk(6, dim=-1)\n",
    "        )\n",
    "        x = x + gate_msa.unsqueeze(1) * self.attn(\n",
    "            modulate(self.norm1(x), scale_msa, shift_msa)\n",
    "        )\n",
    "        x = x + gate_mlp.unsqueeze(1) * self.mlp(\n",
    "            modulate(self.norm2(x), scale_mlp, shift_mlp)\n",
    "        )\n",
    "        return x\n",
    "\n",
    "# --- 主要的 Backbone 模块 ---\n",
    "\n",
    "class MfditBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    接收 token 序列 x 和条件向量 c，通过一系列 DiTBlock 进行处理。\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=1152, depth=28, num_heads=16, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(dim, num_heads, mlp_ratio) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, c)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Backbone Demo ---\")\n",
    "    # 模型参数\n",
    "    B = 4\n",
    "    NUM_TOKENS = 256 # (32/2) * (32/2)\n",
    "    DIM = 1152\n",
    "\n",
    "    # 创建 Backbone 模块实例\n",
    "    backbone = MfditBackbone(dim=DIM, depth=28, num_heads=16)\n",
    "\n",
    "    # 创建模拟输入数据 (来自 Embedding 层的输出)\n",
    "    x_tokens_in = torch.randn(B, NUM_TOKENS, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    # 前向传播\n",
    "    x_features = backbone(x_tokens_in, c_vector_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入 Token 序列形状: {x_tokens_in.shape}\")\n",
    "    print(f\"输入条件向量 c 形状: {c_vector_in.shape}\")\n",
    "    print(f\"输出特征序列形状: {x_features.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391e69a",
   "metadata": {},
   "source": [
    "### head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57514074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task Head Demo ---\n",
      "输入特征序列形状: torch.Size([4, 256, 1152])\n",
      "输入条件向量 c 形状: torch.Size([4, 1152])\n",
      "输出图像形状: torch.Size([4, 4, 32, 32])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取) ---\n",
    "def modulate(x, scale, shift):\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "\n",
    "class FinalLayer(nn.Module):\n",
    "    def __init__(self, dim, patch_size, out_dim):\n",
    "        super().__init__()\n",
    "        self.norm_final = RMSNorm(dim)\n",
    "        self.linear = nn.Linear(dim, patch_size * patch_size * out_dim)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 2 * dim))\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        shift, scale = self.adaLN_modulation(c).chunk(2, dim=-1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 Task Head 模块 ---\n",
    "\n",
    "class MfditTaskHead(nn.Module):\n",
    "    \"\"\"\n",
    "    接收来自 Backbone 的特征 x 和条件向量 c，并将其转换回图像格式。\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=1152, patch_size=2, out_channels=4):\n",
    "        super().__init__()\n",
    "        self.final_layer = FinalLayer(dim, patch_size, out_channels)\n",
    "        self.out_channels = out_channels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def unpatchify(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, T, patch_size**2 * C)\n",
    "        imgs: (N, C, H, W)\n",
    "        \"\"\"\n",
    "        c = self.out_channels\n",
    "        p = self.patch_size\n",
    "        h = w = int(x.shape[1] ** 0.5)\n",
    "        assert h * w == x.shape[1]\n",
    "\n",
    "        x = x.reshape(shape=(x.shape[0], h, w, p, p, c))\n",
    "        x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "        imgs = x.reshape(shape=(x.shape[0], c, h * p, w * p))\n",
    "        return imgs\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = self.final_layer(x, c)\n",
    "        x = self.unpatchify(x)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Task Head Demo ---\")\n",
    "    # 模型参数\n",
    "    B = 4\n",
    "    NUM_TOKENS = 256\n",
    "    DIM = 1152\n",
    "    PATCH_SIZE = 2\n",
    "    OUT_CHANNELS = 4\n",
    "\n",
    "    # 创建 Task Head 模块实例\n",
    "    task_head = MfditTaskHead(dim=DIM, patch_size=PATCH_SIZE, out_channels=OUT_CHANNELS)\n",
    "\n",
    "    # 创建模拟输入数据 (来自 Backbone 层的输出)\n",
    "    x_features_in = torch.randn(B, NUM_TOKENS, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    # 前向传播\n",
    "    output_image = task_head(x_features_in, c_vector_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入特征序列形状: {x_features_in.shape}\")\n",
    "    print(f\"输入条件向量 c 形状: {c_vector_in.shape}\")\n",
    "    print(f\"输出图像形状: {output_image.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e38273",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8bd6f5",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Embedding Demo ---\n",
      "输入时间序列形状: torch.Size([4, 3, 2048])\n",
      "输出 Token 序列形状: torch.Size([4, 128, 768])\n",
      "输出条件向量 c 形状: torch.Size([4, 768])\n",
      "预期 Token 数量: 128, 实际 Token 数量: 128\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Optional, Callable, Tuple, Union\n",
    "\n",
    "# --- 辅助模块 (从原代码中提取并保持不变) ---\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "        self.nfreq = nfreq\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half_dim = dim // 2\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32) / half_dim).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    def forward(self, t):\n",
    "        t = t * 1000\n",
    "        t_freq = self.timestep_embedding(t, self.nfreq)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self, labels):\n",
    "        return self.embedding(labels)\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos): # TO-DO + sample_rate \n",
    "    # ... (代码与上一回答完全相同)\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float64)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega\n",
    "    pos = pos.reshape(-1)\n",
    "    out = np.einsum('m,d->md', pos, omega)\n",
    "    emb_sin = np.sin(out)\n",
    "    emb_cos = np.cos(out)\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
    "    return emb\n",
    "\n",
    "# --- 关键修改: 1D Patch Embedding ---\n",
    "class PatchEmbed1d(nn.Module):\n",
    "    \"\"\" 1D Time-Series to Patch Embedding \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_len: int = 2048,\n",
    "        patch_size: int = 16,\n",
    "        in_chans: int = 3,\n",
    "        embed_dim: int = 768,\n",
    "        norm_layer: Optional[Callable] = None,\n",
    "        flatten: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # 使用 Conv1d 进行 Patching\n",
    "        self.proj = nn.Conv1d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "        self.flatten = flatten\n",
    "\n",
    "        self.num_patches = (seq_len // patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 形状: B, C, L\n",
    "        B, C, L = x.shape\n",
    "        assert L == self.seq_len, f\"Input sequence length ({L}) doesn't match model ({self.seq_len}).\"\n",
    "\n",
    "        x = self.proj(x) # B, E, L' (L' = L / patch_size)\n",
    "        if self.flatten:\n",
    "            x = x.transpose(1, 2)  # B, L', E\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Embedding 模块 ---\n",
    "class MfditEmbedding1d(nn.Module):\n",
    "    def __init__(self, seq_len=2048, patch_size=16, in_channels=3, dim=768, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "\n",
    "        # 1D 图像和位置嵌入\n",
    "        self.x_embedder = PatchEmbed1d(seq_len, patch_size, in_channels, dim)\n",
    "        self.num_patches = self.x_embedder.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches, dim), requires_grad=False)\n",
    "\n",
    "        # 条件嵌入 (保持不变)\n",
    "        self.t_embedder = TimestepEmbedder(dim)\n",
    "        self.r_embedder = TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # 初始化 1D 位置嵌入\n",
    "        pos_embed = get_1d_sincos_pos_embed_from_grid(self.pos_embed.shape[-1], np.arange(self.num_patches))\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "        # 其他权重初始化... (可以从原代码中复制)\n",
    "\n",
    "\n",
    "    def forward(self, x, t, r, y=None):\n",
    "        # 1. 1D 时间序列嵌入\n",
    "        # 输入 x 形状: B, C, L\n",
    "        x = self.x_embedder(x) + self.pos_embed # x 输出: B, Num_Patches, Dim # TO-DO 输入的 self.num_patches 和 patch_size 是确定的， 可能会涉及到unpatchify\n",
    "\n",
    "        # 2. 条件嵌入\n",
    "        t_emb = self.t_embedder(t)\n",
    "        r_emb = self.r_embedder(r)\n",
    "        c = t_emb + r_emb\n",
    "\n",
    "        if self.use_cond and y is not None:\n",
    "            y_emb = self.y_embedder(y)\n",
    "            c = c + y_emb\n",
    "\n",
    "        return x, c\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1D Embedding Demo ---\")\n",
    "    # 模型参数\n",
    "    B, C, L = 4, 3, 2048  # (Batch, Channels, Length)\n",
    "    PATCH_SIZE = 16\n",
    "    DIM = 768\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "    # 创建 Embedding 模块实例\n",
    "    embedding_layer_1d = MfditEmbedding1d(\n",
    "        seq_len=L,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        in_channels=C,\n",
    "        dim=DIM,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    # 创建模拟输入数据\n",
    "    x_in_1d = torch.randn(B, C, L) # 注意输入格式为 B,C,L\n",
    "    t_in = torch.rand(B)\n",
    "    r_in = torch.rand(B)\n",
    "    y_in = torch.randint(0, NUM_CLASSES, (B,))\n",
    "\n",
    "    # 前向传播\n",
    "    x_tokens, c_vector = embedding_layer_1d(x_in_1d, t_in, r_in, y_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入时间序列形状: {x_in_1d.shape}\")\n",
    "    print(f\"输出 Token 序列形状: {x_tokens.shape}\")\n",
    "    print(f\"输出条件向量 c 形状: {c_vector.shape}\")\n",
    "    print(f\"预期 Token 数量: {L // PATCH_SIZE}, 实际 Token 数量: {x_tokens.shape[1]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f52d279",
   "metadata": {},
   "source": [
    "### backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b3a809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Backbone Demo ---\n",
      "输入 Token 序列形状: torch.Size([4, 128, 768])\n",
      "输入条件向量 c 形状: torch.Size([4, 768])\n",
      "输出特征序列形状: torch.Size([4, 128, 768])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import Mlp, Attention\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取，无任何修改) ---\n",
    "def modulate(x, scale, shift):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "\n",
    "class DiTBlock(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=True, qk_norm=True, norm_layer=RMSNorm)\n",
    "        self.attn.fused_attn = False\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        mlp_dim = int(dim * mlp_ratio)\n",
    "        approx_gelu = lambda: nn.GELU(approximate=\"tanh\")\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_dim, act_layer=approx_gelu, drop=0)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 6 * dim))\n",
    "    def forward(self, x, c):\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (self.adaLN_modulation(c).chunk(6, dim=-1))\n",
    "        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), scale_msa, shift_msa))\n",
    "        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), scale_mlp, shift_mlp))\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Backbone 模块 (仅重命名) ---\n",
    "class MfditBackbone1d(nn.Module):\n",
    "    def __init__(self, dim=768, depth=12, num_heads=12, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(dim, num_heads, mlp_ratio) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, c)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1D Backbone Demo ---\")\n",
    "    # 模型参数\n",
    "    B = 4\n",
    "    NUM_TOKENS = 2048 // 16 # L / patch_size\n",
    "    DIM = 768\n",
    "\n",
    "    # 创建 Backbone 模块实例\n",
    "    backbone_1d = MfditBackbone1d(dim=DIM, depth=12, num_heads=12)\n",
    "\n",
    "    # 创建模拟输入数据 (来自 1D Embedding 层的输出)\n",
    "    x_tokens_in = torch.randn(B, NUM_TOKENS, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    # 前向传播\n",
    "    x_features = backbone_1d(x_tokens_in, c_vector_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入 Token 序列形状: {x_tokens_in.shape}\")\n",
    "    print(f\"输入条件向量 c 形状: {c_vector_in.shape}\")\n",
    "    print(f\"输出特征序列形状: {x_features.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f68af",
   "metadata": {},
   "source": [
    "### head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8201a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Task Head Demo ---\n",
      "输入特征序列形状: torch.Size([4, 128, 768])\n",
      "输入条件向量 c 形状: torch.Size([4, 768])\n",
      "输出时间序列形状: torch.Size([4, 3, 2048])\n",
      "预期输出长度: 2048, 实际输出长度: 2048\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取) ---\n",
    "def modulate(x, scale, shift):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "\n",
    "class FinalLayer(nn.Module):\n",
    "    # 将输出维度修改为 1D patch 所需的\n",
    "    def __init__(self, dim, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm_final = RMSNorm(dim)\n",
    "        # 线性层输出每个 patch 的所有通道的值\n",
    "        self.linear = nn.Linear(dim, patch_size * out_channels)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 2 * dim))\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        shift, scale = self.adaLN_modulation(c).chunk(2, dim=-1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Task Head 模块 ---\n",
    "class MfditTaskHead1d(nn.Module):\n",
    "    def __init__(self, dim=768, patch_size=16, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.final_layer = FinalLayer(dim, patch_size, out_channels)\n",
    "        self.out_channels = out_channels\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def unpatchify_1d(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, T, patch_size * C)\n",
    "        ts: (N, C, L)\n",
    "        \"\"\"\n",
    "        N, T, _ = x.shape\n",
    "        C = self.out_channels\n",
    "        P = self.patch_size\n",
    "        L = T * P\n",
    "\n",
    "        # (N, T, P * C) -> (N, T, P, C)\n",
    "        x = x.view(N, T, P, C)\n",
    "        # (N, T, P, C) -> (N, C, T, P)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # (N, C, T, P) -> (N, C, L)\n",
    "        ts = x.reshape(N, C, L)\n",
    "        return ts\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = self.final_layer(x, c) # x: (N, T, patch_size * out_channels)\n",
    "        x = self.unpatchify_1d(x)  # x: (N, C, L)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1D Task Head Demo ---\")\n",
    "    # 模型参数\n",
    "    B, C, L = 4, 3, 2048\n",
    "    PATCH_SIZE = 16\n",
    "    NUM_TOKENS = L // PATCH_SIZE\n",
    "    DIM = 768\n",
    "\n",
    "    # 创建 Task Head 模块实例\n",
    "    task_head_1d = MfditTaskHead1d(dim=DIM, patch_size=PATCH_SIZE, out_channels=C)\n",
    "\n",
    "    # 创建模拟输入数据 (来自 Backbone 层的输出)\n",
    "    x_features_in = torch.randn(B, NUM_TOKENS, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    # 前向传播\n",
    "    output_ts = task_head_1d(x_features_in, c_vector_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入特征序列形状: {x_features_in.shape}\")\n",
    "    print(f\"输入条件向量 c 形状: {c_vector_in.shape}\")\n",
    "    print(f\"输出时间序列形状: {output_ts.shape}\")\n",
    "    print(f\"预期输出长度: {L}, 实际输出长度: {output_ts.shape[2]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71c5e5",
   "metadata": {},
   "source": [
    "## 1D v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ceab3",
   "metadata": {},
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e99a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (修改后) 1D Embedding Demo ---\n",
      "输入时间序列形状 (x): torch.Size([4, 2048, 3])\n",
      "输入采样时间形状 (sample_T): torch.Size([4, 2048, 1])\n",
      "输出 Token 序列形状: torch.Size([4, 128, 768])\n",
      "输出条件向量 c 形状: torch.Size([4, 768])\n",
      "预期 Token 数量: 128, 实际 Token 数量: 128\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Optional, Callable\n",
    "\n",
    "# --- 辅助模块 (保持不变) ---\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "        self.nfreq = nfreq\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half_dim = dim // 2\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32) / half_dim).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    def forward(self, t):\n",
    "        t = t * 1000\n",
    "        t_freq = self.timestep_embedding(t, self.nfreq)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self, labels):\n",
    "        return self.embedding(labels)\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float64)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega\n",
    "    pos = pos.reshape(-1)\n",
    "    out = np.einsum('m,d->md', pos, omega)\n",
    "    emb_sin = np.sin(out)\n",
    "    emb_cos = np.cos(out)\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
    "    return emb\n",
    "\n",
    "# --- 1D Patch Embedding (保持不变, 但实例化时in_chans会+1) ---\n",
    "class PatchEmbed1d(nn.Module):\n",
    "    def __init__(self, seq_len, patch_size, in_chans, embed_dim, norm_layer=None, flatten=True):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        self.proj = nn.Conv1d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "        self.flatten = flatten\n",
    "        self.num_patches = (seq_len // patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, L = x.shape\n",
    "        assert L == self.seq_len, f\"Input sequence length ({L}) doesn't match model ({self.seq_len}).\"\n",
    "        x = self.proj(x)\n",
    "        if self.flatten:\n",
    "            x = x.transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Embedding 模块 (已修改) ---\n",
    "class MfditEmbedding1d(nn.Module):\n",
    "    def __init__(self, num_patches=128, patch_size=16, in_channels=3, dim=768, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "        self.in_channels = in_channels\n",
    "        self.seq_len = num_patches * patch_size # TO-DO 目前会fix PatchEmbedding 应该 可以overleaping\n",
    "\n",
    "        # 1. 修改: in_channels+1 用于拼接 sample_T\n",
    "        # 2. 修改: seq_len 是计算得出的\n",
    "        self.x_embedder = PatchEmbed1d(\n",
    "            seq_len=self.seq_len,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=self.in_channels + 1, # +1 for sample_T\n",
    "            embed_dim=dim\n",
    "        )\n",
    "        self.num_patches = self.x_embedder.num_patches\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches, dim), requires_grad=False)\n",
    "\n",
    "        # 条件嵌入 (保持不变)\n",
    "        self.t_embedder = TimestepEmbedder(dim)\n",
    "        self.r_embedder = TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        pos_embed = get_1d_sincos_pos_embed_from_grid(self.pos_embed.shape[-1], np.arange(self.num_patches))\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "    def forward(self, x, sample_T, t, r, y=None):\n",
    "        # 输入 x 形状: B, L, C\n",
    "        # 输入 sample_T 形状: B, L, 1\n",
    "        assert x.shape[1] == sample_T.shape[1], \"Sequence length of x and sample_T must match.\"\n",
    "        assert x.shape[1] == self.seq_len, f\"Input sequence length ({x.shape[1]}) doesn't match model ({self.seq_len}).\"\n",
    "\n",
    "        # 1. 修改: 拼接x和sample_T\n",
    "        x_with_time = torch.cat([x, sample_T], dim=-1) # -> B, L, C+1\n",
    "\n",
    "        # 2. 修改: 调整维度以匹配Conv1d\n",
    "        x_with_time = x_with_time.permute(0, 2, 1) # -> B, C+1, L\n",
    "\n",
    "        # 3. 1D 时间序列嵌入\n",
    "        x_tokens = self.x_embedder(x_with_time) + self.pos_embed # -> B, Num_Patches, Dim\n",
    "\n",
    "        # 4. 条件嵌入\n",
    "        t_emb = self.t_embedder(t)\n",
    "        r_emb = self.r_embedder(r)\n",
    "        c = t_emb + r_emb\n",
    "\n",
    "        if self.use_cond and y is not None:\n",
    "            y_emb = self.y_embedder(y)\n",
    "            c = c + y_emb\n",
    "\n",
    "        return x_tokens, c\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- (修改后) 1D Embedding Demo ---\")\n",
    "    B, C = 4, 3\n",
    "    NUM_PATCHES = 128\n",
    "    PATCH_SIZE = 16\n",
    "    L = NUM_PATCHES * PATCH_SIZE # 2048\n",
    "    DIM = 768\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "    embedding_layer_1d = MfditEmbedding1d(\n",
    "        num_patches=NUM_PATCHES,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        in_channels=C,\n",
    "        dim=DIM,\n",
    "        num_classes=NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    x_in_1d = torch.randn(B, L, C)\n",
    "    sample_T_in = torch.randn(B, L, 1) # 新增输入\n",
    "    t_in = torch.rand(B)\n",
    "    r_in = torch.rand(B)\n",
    "    y_in = torch.randint(0, NUM_CLASSES, (B,))\n",
    "\n",
    "    x_tokens, c_vector = embedding_layer_1d(x_in_1d, sample_T_in, t_in, r_in, y_in)\n",
    "\n",
    "    print(f\"输入时间序列形状 (x): {x_in_1d.shape}\")\n",
    "    print(f\"输入采样时间形状 (sample_T): {sample_T_in.shape}\")\n",
    "    print(f\"输出 Token 序列形状: {x_tokens.shape}\")\n",
    "    print(f\"输出条件向量 c 形状: {c_vector.shape}\")\n",
    "    print(f\"预期 Token 数量: {NUM_PATCHES}, 实际 Token 数量: {x_tokens.shape[1]}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810fc32",
   "metadata": {},
   "source": [
    "### embedding evenly spaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fa1403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (einops 重构) 动态 1D Embedding Demo ---\n",
      "输入序列形状: torch.Size([4, 3000, 3])\n",
      "输出 Token 形状: torch.Size([4, 128, 768])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange # 导入 rearrange\n",
    "\n",
    "# --- 辅助模块 (保持不变) ---\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "        self.nfreq = nfreq\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half_dim = dim // 2\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32) / half_dim).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    def forward(self, t):\n",
    "        t = t * 1000\n",
    "        t_freq = self.timestep_embedding(t, self.nfreq)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "        self.num_classes = num_classes\n",
    "    def forward(self, labels):\n",
    "        return self.embedding(labels)\n",
    "\n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    # ... (代码与上一回答完全相同)\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float64)\n",
    "    omega /= embed_dim / 2.\n",
    "    omega = 1. / 10000**omega\n",
    "    pos = pos.reshape(-1)\n",
    "    out = np.einsum('m,d->md', pos, omega)\n",
    "    emb_sin = np.sin(out)\n",
    "    emb_cos = np.cos(out)\n",
    "    emb = np.concatenate([emb_sin, emb_cos], axis=1)\n",
    "    return emb\n",
    "\n",
    "# --- 使用 einops 重构的 1D 动态补丁嵌入 ---\n",
    "class DynamicPatchEmbed1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, in_chans, embed_dim, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Linear(in_chans * patch_size, embed_dim)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, L = x.shape\n",
    "        x_4d = rearrange(x, 'b c l -> b c 1 l')\n",
    "\n",
    "        if L == self.patch_size:\n",
    "            stride = 1\n",
    "        else:\n",
    "            stride = max(1, (L - self.patch_size) // (self.num_patches - 1))\n",
    "\n",
    "        patches = F.unfold(x_4d, kernel_size=(1, self.patch_size), stride=(1, stride))\n",
    "\n",
    "        if patches.shape[-1] < self.num_patches:\n",
    "            patches = F.pad(patches, (0, self.num_patches - patches.shape[-1]))\n",
    "        elif patches.shape[-1] > self.num_patches:\n",
    "            patches = patches[:, :, :self.num_patches]\n",
    "\n",
    "        # --- 关键修改: 使用 rearrange ---\n",
    "        # (B, C * P, T) -> (B, T, C * P)\n",
    "        patches = rearrange(patches, 'b d t -> b t d')\n",
    "        \n",
    "        x = self.proj(patches)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Embedding 模块 (使用 einops 重构) ---\n",
    "class MfditEmbedding1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, in_channels, dim, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.x_embedder = DynamicPatchEmbed1d(num_patches, patch_size, in_channels + 1, dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, dim), requires_grad=False)\n",
    "        self.t_embedder = TimestepEmbedder(dim)\n",
    "        self.r_embedder = TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        pos_embed = get_1d_sincos_pos_embed_from_grid(self.pos_embed.shape[-1], np.arange(self.num_patches))\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "    def forward(self, x, sample_T, t, r, y=None):\n",
    "        # --- 关键修改: 使用 rearrange ---\n",
    "        x_with_time = torch.cat([x, sample_T], dim=-1)\n",
    "        # (B, L, C+1) -> (B, C+1, L)\n",
    "        x_with_time = rearrange(x_with_time, 'b l c -> b c l')\n",
    "\n",
    "        x_tokens = self.x_embedder(x_with_time) + self.pos_embed\n",
    "        \n",
    "        t_emb, r_emb = self.t_embedder(t), self.r_embedder(r)\n",
    "        c = t_emb + r_emb\n",
    "        if self.use_cond and y is not None:\n",
    "            c = c + self.y_embedder(y)\n",
    "        return x_tokens\n",
    "        \n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- (einops 重构) 动态 1D Embedding Demo ---\")\n",
    "    B, C, L_variable = 4, 3, 3000\n",
    "    NUM_PATCHES, PATCH_SIZE, DIM = 128, 16, 768\n",
    "\n",
    "    embedding_layer_1d = MfditEmbedding1d(\n",
    "        num_patches=NUM_PATCHES, patch_size=PATCH_SIZE, in_channels=C, dim=DIM\n",
    "    )\n",
    "    x_in_1d = torch.randn(B, L_variable, C)\n",
    "    sample_T_in = torch.randn(B, L_variable, 1)\n",
    "    t_in, r_in = torch.rand(B), torch.rand(B)\n",
    "    x_tokens = embedding_layer_1d(x_in_1d, sample_T_in, t_in, r_in)\n",
    "    print(f\"输入序列形状: {x_in_1d.shape}\")\n",
    "    print(f\"输出 Token 形状: {x_tokens.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab885a6",
   "metadata": {},
   "source": [
    "### backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42a048b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f27c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2019aafb",
   "metadata": {},
   "source": [
    "### task_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577300eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (修改后) 1D Task Head Demo ---\n",
      "输入特征序列形状: torch.Size([4, 128, 768])\n",
      "输出时间序列形状: torch.Size([4, 2048, 3])\n",
      "预期输出形状: (4, 2048, 3)\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- 依赖的辅助模块 (从原代码中提取) ---\n",
    "def modulate(x, scale, shift):\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "class FinalLayer(nn.Module):\n",
    "    def __init__(self, dim, patch_size, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm_final = RMSNorm(dim)\n",
    "        self.linear = nn.Linear(dim, patch_size * out_channels)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 2 * dim))\n",
    "    def forward(self, x, c):\n",
    "        shift, scale = self.adaLN_modulation(c).chunk(2, dim=-1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Task Head 模块 (已修改) ---\n",
    "class MfditTaskHead1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, out_channels, dim=768):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.out_channels = out_channels\n",
    "        self.final_layer = FinalLayer(dim, patch_size, out_channels)\n",
    "\n",
    "    def unpatchify_1d(self, x):\n",
    "        \"\"\"\n",
    "        x: (N, T, patch_size * C_out)\n",
    "        ts: (N, C_out, L)\n",
    "        \"\"\"\n",
    "        N, T, _ = x.shape\n",
    "        # 断言token数量与初始化时一致\n",
    "        assert T == self.num_patches, \"Input token count must match num_patches.\"\n",
    "        C = self.out_channels\n",
    "        P = self.patch_size\n",
    "        L = T * P\n",
    "\n",
    "        x = x.view(N, T, P, C)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        ts = x.reshape(N, C, L)\n",
    "        return ts\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        x = self.final_layer(x, c)\n",
    "        x = self.unpatchify_1d(x)  # -> (N, C, L)\n",
    "        # 修改: 调整输出维度以匹配 B,L,C\n",
    "        x = x.permute(0, 2, 1)   # -> (N, L, C)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- (修改后) 1D Task Head Demo ---\")\n",
    "    B, C = 4, 3\n",
    "    NUM_PATCHES = 128\n",
    "    PATCH_SIZE = 16\n",
    "    L = NUM_PATCHES * PATCH_SIZE\n",
    "    DIM = 768\n",
    "\n",
    "    task_head_1d = MfditTaskHead1d(\n",
    "        num_patches=NUM_PATCHES,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        out_channels=C,\n",
    "        dim=DIM\n",
    "    )\n",
    "\n",
    "    x_features_in = torch.randn(B, NUM_PATCHES, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    output_ts = task_head_1d(x_features_in, c_vector_in)\n",
    "\n",
    "    print(f\"输入特征序列形状: {x_features_in.shape}\")\n",
    "    print(f\"输出时间序列形状: {output_ts.shape}\")\n",
    "    print(f\"预期输出形状: ({B}, {L}, {C})\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1a1c6",
   "metadata": {},
   "source": [
    "## 1D v3 patcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8b823",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b34188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模块一: Embedding 独立测试 ---\n",
      "输入 x shape: torch.Size([4, 3000, 3])\n",
      "输出 tokens shape: torch.Size([4, 128, 768])\n",
      "输出 条件c shape: torch.Size([4, 768])\n",
      "Embedding 模块测试通过！\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "\n",
    "# 核心: 精确的、无损的序列补丁化与重建\n",
    "class SequencePatcher(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def patch(self, x):\n",
    "        B, C, L = x.shape\n",
    "        if L < self.patch_size:\n",
    "            raise ValueError(f\"输入序列长度 ({L}) 必须大于或等于补丁大小 ({self.patch_size})\")\n",
    "\n",
    "        start_indices = torch.linspace(\n",
    "            0, L - self.patch_size, steps=self.num_patches, device=x.device\n",
    "        ).round().long()\n",
    "\n",
    "        patch_indices = torch.arange(self.patch_size, device=x.device)\n",
    "        absolute_indices = start_indices.unsqueeze(1) + patch_indices\n",
    "        absolute_indices = rearrange(absolute_indices, 't p -> 1 1 t p').expand(B, C, -1, -1)\n",
    "        \n",
    "        # 使用 unsqueeze 和 expand 替代 gather, 在某些情况下性能更好\n",
    "        # (B, C, L) -> (B, C, 1, L) -> (B, C, T, L)\n",
    "        expanded_x = x.unsqueeze(2).expand(-1, -1, self.num_patches, -1) # (B, C, T, L)\n",
    "        patches = torch.gather(expanded_x, 3, absolute_indices) # (B, C, T, P)\n",
    "        \n",
    "        patches = rearrange(patches, 'b c t p -> b t (c p)')\n",
    "        return patches\n",
    "    def reconstruct(self, patches, L_original):\n",
    "        \"\"\"\n",
    "        输入: patches (B, T, C * P)\n",
    "             L_original (int) - 原始序列长度\n",
    "        输出: (B, C, L_original)\n",
    "        \"\"\"\n",
    "        B, T, _ = patches.shape\n",
    "        assert T == self.num_patches, \"输入补丁数量与初始化不符\"\n",
    "        \n",
    "        C = patches.shape[-1] // self.patch_size\n",
    "        \n",
    "        patches = rearrange(patches, 'b t (c p) -> b t c p', p=self.patch_size)\n",
    "\n",
    "        start_indices = torch.linspace(\n",
    "            0, L_original - self.patch_size, steps=self.num_patches, device=patches.device\n",
    "        ).round().long()\n",
    "        \n",
    "        output = torch.zeros(B, C, L_original, device=patches.device)\n",
    "        overlap_count = torch.zeros(B, C, L_original, device=patches.device)\n",
    "        \n",
    "        # 使用 scatter_add_ 高效并行地放置补丁\n",
    "        # 创建索引\n",
    "        patch_pos_indices = torch.arange(self.patch_size, device=patches.device).unsqueeze(0)\n",
    "        absolute_indices = start_indices.unsqueeze(1) + patch_pos_indices\n",
    "        \n",
    "        # 扩展维度以匹配 scatter_add_ 的要求\n",
    "        absolute_indices_expanded = rearrange(absolute_indices, 't p -> 1 1 t p').expand(B, C, -1, -1)\n",
    "        patches_for_scatter = rearrange(patches, 'b t c p -> b c t p')\n",
    "        \n",
    "        output.scatter_add_(2, absolute_indices_expanded.flatten(2), patches_for_scatter.flatten(2))\n",
    "        overlap_count.scatter_add_(2, absolute_indices_expanded.flatten(2), torch.ones_like(patches_for_scatter).flatten(2))\n",
    "            \n",
    "        output = output / torch.clamp(overlap_count, min=1.0)\n",
    "        \n",
    "        return output\n",
    "# 辅助模块\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half_dim = dim // 2\n",
    "        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32) / half_dim).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "    def forward(self, t):\n",
    "        t = t * 1000\n",
    "        t_freq = self.timestep_embedding(t, self.mlp[0].in_features)\n",
    "        return self.mlp(t_freq)\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    def __init__(self, num_classes, dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "    def forward(self, labels):\n",
    "        return self.embedding(labels)\n",
    "        \n",
    "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
    "    assert embed_dim % 2 == 0\n",
    "    omega = np.arange(embed_dim // 2, dtype=np.float64) / (embed_dim / 2.)\n",
    "    omega = 1. / 10000**omega\n",
    "    out = np.einsum('m,d->md', pos.reshape(-1), omega)\n",
    "    return np.concatenate([np.sin(out), np.cos(out)], axis=1)\n",
    "\n",
    "# 主要 Embedding 模块\n",
    "class MfditEmbedding1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, in_channels, dim, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "        self.num_patches = num_patches\n",
    "        self.patcher = SequencePatcher(num_patches, patch_size)\n",
    "        self.proj = nn.Linear((in_channels + 1) * patch_size, dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, dim), requires_grad=False)\n",
    "        self.t_embedder = TimestepEmbedder(dim)\n",
    "        self.r_embedder = TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        pos_embed = get_1d_sincos_pos_embed_from_grid(self.pos_embed.shape[-1], np.arange(self.num_patches))\n",
    "        self.pos_embed.data.copy_(torch.from_numpy(pos_embed).float().unsqueeze(0))\n",
    "\n",
    "    def forward(self, x, sample_T, t, r, y=None):\n",
    "        x_with_time = torch.cat([x, sample_T], dim=-1)\n",
    "        x_with_time = rearrange(x_with_time, 'b l c -> b c l')\n",
    "        patches = self.patcher.patch(x_with_time)\n",
    "        x_tokens = self.proj(patches) + self.pos_embed\n",
    "        \n",
    "        t_emb, r_emb = self.t_embedder(t), self.r_embedder(r)\n",
    "        c = t_emb + r_emb\n",
    "        if self.use_cond and y is not None:\n",
    "            c = c + self.y_embedder(y)\n",
    "        \n",
    "        # --- Bug修复: 同时返回 x_tokens 和 c ---\n",
    "        return x_tokens, c\n",
    "# --- Demo for Embedding Module ---\n",
    "print(\"--- 模块一: Embedding 独立测试 ---\")\n",
    "# 超参数\n",
    "B, C_in, L_variable = 4, 3, 3000\n",
    "NUM_PATCHES, PATCH_SIZE, DIM = 128, 16, 768\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# 实例化模块\n",
    "embedding_layer = MfditEmbedding1d(\n",
    "    num_patches=NUM_PATCHES, \n",
    "    patch_size=PATCH_SIZE, \n",
    "    in_channels=C_in, \n",
    "    dim=DIM,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# 创建模拟输入\n",
    "x_in = torch.randn(B, L_variable, C_in)\n",
    "sample_T_in = torch.randn(B, L_variable, 1)\n",
    "t_in, r_in = torch.rand(B), torch.rand(B)\n",
    "y_in = torch.randint(0, NUM_CLASSES, (B,))\n",
    "\n",
    "# 前向传播\n",
    "x_tokens, c_vector = embedding_layer(x_in, sample_T_in, t_in, r_in, y_in)\n",
    "\n",
    "# 验证输出\n",
    "print(f\"输入 x shape: {x_in.shape}\")\n",
    "print(f\"输出 tokens shape: {x_tokens.shape}\")\n",
    "print(f\"输出 条件c shape: {c_vector.shape}\")\n",
    "assert x_tokens.shape == (B, NUM_PATCHES, DIM)\n",
    "assert c_vector.shape == (B, DIM)\n",
    "print(\"Embedding 模块测试通过！\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849048ee",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84656253",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3e23148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模块三: Task Head 独立测试 ---\n",
      "输入 features shape: torch.Size([4, 128, 768])\n",
      "重建后 output shape: torch.Size([4, 3000, 3])\n",
      "Task Head 模块测试通过！\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 注意: 这个模块依赖于上面定义的 SequencePatcher 类\n",
    "class MfditTaskHead1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, out_channels, dim=768):\n",
    "        super().__init__()\n",
    "        self.patcher = SequencePatcher(num_patches, patch_size)\n",
    "        self.final_norm = RMSNorm(dim)\n",
    "        self.final_mod = nn.Sequential(nn.SiLU(), nn.Linear(dim, 2 * dim))\n",
    "        self.proj_out = nn.Linear(dim, out_channels * patch_size)\n",
    "\n",
    "    def forward(self, x_tokens, c, L_original):\n",
    "        shift, scale = self.final_mod(c).chunk(2, dim=-1)\n",
    "        x = modulate(self.final_norm(x_tokens), shift, scale)\n",
    "        patches_out = self.proj_out(x)\n",
    "        reconstructed_ts = self.patcher.reconstruct(patches_out, L_original)\n",
    "        output = rearrange(reconstructed_ts, 'b c l -> b l c')\n",
    "        return output\n",
    "# --- Demo for Task Head Module ---\n",
    "print(\"--- 模块三: Task Head 独立测试 ---\")\n",
    "# 超参数\n",
    "B, L_variable, C_out = 4, 3000, 3\n",
    "NUM_PATCHES, PATCH_SIZE, DIM = 128, 16, 768\n",
    "\n",
    "# 实例化模块\n",
    "task_head = MfditTaskHead1d(\n",
    "    num_patches=NUM_PATCHES, \n",
    "    patch_size=PATCH_SIZE, \n",
    "    out_channels=C_out, \n",
    "    dim=DIM\n",
    ")\n",
    "\n",
    "# 模拟输入 (来自Backbone层的输出)\n",
    "features_in = torch.randn(B, NUM_PATCHES, DIM)\n",
    "c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "# 前向传播\n",
    "output_ts = task_head(features_in, c_vector_in, L_original=L_variable)\n",
    "\n",
    "# 验证输出\n",
    "print(f\"输入 features shape: {features_in.shape}\")\n",
    "print(f\"重建后 output shape: {output_ts.shape}\")\n",
    "assert output_ts.shape == (B, L_variable, C_out)\n",
    "print(\"Task Head 模块测试通过！\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6867461",
   "metadata": {},
   "source": [
    "## 1D v + channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05e0dd",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ba1dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模块一: 统一补丁配置的 Embedding 独立测试 ---\n",
      "输入 vibration (3通道), L=3000\n",
      "  -> 输出 tokens shape: torch.Size([4, 128, 768])\n",
      "  -> 输出 condition shape: torch.Size([4, 768])\n",
      "  -> 输出 indices shape: torch.Size([128])\n",
      "  'vibration'信号处理成功!\n",
      "----------------------------------------\n",
      "输入 temperature (1通道), L=3000\n",
      "  -> 输出 tokens shape: torch.Size([4, 128, 768])\n",
      "  -> 输出 condition shape: torch.Size([4, 768])\n",
      "  -> 输出 indices shape: torch.Size([128])\n",
      "  'temperature'信号处理成功!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 模块一(A): 最终版 - 独立的、无状态的 SequencePatcher\n",
    "# --------------------------------------------------------------------------\n",
    "class SequencePatcher(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def patch(self, x):\n",
    "        \"\"\" 输入 (B, C, L), 输出 (B, T, C, P) 和 start_indices (T,) \"\"\"\n",
    "        B, C, L = x.shape\n",
    "        if L < self.patch_size:\n",
    "            raise ValueError(f\"序列长度 ({L}) 不能小于补丁大小 ({self.patch_size})\")\n",
    "\n",
    "        start_indices = torch.linspace(\n",
    "            0, L - self.patch_size, steps=self.num_patches, device=x.device\n",
    "        ).round().long()\n",
    "\n",
    "        patch_indices = torch.arange(self.patch_size, device=x.device)\n",
    "        absolute_indices = rearrange(start_indices, 't -> t 1') + rearrange(patch_indices, 'p -> 1 p')\n",
    "        absolute_indices_for_gather = rearrange(absolute_indices, 't p -> 1 1 t p').expand(B, C, -1, -1)\n",
    "        \n",
    "        patches = torch.gather(x.unsqueeze(2).expand(-1, -1, self.num_patches, -1), 3, absolute_indices_for_gather)\n",
    "        return rearrange(patches, 'b c t p -> b t c p'), start_indices\n",
    "\n",
    "    def unpatch(self, patches, start_indices, L_original):\n",
    "        \"\"\" 输入 (B, T, C, P), start_indices, L_original, 输出 (B, L, C) \"\"\"\n",
    "        B, T, C, P = patches.shape\n",
    "        assert T == self.num_patches and P == self.patch_size\n",
    "        \n",
    "        output = torch.zeros(B, C, L_original, device=patches.device)\n",
    "        overlap_count = torch.zeros(B, C, L_original, device=patches.device)\n",
    "        \n",
    "        patch_pos_indices = torch.arange(P, device=patches.device).unsqueeze(0)\n",
    "        absolute_indices = start_indices.unsqueeze(1) + patch_pos_indices\n",
    "        absolute_indices_expanded = rearrange(absolute_indices, 't p -> 1 1 t p').expand(B, C, -1, -1)\n",
    "        patches_for_scatter = rearrange(patches, 'b t c p -> b c t p')\n",
    "        \n",
    "        output.scatter_add_(2, absolute_indices_expanded.flatten(2), patches_for_scatter.flatten(2))\n",
    "        overlap_count.scatter_add_(2, absolute_indices_expanded.flatten(2), torch.ones_like(patches_for_scatter).flatten(2))\n",
    "        \n",
    "        reconstructed_ts = output / torch.clamp(overlap_count, min=1.0)\n",
    "        return rearrange(reconstructed_ts, 'b c l -> b l c')\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 模块一(B): 主要的 Embedding 模块\n",
    "# --------------------------------------------------------------------------\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    def __init__(self, dim, nfreq=256):\n",
    "        super().__init__(); self.mlp = nn.Sequential(nn.Linear(nfreq, dim), nn.SiLU(), nn.Linear(dim, dim))\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half = dim // 2; freqs = torch.exp(-math.log(max_period) * torch.arange(half, dtype=torch.float32) / half).to(t.device)\n",
    "        embedding = torch.cat([torch.cos(t[:, None] * freqs), torch.sin(t[:, None] * freqs)], dim=-1)\n",
    "        if dim % 2: embedding = F.pad(embedding, (0, 1))\n",
    "        return embedding\n",
    "    def forward(self, t): return self.mlp(self.timestep_embedding(t * 1000, self.mlp[0].in_features))\n",
    "\n",
    "class LabelEmbedder(nn.Module):\n",
    "    def __init__(self, num_classes, dim): super().__init__(); self.embedding = nn.Embedding(num_classes + 1, dim)\n",
    "    def forward(self, labels): return self.embedding(labels)\n",
    "\n",
    "def get_1d_sincos_pos_embed(embed_dim, num_patches):\n",
    "    pos = torch.arange(num_patches)\n",
    "    omega = torch.arange(embed_dim // 2, dtype=torch.float64) / (embed_dim / 2.)\n",
    "    omega = 1. / 10000**omega\n",
    "    out = torch.einsum('m,d->md', pos, omega)\n",
    "    return torch.cat([torch.sin(out), torch.cos(out)], dim=1).float()\n",
    "\n",
    "class MfditEmbedding1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, channel_map, c_dim, dim, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.use_cond = num_classes is not None\n",
    "        # 核心修改: 使用统一的补丁配置\n",
    "        self.patcher = SequencePatcher(num_patches, patch_size)\n",
    "        \n",
    "        self.channel_embedders = nn.ModuleDict({\n",
    "            name: nn.Sequential(nn.Linear(num_channels + 1, c_dim * 2), nn.GELU(), nn.Linear(c_dim * 2, c_dim))\n",
    "            for name, num_channels in channel_map.items()\n",
    "        })\n",
    "        self.proj_patch = nn.Linear(patch_size * c_dim, dim)\n",
    "        self.pos_embed = nn.Parameter(get_1d_sincos_pos_embed(dim, num_patches).unsqueeze(0), requires_grad=False)\n",
    "        self.t_embedder, self.r_embedder = TimestepEmbedder(dim), TimestepEmbedder(dim)\n",
    "        self.y_embedder = LabelEmbedder(num_classes, dim) if self.use_cond else None\n",
    "\n",
    "    def forward(self, x, name, sample_T, t, r, y=None):\n",
    "        x_with_time = torch.cat([x, sample_T], dim=-1)\n",
    "        \n",
    "        patches, start_indices = self.patcher.patch(rearrange(x_with_time, 'b l c -> b c l'))\n",
    "        \n",
    "        patches_for_mlp = rearrange(patches, 'b t c p -> b t p c')\n",
    "        channel_embedded_patches = self.channel_embedders[name](patches_for_mlp)\n",
    "        flattened_patches = rearrange(channel_embedded_patches, 'b t p c_dim -> b t (p c_dim)')\n",
    "        x_tokens = self.proj_patch(flattened_patches)\n",
    "        x_tokens = x_tokens + self.pos_embed\n",
    "        \n",
    "        t_emb, r_emb = self.t_embedder(t), self.r_embedder(r)\n",
    "        c = t_emb + r_emb\n",
    "        if self.use_cond and y is not None: c = c + self.y_embedder(y)\n",
    "            \n",
    "        # 核心修改: 返回重建所需的 start_indices\n",
    "        return x_tokens, c, start_indices\n",
    "# --- 模块一: 最终版 Embedding 独立测试 ---\n",
    "print(\"--- 模块一: 统一补丁配置的 Embedding 独立测试 ---\")\n",
    "B, L_variable = 4, 3000\n",
    "# 统一的补丁配置\n",
    "NUM_PATCHES, PATCH_SIZE = 128, 16\n",
    "# 其他超参数\n",
    "C_DIM, DIM = 16, 768\n",
    "\n",
    "CHANNEL_MAP = {'vibration': 3, 'temperature': 1}\n",
    "\n",
    "# 实例化模块\n",
    "embedding_layer = MfditEmbedding1d(NUM_PATCHES, PATCH_SIZE, CHANNEL_MAP, C_DIM, DIM)\n",
    "\n",
    "# --- 测试'vibration'信号 ---\n",
    "x_vib = torch.randn(B, L_variable, 3)\n",
    "sample_T_in = torch.randn(B, L_variable, 1)\n",
    "t_in, r_in = torch.rand(B), torch.rand(B)\n",
    "\n",
    "# 接收三个返回值\n",
    "x_tokens_vib, c_vib, indices_vib = embedding_layer(x_vib, 'vibration', sample_T_in, t_in, r_in)\n",
    "\n",
    "print(f\"输入 vibration (3通道), L={L_variable}\")\n",
    "print(f\"  -> 输出 tokens shape: {x_tokens_vib.shape}\")\n",
    "print(f\"  -> 输出 condition shape: {c_vib.shape}\")\n",
    "print(f\"  -> 输出 indices shape: {indices_vib.shape}\")\n",
    "assert x_tokens_vib.shape == (B, NUM_PATCHES, DIM)\n",
    "assert indices_vib.shape == (NUM_PATCHES,)\n",
    "print(\"  'vibration'信号处理成功!\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 测试'temperature'信号 ---\n",
    "x_temp = torch.randn(B, L_variable, 1)\n",
    "# 接收三个返回值\n",
    "x_tokens_temp, c_temp, indices_temp = embedding_layer(x_temp, 'temperature', sample_T_in, t_in, r_in)\n",
    "print(f\"输入 temperature (1通道), L={L_variable}\")\n",
    "print(f\"  -> 输出 tokens shape: {x_tokens_temp.shape}\")\n",
    "print(f\"  -> 输出 condition shape: {c_temp.shape}\")\n",
    "print(f\"  -> 输出 indices shape: {indices_temp.shape}\")\n",
    "assert x_tokens_temp.shape == (B, NUM_PATCHES, DIM)\n",
    "assert indices_temp.shape == (NUM_PATCHES,)\n",
    "print(\"  'temperature'信号处理成功!\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a1a208",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33df5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lq/.conda/envs/P/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Backbone Demo ---\n",
      "输入 Token 序列形状: torch.Size([4, 128, 768])\n",
      "输入条件向量 c 形状: torch.Size([4, 768])\n",
      "输出特征序列形状: torch.Size([4, 128, 768])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.vision_transformer import Mlp, Attention\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def modulate(x, scale, shift):\n",
    "\n",
    "    return x * (1 + scale.unsqueeze(1)) + shift.unsqueeze(1)\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = dim**0.5\n",
    "        self.g = nn.Parameter(torch.ones(1))\n",
    "    def forward(self, x):\n",
    "        return F.normalize(x, dim=-1) * self.scale * self.g\n",
    "\n",
    "class DiTBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = RMSNorm(dim)\n",
    "        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=True, qk_norm=True, norm_layer=RMSNorm)\n",
    "        self.attn.fused_attn = False\n",
    "        self.norm2 = RMSNorm(dim)\n",
    "        mlp_dim = int(dim * mlp_ratio)\n",
    "        approx_gelu = lambda: nn.GELU(approximate=\"tanh\")\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_dim, act_layer=approx_gelu, drop=0)\n",
    "        self.adaLN_modulation = nn.Sequential(nn.SiLU(), nn.Linear(dim, 6 * dim))\n",
    "    def forward(self, x, c):\n",
    "        shift_msa, scale_msa, gate_msa, shift_mlp, scale_mlp, gate_mlp = (self.adaLN_modulation(c).chunk(6, dim=-1))\n",
    "        x = x + gate_msa.unsqueeze(1) * self.attn(modulate(self.norm1(x), scale_msa, shift_msa))\n",
    "        x = x + gate_mlp.unsqueeze(1) * self.mlp(modulate(self.norm2(x), scale_mlp, shift_mlp))\n",
    "        return x\n",
    "\n",
    "# --- 主要的 1D Backbone 模块 (仅重命名) ---\n",
    "class MfditBackbone1d(nn.Module):\n",
    "    def __init__(self, dim=768, depth=12, num_heads=12, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            DiTBlock(dim, num_heads, mlp_ratio) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        for block in self.blocks:\n",
    "            x = block(x, c)\n",
    "        return x\n",
    "\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1D Backbone Demo ---\")\n",
    "    # 模型参数\n",
    "    B = 4\n",
    "    NUM_TOKENS = 2048 // 16 # L / patch_size\n",
    "    DIM = 768\n",
    "\n",
    "    # 创建 Backbone 模块实例\n",
    "    backbone_1d = MfditBackbone1d(dim=DIM, depth=12, num_heads=12)\n",
    "\n",
    "    # 创建模拟输入数据 (来自 1D Embedding 层的输出)\n",
    "    x_tokens_in = torch.randn(B, NUM_TOKENS, DIM)\n",
    "    c_vector_in = torch.randn(B, DIM)\n",
    "\n",
    "    # 前向传播\n",
    "    x_features = backbone_1d(x_tokens_in, c_vector_in)\n",
    "\n",
    "    # 打印输出形状\n",
    "    print(f\"输入 Token 序列形状: {x_tokens_in.shape}\")\n",
    "    print(f\"输入条件向量 c 形状: {c_vector_in.shape}\")\n",
    "    print(f\"输出特征序列形状: {x_features.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2189ff",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf7f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 模块三: 最终版 Task Head 独立测试 ---\n",
      "请求重建 'vibration' 信号 (3个通道)\n",
      "输入 features shape: torch.Size([4, 128, 768])\n",
      "重建后 output shape: torch.Size([4, 3000, 3])\n",
      "  'vibration' 信号重建成功!\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MfditTaskHead1d(nn.Module):\n",
    "    def __init__(self, num_patches, patch_size, channel_map, c_dim, dim):\n",
    "        super().__init__()\n",
    "        # 核心修改: 使用统一的补丁配置\n",
    "        self.patcher = SequencePatcher(num_patches, patch_size)\n",
    "        self.channel_map = channel_map\n",
    "        self.final_norm = RMSNorm(dim)\n",
    "        self.final_mod = nn.Sequential(nn.SiLU(), nn.Linear(dim, 2 * dim))\n",
    "        self.proj_out = nn.Linear(dim, patch_size * c_dim)\n",
    "        self.recon_heads = nn.ModuleDict({\n",
    "            name: nn.Sequential(nn.Linear(c_dim, c_dim * 2), nn.GELU(), nn.Linear(c_dim * 2, num_channels + 1))\n",
    "            for name, num_channels in channel_map.items()\n",
    "        })\n",
    "        \n",
    "    def forward(self, x_tokens, name, c, L_original, start_indices):\n",
    "        shift, scale = self.final_mod(c).chunk(2, dim=-1)\n",
    "        x = modulate(self.final_norm(x_tokens), shift, scale)\n",
    "        x = self.proj_out(x)\n",
    "        \n",
    "        patches_for_mlp = rearrange(x, 'b t (p c_dim) -> b t p c_dim', p=self.patcher.patch_size)\n",
    "        reconstructed_channels = self.recon_heads[name](patches_for_mlp)\n",
    "        patches_to_unpatch = rearrange(reconstructed_channels, 'b t p c -> b t c p')\n",
    "        \n",
    "        # 核心修改: 使用传入的 start_indices 进行重建\n",
    "        reconstructed_ts_with_time = self.patcher.unpatch(patches_to_unpatch, start_indices, L_original)\n",
    "        \n",
    "        num_original_channels = self.channel_map[name]\n",
    "        reconstructed_ts = reconstructed_ts_with_time[:, :, :num_original_channels]\n",
    "        \n",
    "        return reconstructed_ts\n",
    "# --- 模块三: 最终版 Task Head 独立测试 ---\n",
    "print(\"--- 模块三: 最终版 Task Head 独立测试 ---\")\n",
    "B, L_variable = 4, 3000\n",
    "# 统一的补丁配置\n",
    "NUM_PATCHES, PATCH_SIZE = 128, 16\n",
    "C_DIM, DIM = 16, 768\n",
    "\n",
    "CHANNEL_MAP_HEAD = {'vibration': 3, 'temperature': 1}\n",
    "task_head = MfditTaskHead1d(NUM_PATCHES, PATCH_SIZE, CHANNEL_MAP_HEAD, C_DIM, DIM)\n",
    "\n",
    "# --- 测试重建 'vibration' (3通道) 信号 ---\n",
    "output_name = 'vibration'\n",
    "C_out = CHANNEL_MAP_HEAD[output_name]\n",
    "print(f\"请求重建 '{output_name}' 信号 ({C_out}个通道)\")\n",
    "\n",
    "# 模拟输入\n",
    "features_in = torch.randn(B, NUM_PATCHES, DIM)\n",
    "c_vector_in = torch.randn(B, DIM)\n",
    "# 模拟从Embedding层得到的重建索引\n",
    "start_indices_in = torch.linspace(0, L_variable - PATCH_SIZE, steps=NUM_PATCHES).round().long()\n",
    "\n",
    "output_ts = task_head(features_in, output_name, c_vector_in, L_variable, start_indices_in)\n",
    "\n",
    "print(f\"输入 features shape: {features_in.shape}\")\n",
    "print(f\"重建后 output shape: {output_ts.shape}\")\n",
    "assert output_ts.shape == (B, L_variable, C_out)\n",
    "print(f\"  '{output_name}' 信号重建成功!\")\n",
    "print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02a461",
   "metadata": {},
   "source": [
    "# DOPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a0889",
   "metadata": {},
   "source": [
    "## 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688c8b1",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f90c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Embedding Demo ---\n",
      "输入形状: torch.Size([4, 64, 64, 6, 3])\n",
      "嵌入后特征形状: torch.Size([4, 32, 12, 12])\n",
      "计算出的均值形状: torch.Size([4, 1, 1, 1, 3])\n",
      "计算出的标准差形状: torch.Size([4, 1, 1, 1, 3])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Embedding (嵌入层) ---\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.fft\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ACTIVATION = {'gelu':nn.GELU(),'tanh':nn.Tanh(),'sigmoid':nn.Sigmoid(),'relu':nn.ReLU(),'leaky_relu':nn.LeakyReLU(0.1),'softplus':nn.Softplus(),'ELU':nn.ELU(),'silu':nn.SiLU()}\n",
    "\n",
    "import math\n",
    "import logging\n",
    "from torch.nn.modules.container import Sequential\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768, out_dim=128,act='gelu'):\n",
    "        super().__init__()\n",
    "        # img_size = to_2tuple(img_size)\n",
    "        # patch_size = to_2tuple(patch_size)\n",
    "        img_size = (img_size, img_size)\n",
    "        patch_size = (patch_size, patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        self.out_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])\n",
    "        self.out_dim = out_dim\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size),\n",
    "            self.act,\n",
    "            nn.Conv2d(embed_dim, out_dim, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        # x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class TimeAggregator(nn.Module):\n",
    "    def __init__(self, n_channels, n_timesteps, out_channels, type='mlp'):\n",
    "        super(TimeAggregator, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.out_channels = out_channels\n",
    "        self.type = type\n",
    "        if self.type == 'mlp':\n",
    "            self.w = nn.Parameter(1/(n_timesteps * out_channels**0.5) *torch.randn(n_timesteps, out_channels, out_channels),requires_grad=True)   # initialization could be tuned\n",
    "        elif self.type == 'exp_mlp':\n",
    "            self.w = nn.Parameter(1/(n_timesteps * out_channels**0.5) *torch.randn(n_timesteps, out_channels, out_channels),requires_grad=True)   # initialization could be tuned\n",
    "            self.gamma = nn.Parameter(2**torch.linspace(-10,10, out_channels).unsqueeze(0),requires_grad=True)  # 1, C\n",
    "    ##  B, X, Y, T, C\n",
    "    def forward(self, x):\n",
    "        if self.type == 'mlp':\n",
    "            x = torch.einsum('tij, ...ti->...j', self.w, x)\n",
    "        elif self.type == 'exp_mlp':\n",
    "            t = torch.linspace(0, 1, x.shape[-2]).unsqueeze(-1).to(x.device) # T, 1\n",
    "            t_embed = torch.cos(t @ self.gamma)\n",
    "            x = torch.einsum('tij,...ti->...j', self.w, x * t_embed)\n",
    "\n",
    "        return x\n",
    "\n",
    "class DPOTNetEmbedding(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_channels=1, out_channels=4, in_timesteps=1, embed_dim=768,\n",
    "                 act='gelu', time_agg='exp_mlp', normalize=False):\n",
    "        \"\"\"\n",
    "        初始化嵌入层。\n",
    "        :param img_size: 输入图像的尺寸。\n",
    "        :param patch_size: 每个分块的尺寸。\n",
    "        :param in_channels: 输入数据的通道数。\n",
    "        :param out_channels: 输出数据的通道数。\n",
    "        :param in_timesteps: 输入数据的时间步长。\n",
    "        :param embed_dim: 嵌入向量的维度。\n",
    "        :param act: 激活函数类型。\n",
    "        :param time_agg: 时间聚合层类型。\n",
    "        :param normalize: 是否进行数据规范化。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.in_channels = in_channels\n",
    "        # 初始化分块嵌入模块\n",
    "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_channels + 3,\n",
    "                                      embed_dim=out_channels * patch_size + 3, out_dim=embed_dim, act=act)\n",
    "        # 初始化可学习的位置编码\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.zeros(1, embed_dim, self.patch_embed.out_size[0], self.patch_embed.out_size[1]))\n",
    "        # 如果启用规范化，则初始化用于学习缩放参数的线性层\n",
    "        if self.normalize:\n",
    "            self.scale_feats_mu = nn.Linear(2 * in_channels, embed_dim)\n",
    "            self.scale_feats_sigma = nn.Linear(2 * in_channels, embed_dim)\n",
    "        # 初始化时间聚合层\n",
    "        self.time_agg_layer = TimeAggregator(in_channels, in_timesteps, embed_dim, time_agg)\n",
    "        # 使用截断正态分布初始化位置编码\n",
    "        torch.nn.init.trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "    def get_grid_3d(self, x):\n",
    "        \"\"\"生成3D坐标网格\"\"\"\n",
    "        batchsize, size_x, size_y, size_z = x.shape[0], x.shape[1], x.shape[2], x.shape[3]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1, 1).to(x.device).repeat([batchsize, 1, size_y, size_z, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1, 1).to(x.device).repeat([batchsize, size_x, 1, size_z, 1])\n",
    "        gridz = torch.tensor(np.linspace(0, 1, size_z), dtype=torch.float)\n",
    "        gridz = gridz.reshape(1, 1, 1, size_z, 1).to(x.device).repeat([batchsize, size_x, size_y, 1, 1])\n",
    "        grid = torch.cat((gridx, gridy, gridz), dim=-1)\n",
    "        return grid\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "        输入 x 的形状: (B, H, W, T, C)\n",
    "        \"\"\"\n",
    "        B, H, W, T, C = x.shape\n",
    "        mu, sigma = None, None\n",
    "        \n",
    "        # 1. (可选) 规范化\n",
    "        if self.normalize:\n",
    "            mu, sigma = x.mean(dim=(1, 2, 3), keepdim=True), x.std(dim=(1, 2, 3), keepdim=True) + 1e-6\n",
    "            x = (x - mu) / sigma\n",
    "            # 学习用于仿射变换的参数，实现类似AdaIN的功能\n",
    "            scale_mu = self.scale_feats_mu(torch.cat([mu, sigma], dim=-1)).squeeze(-2).permute(0, 3, 1, 2)\n",
    "            scale_sigma = self.scale_feats_sigma(torch.cat([mu, sigma], dim=-1)).squeeze(-2).permute(0, 3, 1, 2)\n",
    "\n",
    "        # 2. 添加坐标网格信息\n",
    "        grid = self.get_grid_3d(x)\n",
    "        x = torch.cat((x, grid), dim=-1).contiguous()  # (B, H, W, T, C+3)\n",
    "        \n",
    "        # 调整维度以适应卷积操作\n",
    "        x = rearrange(x, 'b x y t c -> (b t) c x y')\n",
    "        \n",
    "        # 3. 分块与投影\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        # 4. 添加位置编码\n",
    "        x = x + self.pos_embed\n",
    "        \n",
    "        # 调整维度以进行时间聚合\n",
    "        x = rearrange(x, '(b t) c x y -> b x y t c', b=B, t=T)\n",
    "        \n",
    "        # 5. 时间聚合\n",
    "        x = self.time_agg_layer(x)\n",
    "        \n",
    "        # 调整为骨干网络期望的输入形状\n",
    "        x = rearrange(x, 'b x y c -> b c x y')\n",
    "        \n",
    "        # (可选) 应用学习到的仿射变换\n",
    "        if self.normalize:\n",
    "            x = scale_sigma * x + scale_mu\n",
    "            \n",
    "        return x, mu, sigma\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Embedding Demo ---\")\n",
    "    \n",
    "    # --- 模型参数 ---\n",
    "    IMG_SIZE = 64       # 图像尺寸\n",
    "    PATCH_SIZE = 5      # 分块大小\n",
    "    IN_CHANNELS = 3     # 输入通道数\n",
    "    OUT_CHANNELS = 3    # 输出通道数\n",
    "    IN_TIMESTEPS = 6    # 输入时间步\n",
    "    EMBED_DIM = 32      # 嵌入维度\n",
    "    B = 4               # 批量大小\n",
    "\n",
    "    # --- 创建 Embedding 模块实例 ---\n",
    "    embedding_layer = DPOTNetEmbedding(\n",
    "        img_size=IMG_SIZE,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        in_channels=IN_CHANNELS,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        in_timesteps=IN_TIMESTEPS,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        normalize=True  # 启用规范化\n",
    "    )\n",
    "\n",
    "    # --- 创建模拟输入数据 ---\n",
    "    # 输入形状: (批量, 高, 宽, 时间步, 通道)\n",
    "    x_in_embed = torch.randn(B, IMG_SIZE, IMG_SIZE, IN_TIMESTEPS, IN_CHANNELS)\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    embedded_x, mu, sigma = embedding_layer(x_in_embed)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入形状: {x_in_embed.shape}\")\n",
    "    # 预期输出形状: (批量, 嵌入维度, 高/分块大小, 宽/分块大小)\n",
    "    print(f\"嵌入后特征形状: {embedded_x.shape}\")\n",
    "    print(f\"计算出的均值形状: {mu.shape}\")\n",
    "    print(f\"计算出的标准差形状: {sigma.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8703baad",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5098213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Backbone Demo ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EMBED_DIM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 91\u001b[0m\n\u001b[1;32m     87\u001b[0m DEPTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# 骨干网络深度\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# --- 创建 Backbone 模块实例 ---\u001b[39;00m\n\u001b[1;32m     90\u001b[0m backbone_layer \u001b[38;5;241m=\u001b[39m DPOTNetBackbone(\n\u001b[0;32m---> 91\u001b[0m     embed_dim\u001b[38;5;241m=\u001b[39m\u001b[43mEMBED_DIM\u001b[49m,\n\u001b[1;32m     92\u001b[0m     depth\u001b[38;5;241m=\u001b[39mDEPTH,\n\u001b[1;32m     93\u001b[0m     img_size\u001b[38;5;241m=\u001b[39mIMG_SIZE,\n\u001b[1;32m     94\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39mPATCH_SIZE\n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# --- 前向传播 ---\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# 使用上一阶段的输出 `embedded_x` 作为输入\u001b[39;00m\n\u001b[1;32m     99\u001b[0m features \u001b[38;5;241m=\u001b[39m backbone_layer(embedded_x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EMBED_DIM' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Backbone (骨干网络) ---\n",
    "\n",
    "class AFNO2D(nn.Module):\n",
    "    \"\"\"\n",
    "    hidden_size: channel dimension size\n",
    "    num_blocks: how many blocks to use in the block diagonal weight matrices (higher => less complexity but less parameters)\n",
    "    \"\"\"\n",
    "    def __init__(self, width = 32, num_blocks=8, channel_first = False,sparsity_threshold=0.01, modes = 32,hard_thresholding_fraction=1, hidden_size_factor=1, act='gelu'):\n",
    "        super().__init__()\n",
    "        assert width % num_blocks == 0, f\"hidden_size {width} should be divisble by num_blocks {num_blocks}\"\n",
    "\n",
    "\n",
    "\n",
    "        self.hidden_size = width\n",
    "        self.sparsity_threshold = sparsity_threshold\n",
    "        self.num_blocks = num_blocks\n",
    "        self.block_size = self.hidden_size // self.num_blocks\n",
    "        self.channel_first = channel_first\n",
    "        self.modes = modes\n",
    "        self.hidden_size_factor = hidden_size_factor\n",
    "        # self.scale = 0.02\n",
    "        self.scale = 1 / (self.block_size * self.block_size * self.hidden_size_factor)\n",
    "\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        self.w1 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size, self.block_size * self.hidden_size_factor))\n",
    "        self.b1 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size * self.hidden_size_factor))\n",
    "        self.w2 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size * self.hidden_size_factor, self.block_size))\n",
    "        self.b2 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size))\n",
    "\n",
    "    ### N, C, X, Y\n",
    "    def forward(self, x, spatial_size=None):\n",
    "        if self.channel_first:\n",
    "            B, C, H, W = x.shape\n",
    "            x = x.permute(0, 2, 3, 1)  ### ->N, X, Y, C\n",
    "        else:\n",
    "            B, H, W, C = x.shape\n",
    "        x_orig = x\n",
    "\n",
    "        x = torch.fft.rfft2(x, dim=(1, 2), norm=\"ortho\")\n",
    "        # x = torch.fft.rfft2(x, dim=(1, 2))\n",
    "\n",
    "        x = x.reshape(B, x.shape[1], x.shape[2], self.num_blocks, self.block_size)\n",
    "\n",
    "        o1_real = torch.zeros([B, x.shape[1], x.shape[2], self.num_blocks, self.block_size * self.hidden_size_factor], device=x.device)\n",
    "        o1_imag = torch.zeros([B, x.shape[1], x.shape[2], self.num_blocks, self.block_size * self.hidden_size_factor], device=x.device)\n",
    "        o2_real = torch.zeros(x.shape, device=x.device)\n",
    "        o2_imag = torch.zeros(x.shape, device=x.device)\n",
    "\n",
    "        # total_modes = H*W // 2 + 1\n",
    "        kept_modes = self.modes\n",
    "\n",
    "        o1_real[:, :kept_modes, :kept_modes] = self.act(\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes, :kept_modes].real, self.w1[0]) - \\\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes, :kept_modes].imag, self.w1[1]) + \\\n",
    "            self.b1[0]\n",
    "        )\n",
    "\n",
    "        o1_imag[:, :kept_modes, :kept_modes] = self.act(\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes, :kept_modes].imag, self.w1[0]) + \\\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes, :kept_modes].real, self.w1[1]) + \\\n",
    "            self.b1[1]\n",
    "        )\n",
    "\n",
    "        o2_real[:, :kept_modes, :kept_modes] = (\n",
    "            torch.einsum('...bi,bio->...bo', o1_real[:, :kept_modes, :kept_modes], self.w2[0]) - \\\n",
    "            torch.einsum('...bi,bio->...bo', o1_imag[:, :kept_modes, :kept_modes], self.w2[1]) + \\\n",
    "            self.b2[0]\n",
    "        )\n",
    "\n",
    "        o2_imag[:, :kept_modes, :kept_modes] = (\n",
    "            torch.einsum('...bi,bio->...bo', o1_imag[:, :kept_modes, :kept_modes], self.w2[0]) + \\\n",
    "            torch.einsum('...bi,bio->...bo', o1_real[:, :kept_modes, :kept_modes], self.w2[1]) + \\\n",
    "            self.b2[1]\n",
    "        )\n",
    "\n",
    "        x = torch.stack([o2_real, o2_imag], dim=-1)\n",
    "        ## for ab study\n",
    "        # x = F.softshrink(x, lambd=self.sparsity_threshold)\n",
    "\n",
    "        x = torch.view_as_complex(x)\n",
    "        x = x.reshape(B, x.shape[1], x.shape[2], C)\n",
    "        x = torch.fft.irfft2(x, s=(H, W), dim=(1, 2), norm=\"ortho\")\n",
    "\n",
    "\n",
    "\n",
    "        x = x + x_orig\n",
    "        if self.channel_first:\n",
    "            x = x.permute(0, 3, 1, 2)     ### N, C, X, Y\n",
    "\n",
    "        return x\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, mixing_type = 'afno', double_skip = True, width = 32, n_blocks = 4, mlp_ratio=1., channel_first = True, modes = 32, drop=0., drop_path=0., act='gelu', h=14, w=8,):\n",
    "        super().__init__()\n",
    "        # self.norm1 = norm_layer(width)\n",
    "        # self.norm1 = torch.nn.LayerNorm([width])\n",
    "        self.norm1 = torch.nn.GroupNorm(8, width)\n",
    "        # self.norm1 = torch.nn.InstanceNorm2d(width,affine=True,track_running_stats=False)\n",
    "        self.width = width\n",
    "        self.modes = modes\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        if mixing_type == \"afno\":\n",
    "            self.filter = AFNO2D(width = width, num_blocks=n_blocks, sparsity_threshold=0.01, channel_first = channel_first, modes = modes,\n",
    "                                 hard_thresholding_fraction=1, hidden_size_factor=1, act=act)\n",
    "\n",
    "        self.norm2 = torch.nn.GroupNorm(8, width)\n",
    "\n",
    "\n",
    "\n",
    "        mlp_hidden_dim = int(width * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=width, out_channels=mlp_hidden_dim, kernel_size=1, stride=1),\n",
    "            self.act,\n",
    "            nn.Conv2d(in_channels=mlp_hidden_dim, out_channels=width, kernel_size=1, stride=1),\n",
    "        )\n",
    "\n",
    "        self.double_skip = double_skip\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.filter(x)\n",
    "\n",
    "\n",
    "        if self.double_skip:\n",
    "            x = x + residual\n",
    "            residual = x\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        return x\n",
    "    \n",
    "class DPOTNetBackbone(nn.Module):\n",
    "    def __init__(self, embed_dim=768, depth=12, mixing_type='afno', modes=32, mlp_ratio=1., n_blocks=4, act='gelu',\n",
    "                 img_size=224, patch_size=16):\n",
    "        \"\"\"\n",
    "        初始化骨干网络。\n",
    "        :param embed_dim: 嵌入维度。\n",
    "        :param depth: 骨干网络的层数（Block的数量）。\n",
    "        :param mixing_type: 混合器类型, 此处为 'afno'。\n",
    "        :param modes: 傅里叶变换中保留的模式数。\n",
    "        :param mlp_ratio: MLP层的隐藏维度与嵌入维度的比率。\n",
    "        :param n_blocks: AFNO中块对角矩阵的数量。\n",
    "        :param act: 激活函数类型。\n",
    "        :param img_size: 输入图像尺寸。\n",
    "        :param patch_size: 分块尺寸。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 计算AFNO层需要的空间频率维度\n",
    "        h = img_size // patch_size\n",
    "        w = h // 2 + 1\n",
    "        # 创建一个由多个Block组成的模块列表\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(mixing_type=mixing_type, modes=modes,\n",
    "                  width=embed_dim, mlp_ratio=mlp_ratio, channel_first=True, n_blocks=n_blocks, double_skip=False,\n",
    "                  h=h, w=w, act=act)\n",
    "            for _ in range(depth)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "        输入 x 的形状: (B, C, H', W')\n",
    "        \"\"\"\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        return x\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    # (接上一个Demo)\n",
    "    print(\"--- Backbone Demo ---\")\n",
    "    \n",
    "    # --- 模型参数 ---\n",
    "    DEPTH = 4  # 骨干网络深度\n",
    "\n",
    "    # --- 创建 Backbone 模块实例 ---\n",
    "    backbone_layer = DPOTNetBackbone(\n",
    "        embed_dim=EMBED_DIM,\n",
    "        depth=DEPTH,\n",
    "        img_size=IMG_SIZE,\n",
    "        patch_size=PATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    # 使用上一阶段的输出 `embedded_x` 作为输入\n",
    "    features = backbone_layer(embedded_x)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入特征形状: {embedded_x.shape}\")\n",
    "    # 骨干网络不改变特征图的形状\n",
    "    print(f\"输出特征形状: {features.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4acbe",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1562fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task Head (任务头) ---\n",
    "class DPOTNetTaskHead(nn.Module):\n",
    "    def __init__(self, embed_dim=768, out_channels=4, out_timesteps=1, n_cls=12, out_layer_dim=32, patch_size=16,\n",
    "                 act='gelu', normalize=False):\n",
    "        \"\"\"\n",
    "        初始化任务头。\n",
    "        :param embed_dim: 嵌入维度。\n",
    "        :param out_channels: 最终输出的通道数。\n",
    "        :param out_timesteps: 最终输出的时间步长。\n",
    "        :param n_cls: 分类任务的类别数。\n",
    "        :param out_layer_dim: 输出层中间卷积的维度。\n",
    "        :param patch_size: 分块大小，用于转置卷积。\n",
    "        :param act: 激活函数类型。\n",
    "        :param normalize: 是否需要进行反规范化。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.out_timesteps = out_timesteps\n",
    "        self.normalize = normalize\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        # 分类头\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            self.act,\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            self.act,\n",
    "            nn.Linear(embed_dim, n_cls)\n",
    "        )\n",
    "        \n",
    "        # 输出生成层\n",
    "        self.out_layer = nn.Sequential(\n",
    "            # 转置卷积，用于上采样恢复分辨率\n",
    "            nn.ConvTranspose2d(in_channels=embed_dim, out_channels=out_layer_dim, kernel_size=patch_size,\n",
    "                               stride=patch_size),\n",
    "            self.act,\n",
    "            nn.Conv2d(in_channels=out_layer_dim, out_channels=out_layer_dim, kernel_size=1, stride=1),\n",
    "            self.act,\n",
    "            nn.Conv2d(in_channels=out_layer_dim, out_channels=self.out_channels * self.out_timesteps,\n",
    "                      kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu=None, sigma=None):\n",
    "        \"\"\"\n",
    "        前向传播函数。\n",
    "        输入 x 的形状: (B, C, H', W')\n",
    "        \"\"\"\n",
    "        # 1. 分类任务\n",
    "        # 全局平均池化\n",
    "        cls_token = x.mean(dim=(2, 3), keepdim=False)\n",
    "        cls_pred = self.cls_head(cls_token)\n",
    "        \n",
    "        # 2. 生成任务\n",
    "        x = self.out_layer(x).permute(0, 2, 3, 1)\n",
    "        \n",
    "        # 调整形状以匹配 (B, H, W, T_out, C_out)\n",
    "        x = x.reshape(*x.shape[:3], self.out_timesteps, self.out_channels).contiguous()\n",
    "        \n",
    "        # (可选) 反规范化\n",
    "        if self.normalize and mu is not None and sigma is not None:\n",
    "            x = x * sigma + mu\n",
    "            \n",
    "        return x, cls_pred\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    # (接上一个Demo)\n",
    "    print(\"--- Task Head Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    OUT_TIMESTEPS = 1   # 输出时间步\n",
    "    N_CLS = 10          # 分类类别数\n",
    "\n",
    "    # --- 创建 Task Head 模块实例 ---\n",
    "    task_head_layer = DPOTNetTaskHead(\n",
    "        embed_dim=EMBED_DIM,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        out_timesteps=OUT_TIMESTEPS,\n",
    "        n_cls=N_CLS,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        normalize=True # 启用反规范化\n",
    "    )\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    # 使用Backbone的输出 `features` 和 Embedding的 `mu`, `sigma` 作为输入\n",
    "    output, cls_pred = task_head_layer(features, mu, sigma)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入特征形状: {features.shape}\")\n",
    "    # 预期输出形状: (批量, 高, 宽, 输出时间步, 输出通道)\n",
    "    print(f\"最终生成输出形状: {output.shape}\")\n",
    "    # 预期分类输出形状: (批量, 类别数)\n",
    "    print(f\"分类预测形状: {cls_pred.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6376c55",
   "metadata": {},
   "source": [
    "### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOTNet(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, mixing_type='afno', in_channels=1, out_channels=4,\n",
    "                 in_timesteps=1, out_timesteps=1, n_blocks=4, embed_dim=768, out_layer_dim=32, depth=12,\n",
    "                 modes=32, mlp_ratio=1., n_cls=12, normalize=False, act='gelu', time_agg='exp_mlp'):\n",
    "        super(DPOTNet, self).__init__()\n",
    "        # 实例化嵌入层\n",
    "        self.embedding = DPOTNetEmbedding(img_size=img_size, patch_size=patch_size, in_channels=in_channels,\n",
    "                                          out_channels=out_channels, in_timesteps=in_timesteps, embed_dim=embed_dim,\n",
    "                                          act=act, time_agg=time_agg, normalize=normalize)\n",
    "        # 实例化骨干网络\n",
    "        self.backbone = DPOTNetBackbone(embed_dim=embed_dim, depth=depth, mixing_type=mixing_type, modes=modes,\n",
    "                                        mlp_ratio=mlp_ratio, n_blocks=n_blocks, act=act, img_size=img_size,\n",
    "                                        patch_size=patch_size)\n",
    "        # 实例化任务头\n",
    "        self.task_head = DPOTNetTaskHead(embed_dim=embed_dim, out_channels=out_channels,\n",
    "                                         out_timesteps=out_timesteps, n_cls=n_cls,\n",
    "                                         out_layer_dim=out_layer_dim, patch_size=patch_size, act=act,\n",
    "                                         normalize=normalize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 依次通过三个模块\n",
    "        x, mu, sigma = self.embedding(x)\n",
    "        x = self.backbone(x)\n",
    "        x, cls_pred = self.task_head(x, mu, sigma)\n",
    "        return x, cls_pred\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 完整模型 Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    IMG_SIZE = 20\n",
    "    PATCH_SIZE = 5\n",
    "    IN_CHANNELS = 3\n",
    "    OUT_CHANNELS = 3\n",
    "    IN_TIMESTEPS = 6\n",
    "    OUT_TIMESTEPS = 1\n",
    "    EMBED_DIM = 32\n",
    "    DEPTH = 4\n",
    "    N_CLS = 10\n",
    "    B = 4\n",
    "\n",
    "    # --- 创建完整DPOTNet实例 ---\n",
    "    net = DPOTNet(\n",
    "        img_size=IMG_SIZE,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        in_channels=IN_CHANNELS,\n",
    "        out_channels=OUT_CHANNELS,\n",
    "        in_timesteps=IN_TIMESTEPS,\n",
    "        out_timesteps=OUT_TIMESTEPS,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        depth=DEPTH,\n",
    "        n_cls=N_CLS,\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # --- 创建模拟输入数据 ---\n",
    "    x_in = torch.randn(B, IMG_SIZE, IMG_SIZE, IN_TIMESTEPS, IN_CHANNELS)\n",
    "    \n",
    "    # --- 前向传播 ---\n",
    "    y, _ = net(x_in)\n",
    "    \n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入形状: {x_in.shape}\")\n",
    "    print(f\"最终输出形状: {y.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41765673",
   "metadata": {},
   "source": [
    "## 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806e68e",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "115a8205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Embedding Demo ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入序列形状 (B, L, C): torch.Size([4, 1024, 3])\n",
      "嵌入后特征形状 (B, embed_dim, num_patches): torch.Size([4, 64, 64])\n",
      "计算出的均值形状: torch.Size([4, 1, 3])\n",
      "计算出的标准差形状: torch.Size([4, 1, 3])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.fft\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "# 激活函数字典\n",
    "ACTIVATION = {\n",
    "    'gelu': nn.GELU(), 'tanh': nn.Tanh(), 'sigmoid': nn.Sigmoid(), \n",
    "    'relu': nn.ReLU(), 'leaky_relu': nn.LeakyReLU(0.1), \n",
    "    'softplus': nn.Softplus(), 'ELU': nn.ELU(), 'silu': nn.SiLU()\n",
    "}\n",
    "\n",
    "class PatchEmbed1D(nn.Module):\n",
    "    \"\"\"\n",
    "    将1D序列分块并进行线性嵌入的模块。\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len=1024, patch_len=16, in_chans=3, embed_dim=768, out_dim=128, act='gelu'):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.patch_len = patch_len\n",
    "        self.in_chans = in_chans\n",
    "        self.out_dim = out_dim\n",
    "        self.num_patches = seq_len // patch_len\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        # 使用1D卷积实现分块和嵌入\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv1d(in_chans, embed_dim, kernel_size=patch_len, stride=patch_len),\n",
    "            self.act,\n",
    "            nn.Conv1d(embed_dim, out_dim, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 形状: (B, C, L)\n",
    "        B, C, L = x.shape\n",
    "        assert L == self.seq_len, f\"Input sequence length ({L}) doesn't match model ({self.seq_len}).\"\n",
    "        # 输出 x 形状: (B, out_dim, num_patches)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class DPOTNetEmbedding1D(nn.Module):\n",
    "    \"\"\"\n",
    "    DPOTNet 的1D版本嵌入层。\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len=1024, patch_len=16, in_channels=1, embed_dim=768, act='gelu', normalize=False):\n",
    "        super().__init__()\n",
    "        self.normalize = normalize\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # 使用1D分块嵌入模块\n",
    "        self.patch_embed = PatchEmbed1D(seq_len=seq_len, patch_len=patch_len, in_chans=in_channels + 1,\n",
    "                                        embed_dim=embed_dim, out_dim=embed_dim, act=act)\n",
    "        \n",
    "        # 1D位置编码，对应每个patch\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, embed_dim, self.patch_embed.num_patches))\n",
    "        \n",
    "        if self.normalize:\n",
    "            self.scale_feats_mu = nn.Linear(2 * in_channels, embed_dim)\n",
    "            self.scale_feats_sigma = nn.Linear(2 * in_channels, embed_dim)\n",
    "            \n",
    "        torch.nn.init.trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "    def get_grid_1d(self, x):\n",
    "        \"\"\"生成1D坐标网格\"\"\"\n",
    "        batchsize, seq_len, n_feats = x.shape\n",
    "        grid = torch.linspace(0, 1, seq_len, dtype=torch.float, device=x.device)\n",
    "        grid = grid.reshape(1, seq_len, 1).repeat(batchsize, 1, 1)\n",
    "        return grid\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 形状: (B, L, C)\n",
    "        B, L, C = x.shape\n",
    "        mu, sigma = None, None\n",
    "        \n",
    "        if self.normalize:\n",
    "            mu, sigma = x.mean(dim=1, keepdim=True), x.std(dim=1, keepdim=True) + 1e-6\n",
    "            x = (x - mu) / sigma\n",
    "            # 调整mu和sigma的形状以用于线性层\n",
    "            scale_mu = self.scale_feats_mu(torch.cat([mu, sigma], dim=-1).squeeze(1)) # -> B, embed_dim\n",
    "            scale_sigma = self.scale_feats_sigma(torch.cat([mu, sigma], dim=-1).squeeze(1)) # -> B, embed_dim\n",
    "\n",
    "        # 添加位置坐标\n",
    "        grid = self.get_grid_1d(x)\n",
    "        x = torch.cat((x, grid), dim=-1) # (B, L, C+1)\n",
    "        \n",
    "        # 调整维度以适应1D卷积: (B, C, L)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # 分块与投影\n",
    "        x = self.patch_embed(x) # (B, embed_dim, num_patches)\n",
    "        \n",
    "        # 添加位置编码\n",
    "        x = x + self.pos_embed\n",
    "        \n",
    "        if self.normalize:\n",
    "            # 调整 scale_mu/sigma 的形状以匹配 x\n",
    "            x = scale_sigma.unsqueeze(-1) * x + scale_mu.unsqueeze(-1)\n",
    "            \n",
    "        return x, mu, sigma\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1D Embedding Demo ---\")\n",
    "    \n",
    "    # --- 模型参数 ---\n",
    "    SEQ_LEN = 1024      # 输入序列长度\n",
    "    PATCH_LEN = 16      # 分块长度\n",
    "    IN_CHANNELS = 3     # 输入特征/通道数\n",
    "    EMBED_DIM = 64      # 嵌入维度\n",
    "    B = 4               # 批量大小\n",
    "\n",
    "    # --- 创建 1D Embedding 模块实例 ---\n",
    "    embedding_layer_1d = DPOTNetEmbedding1D(\n",
    "        seq_len=SEQ_LEN,\n",
    "        patch_len=PATCH_LEN,\n",
    "        in_channels=IN_CHANNELS,\n",
    "        embed_dim=EMBED_DIM,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    # --- 创建模拟输入数据 ---\n",
    "    # 输入形状: (批量, 序列长度, 特征数)\n",
    "    x_in_1d = torch.randn(B, SEQ_LEN, IN_CHANNELS)\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    embedded_x_1d, mu, sigma = embedding_layer_1d(x_in_1d)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入序列形状 (B, L, C): {x_in_1d.shape}\")\n",
    "    print(f\"嵌入后特征形状 (B, embed_dim, num_patches): {embedded_x_1d.shape}\")\n",
    "    print(f\"计算出的均值形状: {mu.shape}\")\n",
    "    print(f\"计算出的标准差形状: {sigma.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a60990",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa94e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Backbone Demo ---\n",
      "输入特征形状 (B, embed_dim, num_patches): torch.Size([4, 64, 64])\n",
      "输出特征形状 (B, embed_dim, num_patches): torch.Size([4, 64, 64])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.fft\n",
    "\n",
    "class AFNO1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D版本的AFNO，用于处理序列数据。\n",
    "    \"\"\"\n",
    "    def __init__(self, width=64, num_blocks=8, modes=16, hidden_size_factor=2, act='gelu'):\n",
    "        super().__init__()\n",
    "        assert width % num_blocks == 0, f\"hidden_size {width} should be divisible by num_blocks {num_blocks}\"\n",
    "\n",
    "        self.hidden_size = width\n",
    "        self.num_blocks = num_blocks\n",
    "        self.block_size = self.hidden_size // self.num_blocks\n",
    "        self.modes = modes\n",
    "        self.hidden_size_factor = hidden_size_factor\n",
    "        self.scale = 1 / (self.block_size * self.block_size * self.hidden_size_factor)\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        self.w1 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size, self.block_size * self.hidden_size_factor))\n",
    "        self.b1 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size * self.hidden_size_factor))\n",
    "        self.w2 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size * self.hidden_size_factor, self.block_size))\n",
    "        self.b2 = nn.Parameter(self.scale * torch.rand(2, self.num_blocks, self.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入 x 形状: (B, C, num_patches)\n",
    "        B, C, N = x.shape\n",
    "        x = x.permute(0, 2, 1) # (B, num_patches, C)\n",
    "        x_orig = x\n",
    "\n",
    "        # 1D 傅里叶变换\n",
    "        x = torch.fft.rfft(x, dim=1, norm=\"ortho\")\n",
    "        x = x.reshape(B, x.shape[1], self.num_blocks, self.block_size)\n",
    "\n",
    "        o1_real = torch.zeros([B, x.shape[1], self.num_blocks, self.block_size * self.hidden_size_factor], device=x.device)\n",
    "        o1_imag = torch.zeros([B, x.shape[1], self.num_blocks, self.block_size * self.hidden_size_factor], device=x.device)\n",
    "        o2_real = torch.zeros(x.shape, device=x.device)\n",
    "        o2_imag = torch.zeros(x.shape, device=x.device)\n",
    "\n",
    "        kept_modes = self.modes\n",
    "        o1_real[:, :kept_modes] = self.act(\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes].real, self.w1[0]) - \\\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes].imag, self.w1[1]) + \\\n",
    "            self.b1[0]\n",
    "        )\n",
    "        o1_imag[:, :kept_modes] = self.act(\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes].imag, self.w1[0]) + \\\n",
    "            torch.einsum('...bi,bio->...bo', x[:, :kept_modes].real, self.w1[1]) + \\\n",
    "            self.b1[1]\n",
    "        )\n",
    "        o2_real[:, :kept_modes] = (\n",
    "            torch.einsum('...bi,bio->...bo', o1_real[:, :kept_modes], self.w2[0]) - \\\n",
    "            torch.einsum('...bi,bio->...bo', o1_imag[:, :kept_modes], self.w2[1]) + \\\n",
    "            self.b2[0]\n",
    "        )\n",
    "        o2_imag[:, :kept_modes] = (\n",
    "            torch.einsum('...bi,bio->...bo', o1_imag[:, :kept_modes], self.w2[0]) + \\\n",
    "            torch.einsum('...bi,bio->...bo', o1_real[:, :kept_modes], self.w2[1]) + \\\n",
    "            self.b2[1]\n",
    "        )\n",
    "\n",
    "        x = torch.stack([o2_real, o2_imag], dim=-1)\n",
    "        x = torch.view_as_complex(x)\n",
    "        x = x.reshape(B, x.shape[1], C)\n",
    "        \n",
    "        # 1D 逆傅里叶变换\n",
    "        x = torch.fft.irfft(x, n=N, dim=1, norm=\"ortho\")\n",
    "        \n",
    "        x = x + x_orig\n",
    "        x = x.permute(0, 2, 1) # (B, C, num_patches)\n",
    "        return x\n",
    "\n",
    "class Block1D(nn.Module):\n",
    "    \"\"\"\n",
    "    1D版本的Block模块。\n",
    "    \"\"\"\n",
    "    def __init__(self, width=64, mlp_ratio=4., n_blocks=8, modes=16, act='gelu'):\n",
    "        super().__init__()\n",
    "        self.norm1 = torch.nn.GroupNorm(n_blocks, width)\n",
    "        self.filter = AFNO1D(width=width, num_blocks=n_blocks, modes=modes, act=act)\n",
    "        self.norm2 = torch.nn.GroupNorm(n_blocks, width)\n",
    "        \n",
    "        mlp_hidden_dim = int(width * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv1d(width, mlp_hidden_dim, 1),\n",
    "            ACTIVATION[act],\n",
    "            nn.Conv1d(mlp_hidden_dim, width, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.filter(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = x + residual\n",
    "        \n",
    "        return x\n",
    "\n",
    "class DPOTNetBackbone1D(nn.Module):\n",
    "    \"\"\"\n",
    "    DPOTNet 的1D版本骨干网络。\n",
    "    \"\"\"\n",
    "    def __init__(self, width=64, depth=4, mlp_ratio=4., n_blocks=8, modes=16, act='gelu'):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block1D(width=width, mlp_ratio=mlp_ratio, n_blocks=n_blocks, modes=modes, act=act)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        return x\n",
    "# --- Demo 代码 (续) ---\n",
    "if __name__ == '__main__':\n",
    "    # (前面是1D Embedding Demo)\n",
    "    print(\"--- 1D Backbone Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    DEPTH = 4  # 骨干网络深度\n",
    "    \n",
    "    # --- 创建 1D Backbone 模块实例 ---\n",
    "    backbone_layer_1d = DPOTNetBackbone1D(\n",
    "        width=EMBED_DIM,\n",
    "        depth=DEPTH,\n",
    "        modes=EMBED_DIM // 4 # 通常modes设为嵌入维度的一个分数\n",
    "    )\n",
    "    \n",
    "    # --- 前向传播 ---\n",
    "    # 使用上一阶段的输出 `embedded_x_1d` 作为输入\n",
    "    features_1d = backbone_layer_1d(embedded_x_1d)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入特征形状 (B, embed_dim, num_patches): {embedded_x_1d.shape}\")\n",
    "    # Backbone不改变特征序列的形状\n",
    "    print(f\"输出特征形状 (B, embed_dim, num_patches): {features_1d.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db7774",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9ec5297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1D Task Head Demo ---\n",
      "输入特征形状 (B, embed_dim, num_patches): torch.Size([4, 64, 64])\n",
      "最终生成序列形状 (B, L, C): torch.Size([4, 1024, 3])\n",
      "分类预测形状 (B, n_cls): torch.Size([4, 10])\n",
      "--------------------\n",
      "--- 1D Full Model Demo ---\n",
      "端到端输入形状: torch.Size([4, 1024, 3])\n",
      "端到端输出形状: torch.Size([4, 1024, 3])\n",
      "端到端分类形状: torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "class DPOTNetTaskHead1D(nn.Module):\n",
    "    \"\"\"\n",
    "    DPOTNet 的1D版本任务头。\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=64, out_channels=3, n_cls=10, patch_len=16, act='gelu', normalize=False):\n",
    "        super().__init__()\n",
    "        self.out_channels = out_channels\n",
    "        self.normalize = normalize\n",
    "        self.act = ACTIVATION[act]\n",
    "\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            self.act,\n",
    "            nn.Linear(embed_dim, n_cls)\n",
    "        )\n",
    "        \n",
    "        # 1D 输出层\n",
    "        self.out_layer = nn.Sequential(\n",
    "            # 1D转置卷积，用于上采样恢复序列长度\n",
    "            nn.ConvTranspose1d(embed_dim, embed_dim, kernel_size=patch_len, stride=patch_len),\n",
    "            self.act,\n",
    "            nn.Conv1d(embed_dim, self.out_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mu=None, sigma=None):\n",
    "        # 输入 x 形状: (B, embed_dim, num_patches)\n",
    "        \n",
    "        # 1. 分类任务 (在 num_patches 维度上池化)\n",
    "        cls_token = x.mean(dim=2) # (B, embed_dim)\n",
    "        cls_pred = self.cls_head(cls_token) # (B, n_cls)\n",
    "        \n",
    "        # 2. 生成任务\n",
    "        x_out = self.out_layer(x) # (B, out_channels, L)\n",
    "        \n",
    "        # 调整为 (B, L, C)\n",
    "        x_out = x_out.permute(0, 2, 1)\n",
    "        \n",
    "        if self.normalize and mu is not None and sigma is not None:\n",
    "            x_out = x_out * sigma + mu\n",
    "            \n",
    "        return x_out, cls_pred\n",
    "# --- Demo 代码 (续) ---\n",
    "if __name__ == '__main__':\n",
    "    # (前面是 1D Embedding 和 1D Backbone Demo)\n",
    "    print(\"--- 1D Task Head Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    N_CLS = 10  # 分类任务的类别数\n",
    "\n",
    "    # --- 创建 1D Task Head 模块实例 ---\n",
    "    task_head_layer_1d = DPOTNetTaskHead1D(\n",
    "        embed_dim=EMBED_DIM,\n",
    "        out_channels=IN_CHANNELS, # 输出通道数通常与输入通道数一致\n",
    "        n_cls=N_CLS,\n",
    "        patch_len=PATCH_LEN,\n",
    "        normalize=True\n",
    "    )\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    # 使用 Backbone 的输出 `features_1d` 和 Embedding 的 `mu`, `sigma` 作为输入\n",
    "    output_1d, cls_pred_1d = task_head_layer_1d(features_1d, mu, sigma)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入特征形状 (B, embed_dim, num_patches): {features_1d.shape}\")\n",
    "    print(f\"最终生成序列形状 (B, L, C): {output_1d.shape}\")\n",
    "    print(f\"分类预测形状 (B, n_cls): {cls_pred_1d.shape}\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    # --- 演示端到端完整模型 ---\n",
    "    print(\"--- 1D Full Model Demo ---\")\n",
    "    embedding_layer = DPOTNetEmbedding1D(SEQ_LEN, PATCH_LEN, IN_CHANNELS, EMBED_DIM, normalize=True)\n",
    "    backbone_layer = DPOTNetBackbone1D(EMBED_DIM, DEPTH)\n",
    "    task_head_layer = DPOTNetTaskHead1D(EMBED_DIM, IN_CHANNELS, N_CLS, PATCH_LEN, normalize=True)\n",
    "    \n",
    "    x_in = torch.randn(B, SEQ_LEN, IN_CHANNELS)\n",
    "    \n",
    "    x_embed, mu_s, sigma_s = embedding_layer(x_in)\n",
    "    x_feat = backbone_layer(x_embed)\n",
    "    x_final, cls_final = task_head_layer(x_feat, mu_s, sigma_s)\n",
    "    \n",
    "    print(f\"端到端输入形状: {x_in.shape}\")\n",
    "    print(f\"端到端输出形状: {x_final.shape}\")\n",
    "    print(f\"端到端分类形状: {cls_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf6fc9",
   "metadata": {},
   "source": [
    "# Sundial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e46e0",
   "metadata": {},
   "source": [
    "## flow_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af14824",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823cd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Flow Embedding Demo ---\n",
      "输入时间步形状: torch.Size([4])\n",
      "输入条件向量形状: torch.Size([4, 32])\n",
      "输出统一条件信号形状: torch.Size([4, 64])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TimestepEmbedder(nn.Module):\n",
    "    \"\"\"将标量时间步（t）嵌入为矢量表示。\"\"\"\n",
    "    def __init__(self, hidden_size, frequency_embedding_size=256):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
    "        )\n",
    "        self.frequency_embedding_size = frequency_embedding_size\n",
    "\n",
    "    @staticmethod\n",
    "    def timestep_embedding(t, dim, max_period=10000):\n",
    "        half = dim // 2\n",
    "        freqs = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "        ).to(device=t.device)\n",
    "        args = t[:, None].float() * freqs[None]\n",
    "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "        if dim % 2:\n",
    "            embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, t):\n",
    "        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n",
    "        t_emb = self.mlp(t_freq)\n",
    "        return t_emb\n",
    "\n",
    "class FlowEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    FlowLoss的嵌入模块。\n",
    "    职责：将时间步t和条件z处理成统一的条件信号y。\n",
    "    \"\"\"\n",
    "    def __init__(self, model_channels, z_channels):\n",
    "        super().__init__()\n",
    "        self.time_embed = TimestepEmbedder(model_channels)\n",
    "        self.cond_embed = nn.Linear(z_channels, model_channels)\n",
    "\n",
    "    def forward(self, t, z):\n",
    "        \"\"\"\n",
    "        :param t: 时间步张量 [batch_size]\n",
    "        :param z: 来自上游Transformer的条件向量 [batch_size, z_channels]\n",
    "        :return y: 统一的条件信号 [batch_size, model_channels]\n",
    "        \"\"\"\n",
    "        t_emb = self.time_embed(t)\n",
    "        z_emb = self.cond_embed(z)\n",
    "        # 最终的条件信号是时间嵌入和条件嵌入的和\n",
    "        y = t_emb + z_emb\n",
    "        return y\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Flow Embedding Demo ---\")\n",
    "    \n",
    "    # --- 模型参数 ---\n",
    "    BATCH_SIZE = 4\n",
    "    MODEL_CHANNELS = 64\n",
    "    Z_CHANNELS = 32\n",
    "    MAX_PERIOD = 10000\n",
    "    \n",
    "    # --- 创建 FlowEmbedding 模块实例 ---\n",
    "    flow_embedding_layer = FlowEmbedding(model_channels=MODEL_CHANNELS, z_channels=Z_CHANNELS)\n",
    "    \n",
    "    # --- 创建模拟输入数据 ---\n",
    "    t_in = torch.randint(0, 1000, (BATCH_SIZE,))  # 随机时间步\n",
    "    z_in = torch.randn(BATCH_SIZE, Z_CHANNELS)   # 随机条件向量\n",
    "    \n",
    "    # --- 前向传播 ---\n",
    "    y_out = flow_embedding_layer(t_in, z_in)\n",
    "    \n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入时间步形状: {t_in.shape}\")\n",
    "    print(f\"输入条件向量形状: {z_in.shape}\")\n",
    "    print(f\"输出统一条件信号形状: {y_out.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218cae3",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b167f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Flow Backbone Demo ---\n",
      "输入加噪特征形状: torch.Size([4, 1024, 64])\n",
      "输入条件信号形状: torch.Size([4, 1024, 128])\n",
      "输出特征形状: torch.Size([4, 1024, 128])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def modulate(x, shift, scale):\n",
    "    \"\"\"辅助函数，用于通过移位(shift)和缩放(scale)来调整张量x。\"\"\"\n",
    "    return x * (1 + scale) + shift\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"一个由条件信号y调制的残差块。\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.in_ln = nn.LayerNorm(channels, eps=1e-6)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels, bias=True),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channels, channels, bias=True),\n",
    "        )\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(channels, 3 * channels, bias=True) # 输出 shift, scale, gate\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        shift_mlp, scale_mlp, gate_mlp = self.adaLN_modulation(y).chunk(3, dim=-1)\n",
    "        h = modulate(self.in_ln(x), shift_mlp, scale_mlp)\n",
    "        h = self.mlp(h)\n",
    "        return x + gate_mlp * h\n",
    "\n",
    "class FlowBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    FlowLoss的核心处理骨干。\n",
    "    职责：在条件y的指导下，处理加噪输入x。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, model_channels, num_res_blocks):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_channels, model_channels)\n",
    "        \n",
    "        res_blocks = []\n",
    "        for _ in range(num_res_blocks):\n",
    "            res_blocks.append(ResBlock(model_channels))\n",
    "        self.res_blocks = nn.ModuleList(res_blocks)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        :param x: 加噪输入 [batch_size, in_channels]\n",
    "        :param y: 来自Embedding层的条件信号 [batch_size, model_channels]\n",
    "        :return: 处理后的特征 [batch_size, model_channels]\n",
    "        \"\"\"\n",
    "        x = self.input_proj(x)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, y)\n",
    "        return x\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Flow Backbone Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    BATCH_SIZE = 4\n",
    "    IN_CHANNELS = 64\n",
    "    MODEL_CHANNELS = 128\n",
    "    NUM_RES_BLOCKS = 6\n",
    "    LENGTH = 1024  # 输入特征长度\n",
    "\n",
    "    # --- 创建 FlowBackbone 模块实例 ---\n",
    "    flow_backbone_layer = FlowBackbone(\n",
    "        in_channels=IN_CHANNELS,\n",
    "        model_channels=MODEL_CHANNELS,\n",
    "        num_res_blocks=NUM_RES_BLOCKS\n",
    "    )\n",
    "\n",
    "    # --- 创建模拟输入数据 ---\n",
    "    x_in = torch.randn(BATCH_SIZE, LENGTH, IN_CHANNELS)  # 随机加噪输入\n",
    "    y_in = torch.randn(BATCH_SIZE, LENGTH, MODEL_CHANNELS)  # 随机条件信号\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    features_out = flow_backbone_layer(x_in, y_in)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入加噪特征形状: {x_in.shape}\")\n",
    "    print(f\"输入条件信号形状: {y_in.shape}\")\n",
    "    print(f\"输出特征形状: {features_out.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc2780",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56e146fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Flow Task Head Demo ---\n",
      "输入特征形状: torch.Size([4, 128])\n",
      "输入条件信号形状: torch.Size([4, 128])\n",
      "最终预测形状: torch.Size([4, 10])\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "class FlowTaskHead(nn.Module):\n",
    "    \"\"\"\n",
    "    FlowLoss的任务头。\n",
    "    职责：接收Backbone处理后的特征，生成最终预测。\n",
    "    \"\"\"\n",
    "    def __init__(self, model_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.norm_final = nn.LayerNorm(model_channels, elementwise_affine=False, eps=1e-6)\n",
    "        self.linear = nn.Linear(model_channels, out_channels, bias=True)\n",
    "        self.adaLN_modulation = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(model_channels, 2 * model_channels, bias=True) # 输出 shift, scale\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        :param x: 来自Backbone的特征 [batch_size, model_channels]\n",
    "        :param y: 来自Embedding层的条件信号 [batch_size, model_channels]\n",
    "        :return: 最终预测 [batch_size, out_channels]\n",
    "        \"\"\"\n",
    "        shift, scale = self.adaLN_modulation(y).chunk(2, dim=-1)\n",
    "        x = modulate(self.norm_final(x), shift, scale)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "# --- Demo 代码 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Flow Task Head Demo ---\")\n",
    "\n",
    "    # --- 模型参数 ---\n",
    "    BATCH_SIZE = 4\n",
    "    MODEL_CHANNELS = 128\n",
    "    OUT_CHANNELS = 10\n",
    "\n",
    "    # --- 创建 FlowTaskHead 模块实例 ---\n",
    "    flow_task_head_layer = FlowTaskHead(\n",
    "        model_channels=MODEL_CHANNELS,\n",
    "        out_channels=OUT_CHANNELS\n",
    "    )\n",
    "\n",
    "    # --- 创建模拟输入数据 ---\n",
    "    features_in = torch.randn(BATCH_SIZE, MODEL_CHANNELS)  # 来自Backbone的特征\n",
    "    y_in = torch.randn(BATCH_SIZE, MODEL_CHANNELS)  # 来自Embedding层的条件信号\n",
    "\n",
    "    # --- 前向传播 ---\n",
    "    output_out = flow_task_head_layer(features_in, y_in)\n",
    "\n",
    "    # --- 打印输出形状 ---\n",
    "    print(f\"输入特征形状: {features_in.shape}\")\n",
    "    print(f\"输入条件信号形状: {y_in.shape}\")\n",
    "    print(f\"最终预测形状: {output_out.shape}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b732f57",
   "metadata": {},
   "source": [
    "### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04625c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 解耦后的 FlowLoss 模块 Demo ---\n",
      "\n",
      "--- 1. 推理 (Sampling) ---\n",
      "输入条件 z 的形状: torch.Size([2, 128])\n",
      "生成样本的形状: torch.Size([2, 3, 32])\n",
      "\n",
      "--- 2. 训练 (Loss Calculation) ---\n",
      "真实目标 target 的形状: torch.Size([2, 32])\n",
      "计算得到的损失值: 21.9188\n",
      "\n",
      "解耦后的 FlowLoss Demo 运行完毕!\n"
     ]
    }
   ],
   "source": [
    "class SimpleMLP_Deconstructed(nn.Module):\n",
    "    \"\"\" \n",
    "    将解耦后的三个部分组合成完整的网络。\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, model_channels, out_channels, z_channels, num_res_blocks):\n",
    "        super().__init__()\n",
    "        self.embedding = FlowEmbedding(model_channels, z_channels)\n",
    "        self.backbone = FlowBackbone(in_channels, model_channels, num_res_blocks)\n",
    "        self.task_head = FlowTaskHead(model_channels, out_channels)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # 可以在这里放置权重初始化逻辑\n",
    "        def _basic_init(module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "        self.apply(_basic_init)\n",
    "\n",
    "\n",
    "    def forward(self, x, t, z):\n",
    "        # 1. Embedding: 创建条件信号y\n",
    "        y = self.embedding(t, z)\n",
    "        # 2. Backbone: 在y的指导下处理x\n",
    "        x_processed = self.backbone(x, y)\n",
    "        # 3. Task Head: 生成最终预测\n",
    "        output = self.task_head(x_processed, y)\n",
    "        return output\n",
    "\n",
    "class FlowLossDeconstructed(nn.Module):\n",
    "    \"\"\" \n",
    "    使用解耦模型的总封装器，包含训练和采样逻辑。\n",
    "    \"\"\"\n",
    "    def __init__(self, target_channels, z_channels, depth, width, num_sampling_steps):\n",
    "        super().__init__()\n",
    "        self.in_channels = target_channels\n",
    "        # 使用我们解耦后的网络\n",
    "        self.net = SimpleMLP_Deconstructed(\n",
    "            in_channels=target_channels,\n",
    "            model_channels=width,\n",
    "            out_channels=target_channels,\n",
    "            z_channels=z_channels,\n",
    "            num_res_blocks=depth\n",
    "        )\n",
    "        self.num_sampling_steps = num_sampling_steps\n",
    "\n",
    "    def forward(self, target, z):\n",
    "        # 训练逻辑 (与之前相同)\n",
    "        noise = torch.randn_like(target)\n",
    "        t = torch.rand(target.shape[0], device=target.device)\n",
    "        noised_target = t[:, None] * target + (1 - t[:, None]) * noise\n",
    "        predict_v = self.net(noised_target, t * 1000, z)\n",
    "        \n",
    "        # --- 损失计算部分 ---\n",
    "        weights = 1.0 / torch.arange(1, self.in_channels + 1, dtype=torch.float32, device=target.device)\n",
    "        loss = (weights * (predict_v - target) ** 2).sum(dim=-1) #? 这里的损失计算是否合理？\n",
    "        return loss.mean()\n",
    "\n",
    "    def sample(self, z, num_samples=1):\n",
    "        # 采样逻辑 (与之前相同)\n",
    "        z = z.repeat(num_samples, 1)\n",
    "        noise = torch.randn(z.shape[0], self.in_channels).to(z.device)\n",
    "        x = noise\n",
    "        dt = 1.0 / self.num_sampling_steps\n",
    "        for i in range(self.num_sampling_steps):\n",
    "            t = (torch.ones((x.shape[0])) * i / self.num_sampling_steps).to(x.device)\n",
    "            pred = self.net(x, t * 1000, z)\n",
    "            x = x + (pred - noise) * dt\n",
    "        x = x.reshape(num_samples, -1, self.in_channels).transpose(0, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 解耦后的 FlowLoss 模块 Demo ---\")\n",
    "    \n",
    "    # 1. 定义模型参数\n",
    "    TARGET_CHANNELS = 32\n",
    "    Z_CHANNELS = 128\n",
    "    DEPTH = 4\n",
    "    WIDTH = 256\n",
    "    NUM_SAMPLING_STEPS = 20\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_SAMPLES = 3\n",
    "\n",
    "    # 2. 实例化解耦后的FlowLoss模块\n",
    "    flow_loss_module = FlowLossDeconstructed(\n",
    "        target_channels=TARGET_CHANNELS,\n",
    "        z_channels=Z_CHANNELS,\n",
    "        depth=DEPTH,\n",
    "        width=WIDTH,\n",
    "        num_sampling_steps=NUM_SAMPLING_STEPS\n",
    "    )\n",
    "\n",
    "    # 3. 准备输入数据\n",
    "    z_condition = torch.randn(BATCH_SIZE, Z_CHANNELS)\n",
    "    \n",
    "    # 4. 演示推理过程\n",
    "    print(\"\\n--- 1. 推理 (Sampling) ---\")\n",
    "    flow_loss_module.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_samples = flow_loss_module.sample(z_condition, num_samples=NUM_SAMPLES)\n",
    "    print(f\"输入条件 z 的形状: {z_condition.shape}\")\n",
    "    print(f\"生成样本的形状: {generated_samples.shape}\") # (batch_size, num_samples, target_channels)\n",
    "\n",
    "    # 5. 演示训练过程\n",
    "    print(\"\\n--- 2. 训练 (Loss Calculation) ---\")\n",
    "    flow_loss_module.train()\n",
    "    true_target = torch.randn(BATCH_SIZE, TARGET_CHANNELS)\n",
    "    loss = flow_loss_module(target=true_target, z=z_condition)\n",
    "    print(f\"真实目标 target 的形状: {true_target.shape}\")\n",
    "    print(f\"计算得到的损失值: {loss.item():.4f}\")\n",
    "    \n",
    "    print(\"\\n解耦后的 FlowLoss Demo 运行完毕!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf2f8ac",
   "metadata": {},
   "source": [
    "##  1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa12362",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0708b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Embedding层 Demo ---\n",
      "原始输入数据形状: (batch_size, sequence_length, channel) = torch.Size([2, 512, 3])\n",
      "生成的嵌入向量形状: (batch_size, num_patches, hidden_size) = torch.Size([2, 512, 1, 128])\n",
      "Embedding层 Demo 运行完毕!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers import PretrainedConfig\n",
    "\n",
    "# 为了演示，我们创建一个最小化的配置类\n",
    "class SundialConfig(PretrainedConfig):\n",
    "    model_type = \"sundial\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_token_len=32, \n",
    "                 hidden_size=128, \n",
    "                 intermediate_size=256,\n",
    "                 dropout_rate=0.1,\n",
    "                 hidden_act=\"silu\",\n",
    "                 **kwargs):\n",
    "        self.input_token_len = input_token_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.hidden_act = hidden_act\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class SundialPatchEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    将一维时间序列转换为一系列嵌入向量(patch embedding)。\n",
    "    这个过程类似于NLP中的分词和词嵌入。\n",
    "    \"\"\"\n",
    "    def __init__(self, config: SundialConfig):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(config.dropout_rate)\n",
    "        # 输入维度是数据patch和mask patch拼接后的大小 (input_token_len * 2)\n",
    "        self.hidden_layer = nn.Linear(\n",
    "            config.input_token_len * 2, config.intermediate_size)\n",
    "        self.act = ACT2FN[config.hidden_act]\n",
    "        self.output_layer = nn.Linear(\n",
    "            config.intermediate_size, config.hidden_size)\n",
    "        self.residual_layer = nn.Linear(\n",
    "            config.input_token_len * 2, config.hidden_size)\n",
    "        self.input_token_len = config.input_token_len\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: 输入的原始时间序列, 形状为 [batch_size, sequence_length]\n",
    "\n",
    "        # 创建一个与输入x形状相同,值为1的掩码,用于标识真实数据位置\n",
    "        mask = torch.ones_like(x, dtype=torch.float32)\n",
    "        input_length = x.shape[-1]\n",
    "\n",
    "        # 计算需要填充的长度,以确保序列总长度是 input_token_len 的整数倍\n",
    "        padding_length = (self.input_token_len - (input_length %\n",
    "                                         self.input_token_len)) % self.input_token_len\n",
    "        \n",
    "        # 在序列的左侧(过去)进行填充,填充值为0\n",
    "        x = F.pad(x, (padding_length, 0))\n",
    "        mask = F.pad(mask, (padding_length, 0))\n",
    "        \n",
    "        # 使用 unfold 将时间序列分割成多个patch(块)\n",
    "        x_patched = x.unfold(dimension=-1, size=self.input_token_len,\n",
    "                             step=self.input_token_len)\n",
    "        mask_patched = mask.unfold(\n",
    "            dimension=-1, size=self.input_token_len, step=self.input_token_len)\n",
    "\n",
    "        # 将数据patch和mask patch沿着最后一个维度拼接\n",
    "        combined = torch.cat([x_patched, mask_patched], dim=-1)\n",
    "        \n",
    "        # 通过一个MLP(多层感知机)将patch投影到高维空间(hidden_size)\n",
    "        hid = self.act(self.hidden_layer(combined))\n",
    "        out = self.dropout(self.output_layer(hid))\n",
    "        res = self.residual_layer(combined)\n",
    "        \n",
    "        # 添加残差连接\n",
    "        out = out + res\n",
    "        return out\n",
    "\n",
    "# --- Embedding层 使用示例 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 1. Embedding层 Demo ---\")\n",
    "    \n",
    "    # 1. 配置模型\n",
    "    config = SundialConfig(\n",
    "        input_token_len=32,\n",
    "        hidden_size=128\n",
    "    )\n",
    "\n",
    "    # 2. 实例化Embedding层\n",
    "    embedding_layer = SundialPatchEmbedding(config)\n",
    "    embedding_layer.eval()\n",
    "\n",
    "    # 3. 准备输入数据\n",
    "    BATCH_SIZE = 2\n",
    "    SEQUENCE_LENGTH = 512\n",
    "    CHANNEL = 3\n",
    "    # 模拟两段原始时间序列数据\n",
    "    input_timeseries = torch.randn(BATCH_SIZE, SEQUENCE_LENGTH, CHANNEL)\n",
    "    print(f\"原始输入数据形状: (batch_size, sequence_length, channel) = {input_timeseries.shape}\")\n",
    "\n",
    "    # 4. 前向传播\n",
    "    with torch.no_grad():\n",
    "        embeddings = embedding_layer(input_timeseries)\n",
    "\n",
    "    # 5. 查看输出\n",
    "    # 原始序列被分成了 512 / 32 = 16 个patch\n",
    "    # 输出形状应为: (batch_size, num_patches, hidden_size)\n",
    "    print(f\"生成的嵌入向量形状: (batch_size, num_patches, hidden_size) = {embeddings.shape}\")\n",
    "    print(\"Embedding层 Demo 运行完毕!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a617e",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61890df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Backbone层 Demo ---\n",
      "来自Embedding层的输入形状: torch.Size([2, 16, 128])\n",
      "Backbone输出的隐藏状态形状: torch.Size([2, 16, 128])\n",
      "Backbone层 Demo 运行完毕!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple, List, Union\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import PreTrainedModel, PretrainedConfig, Cache, DynamicCache\n",
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_attn_mask_utils import _prepare_4d_causal_attention_mask\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast\n",
    "\n",
    "# 为了演示，我们创建一个更完整的SundialConfig\n",
    "class SundialConfig(PretrainedConfig):\n",
    "    model_type = \"sundial\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_token_len=32,\n",
    "                 hidden_size=128,\n",
    "                 intermediate_size=256,\n",
    "                 num_hidden_layers=4,\n",
    "                 num_attention_heads=4,\n",
    "                 max_position_embeddings=10000,\n",
    "                 initializer_range=0.02,\n",
    "                 dropout_rate=0.1,\n",
    "                 hidden_act=\"silu\",\n",
    "                 use_cache=True,\n",
    "                 **kwargs):\n",
    "        self.input_token_len = input_token_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.initializer_range = initializer_range\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.hidden_act = hidden_act\n",
    "        self.use_cache = use_cache\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "def rotate_half(x):\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2:]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids, unsqueeze_dim=1):\n",
    "    cos = cos[position_ids].unsqueeze(unsqueeze_dim)\n",
    "    sin = sin[position_ids].unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "class SundialRotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_position_embeddings=10000, base=10000, device=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.base = base\n",
    "        inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, dtype=torch.int64).float().to(device) / self.dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
    "        self._set_cos_sin_cache(seq_len=max_position_embeddings, device=self.inv_freq.device, dtype=torch.get_default_dtype())\n",
    "\n",
    "    def _set_cos_sin_cache(self, seq_len, device, dtype):\n",
    "        self.max_seq_len_cached = seq_len\n",
    "        t = torch.arange(self.max_seq_len_cached, device=device, dtype=torch.int64).type_as(self.inv_freq)\n",
    "        freqs = torch.outer(t, self.inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer(\"cos_cached\", emb.cos().to(dtype), persistent=False)\n",
    "        self.register_buffer(\"sin_cached\", emb.sin().to(dtype), persistent=False)\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        if seq_len > self.max_seq_len_cached:\n",
    "            self._set_cos_sin_cache(seq_len=seq_len, device=x.device, dtype=x.dtype)\n",
    "        return (self.cos_cached[:seq_len].to(dtype=x.dtype), self.sin_cached[:seq_len].to(dtype=x.dtype))\n",
    "\n",
    "class SundialAttention(nn.Module):\n",
    "    def __init__(self, config: SundialConfig, layer_idx: Optional[int] = None):\n",
    "        super().__init__()\n",
    "        self.layer_idx = layer_idx\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.hidden_size // self.num_heads\n",
    "        self.attention_dropout = config.dropout_rate\n",
    "        self.q_proj = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
    "        self.k_proj = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
    "        self.v_proj = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
    "        self.o_proj = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.rotary_emb = SundialRotaryEmbedding(self.head_dim, max_position_embeddings=config.max_position_embeddings)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor] = None,\n",
    "                position_ids: Optional[torch.LongTensor] = None, past_key_value: Optional[Cache] = None,\n",
    "                output_attentions: bool = False, **kwargs) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
    "        bsz, q_len, _ = hidden_states.size()\n",
    "        query_states, key_states, value_states = self.q_proj(hidden_states), self.k_proj(hidden_states), self.v_proj(hidden_states)\n",
    "        query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        key_states = key_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        value_states = value_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        kv_seq_len = key_states.shape[-2]\n",
    "        if past_key_value is not None:\n",
    "            kv_seq_len += past_key_value.get_usable_length(kv_seq_len, self.layer_idx)\n",
    "        cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
    "        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n",
    "\n",
    "        if past_key_value is not None:\n",
    "            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx)\n",
    "\n",
    "        attn_output = F.scaled_dot_product_attention(\n",
    "            query_states, key_states, value_states, attn_mask=attention_mask,\n",
    "            dropout_p=(self.attention_dropout if self.training else 0.0)\n",
    "        )\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().reshape(bsz, q_len, self.hidden_size)\n",
    "        attn_output = self.o_proj(attn_output)\n",
    "        \n",
    "        return attn_output, None, past_key_value\n",
    "\n",
    "class SundialMLP(nn.Module):\n",
    "    def __init__(self, hidden_size: int, intermediate_size: int, hidden_act: str):\n",
    "        super().__init__()\n",
    "        self.gate_proj = nn.Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.up_proj = nn.Linear(hidden_size, intermediate_size, bias=False)\n",
    "        self.down_proj = nn.Linear(intermediate_size, hidden_size, bias=False)\n",
    "        self.act_fn = ACT2FN[hidden_act]\n",
    "\n",
    "    def forward(self, hidden_state):\n",
    "        return self.down_proj(self.act_fn(self.gate_proj(hidden_state)) * self.up_proj(hidden_state))\n",
    "\n",
    "class SundialDecoderLayer(nn.Module):\n",
    "    def __init__(self, config: SundialConfig, layer_idx: int):\n",
    "        super().__init__()\n",
    "        self.self_attn = SundialAttention(config, layer_idx)\n",
    "        self.ffn_layer = SundialMLP(config.hidden_size, config.intermediate_size, config.hidden_act)\n",
    "        self.norm1 = nn.LayerNorm(config.hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(config.hidden_size)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, attention_mask: Optional[torch.Tensor] = None,\n",
    "                position_ids: Optional[torch.LongTensor] = None, past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "                **kwargs) -> Tuple[torch.FloatTensor, Optional[torch.FloatTensor], Optional[torch.FloatTensor]]:\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.norm1(hidden_states)\n",
    "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
    "            hidden_states=hidden_states, attention_mask=attention_mask, position_ids=position_ids, past_key_value=past_key_value)\n",
    "        hidden_states = residual + hidden_states\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.norm2(hidden_states)\n",
    "        hidden_states = self.ffn_layer(hidden_states)\n",
    "        hidden_states = residual + hidden_states\n",
    "        return hidden_states, self_attn_weights, present_key_value\n",
    "\n",
    "class SundialPreTrainedModel(PreTrainedModel):\n",
    "    config_class = SundialConfig\n",
    "    base_model_prefix = \"model\"\n",
    "    supports_gradient_checkpointing = True\n",
    "    _no_split_modules = [\"SundialDecoderLayer\"]\n",
    "    _supports_cache_class = True\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        std = self.config.initializer_range\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "\n",
    "class SundialBackbone(SundialPreTrainedModel):\n",
    "    def __init__(self, config: SundialConfig):\n",
    "        super().__init__(config)\n",
    "        self.layers = nn.ModuleList([SundialDecoderLayer(config, i) for i in range(config.num_hidden_layers)])\n",
    "        self.norm = nn.LayerNorm(config.hidden_size)\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(self, inputs_embeds: torch.FloatTensor, attention_mask: Optional[torch.Tensor] = None,\n",
    "                position_ids: Optional[torch.LongTensor] = None, past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "                use_cache: Optional[bool] = None, return_dict: Optional[bool] = None) -> Union[Tuple, BaseModelOutputWithPast]:\n",
    "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        batch_size, seq_length, _ = inputs_embeds.shape\n",
    "        past_key_values_length = 0\n",
    "        if use_cache and not isinstance(past_key_values, Cache):\n",
    "            past_key_values = DynamicCache.from_legacy_cache(past_key_values)\n",
    "        if past_key_values is not None:\n",
    "             past_key_values_length = past_key_values.get_usable_length(seq_length)\n",
    "\n",
    "        if position_ids is None:\n",
    "            position_ids = torch.arange(past_key_values_length, seq_length + past_key_values_length, dtype=torch.long, device=inputs_embeds.device)\n",
    "            position_ids = position_ids.unsqueeze(0)\n",
    "\n",
    "        attention_mask = _prepare_4d_causal_attention_mask(attention_mask, (batch_size, seq_length), inputs_embeds, past_key_values_length)\n",
    "        hidden_states = inputs_embeds\n",
    "        next_decoder_cache = None\n",
    "\n",
    "        for decoder_layer in self.layers:\n",
    "            layer_outputs = decoder_layer(hidden_states, attention_mask=attention_mask, position_ids=position_ids, past_key_value=past_key_values)\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if use_cache:\n",
    "                next_decoder_cache = layer_outputs[2]\n",
    "\n",
    "        hidden_states = self.norm(hidden_states)\n",
    "        \n",
    "        if not return_dict:\n",
    "            return (hidden_states, next_decoder_cache)\n",
    "        return BaseModelOutputWithPast(last_hidden_state=hidden_states, past_key_values=next_decoder_cache, hidden_states=None, attentions=None)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- Backbone层 使用示例 ---\n",
    "    print(\"--- 2. Backbone层 Demo ---\")\n",
    "\n",
    "    # 1. 准备与Embedding层一致的配置和数据\n",
    "    config = SundialConfig(\n",
    "        input_token_len=32,\n",
    "        hidden_size=128,\n",
    "        intermediate_size=256,\n",
    "        num_hidden_layers=4,\n",
    "        num_attention_heads=4\n",
    "    )\n",
    "    # 假设这是从Embedding层得到的输出\n",
    "    batch_size = 2\n",
    "    num_patches = 16 \n",
    "    hidden_size = 128\n",
    "    # (batch_size, num_patches, hidden_size)\n",
    "    embeddings_from_previous_step = torch.randn(batch_size, num_patches, hidden_size)\n",
    "    print(f\"来自Embedding层的输入形状: {embeddings_from_previous_step.shape}\")\n",
    "\n",
    "    # 2. 实例化Backbone\n",
    "    backbone = SundialBackbone(config)\n",
    "    backbone.eval()\n",
    "\n",
    "    # 3. 前向传播\n",
    "    with torch.no_grad():\n",
    "        # Backbone直接接收嵌入向量\n",
    "        outputs = backbone(inputs_embeds=embeddings_from_previous_step)\n",
    "        \n",
    "    # 4. 查看输出\n",
    "    # Backbone的输出是处理后的隐藏状态\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    print(f\"Backbone输出的隐藏状态形状: {last_hidden_states.shape}\")\n",
    "    print(\"Backbone层 Demo 运行完毕!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6226d3f",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d4ebcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Task Head Demo ---\n",
      "来自Backbone层的输入形状: torch.Size([2, 16, 128])\n",
      "\n",
      "--- 3a. 推理模式 (Sampling) ---\n",
      "生成的预测形状: torch.Size([2, 3, 32])\n",
      "\n",
      "--- 3b. 训练模式 (Loss Calculation) ---\n",
      "计算得到的损失值: 1.4341\n",
      "\n",
      "Task Head Demo 运行完毕!\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Tuple, List, Union\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.normal import Normal\n",
    "\n",
    "# 同样，为了演示创建一个最小化的Config\n",
    "class SundialConfig(PretrainedConfig):\n",
    "    model_type = \"sundial\"\n",
    "    def __init__(self, hidden_size=128, output_token_len=32, \n",
    "                 flow_loss_depth=2, diffusion_batch_mul=1, **kwargs):\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_token_lens = [output_token_len]\n",
    "        self.flow_loss_depth = flow_loss_depth\n",
    "        self.diffusion_batch_mul = diffusion_batch_mul\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "# FlowLoss是任务头的核心计算组件\n",
    "class FlowLoss(nn.Module):\n",
    "    def __init__(self, n_dim, n_hidden, n_layer=2):\n",
    "        super().__init__()\n",
    "        self.n_dim = n_dim\n",
    "        layers = []\n",
    "        for _ in range(n_layer):\n",
    "            layers.append(nn.Linear(n_hidden, n_hidden))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(n_hidden, 2 * n_dim))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, y, c, mask, mask_y):\n",
    "        # 预测高斯分布的均值和标准差\n",
    "        params = self.layers(c)\n",
    "        mu_base, log_std_base = params.chunk(2, -1)\n",
    "        # 应用掩码\n",
    "        mu_base = mu_base * mask_y\n",
    "        log_std_base = log_std_base * mask_y\n",
    "        dist = Normal(loc=mu_base, scale=torch.exp(log_std_base))\n",
    "        # 计算负对数似然损失\n",
    "        loss = -dist.log_prob(y)\n",
    "        loss = (loss * mask_y).mean(dim=-1)\n",
    "        loss = (loss * mask).mean()\n",
    "        return loss\n",
    "\n",
    "    def sample(self, c, n_sample):\n",
    "        # 从预测的分布中采样\n",
    "        params = self.layers(c)\n",
    "        mu_base, log_std_base = params.chunk(2, -1)\n",
    "        dist = Normal(loc=mu_base, scale=torch.exp(log_std_base))\n",
    "        # .sample((n_sample,)) 会增加一个新的维度在最前面\n",
    "        return dist.sample((n_sample,)).transpose(0, 1)\n",
    "\n",
    "class SundialPredictionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    用于时间序列预测的任务头。\n",
    "    \"\"\"\n",
    "    def __init__(self, config: SundialConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.flow_loss = FlowLoss(\n",
    "            n_dim=config.output_token_lens[-1],\n",
    "            n_hidden=config.hidden_size,\n",
    "            n_layer=config.flow_loss_depth,\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, labels: Optional[torch.Tensor] = None, \n",
    "                loss_masks: Optional[torch.Tensor] = None, mask_y: Optional[torch.Tensor] = None,\n",
    "                num_samples: int = 1):\n",
    "        \"\"\"\n",
    "        根据是否有labels，执行训练或推理。\n",
    "        :param hidden_states: 来自Backbone的输出, 形状 [batch_size, seq_len, hidden_size]\n",
    "        \"\"\"\n",
    "        # --- 训练模式 ---\n",
    "        if labels is not None:\n",
    "            bsz, L, _ = hidden_states.shape\n",
    "            \n",
    "            # Reshape Tensors for Loss Calculation\n",
    "            # 维度需要匹配flow_loss的输入\n",
    "            hidden_states = hidden_states.reshape(bsz * L, -1)\n",
    "            labels = labels.reshape(bsz * L, -1)\n",
    "            loss_masks = loss_masks.reshape(bsz * L)\n",
    "            mask_y = mask_y.repeat(L, 1)\n",
    "            \n",
    "            # 如果配置了diffusion_batch_mul，则复制数据以增加训练稳定性\n",
    "            if self.config.diffusion_batch_mul > 1:\n",
    "                hidden_states = hidden_states.repeat(self.config.diffusion_batch_mul, 1)\n",
    "                labels = labels.repeat(self.config.diffusion_batch_mul, 1)\n",
    "                loss_masks = loss_masks.repeat(self.config.diffusion_batch_mul)\n",
    "                mask_y = mask_y.repeat(self.config.diffusion_batch_mul, 1)\n",
    "\n",
    "            loss = self.flow_loss(labels, hidden_states, loss_masks, mask_y)\n",
    "            return {\"loss\": loss}\n",
    "            \n",
    "        # --- 推理模式 ---\n",
    "        else:\n",
    "            # 推理时通常只使用最后一个时间步的隐藏状态进行预测\n",
    "            last_hidden_state = hidden_states[:, -1, :]\n",
    "            predictions = self.flow_loss.sample(last_hidden_state, num_samples)\n",
    "            return {\"predictions\": predictions}\n",
    "\n",
    "# --- Task Head层 使用示例 ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- 3. Task Head Demo ---\")\n",
    "\n",
    "    # 1. 准备配置和来自Backbone的模拟输出\n",
    "    config = SundialConfig(\n",
    "        hidden_size=128,\n",
    "        output_token_len=32, # 预测patch的长度\n",
    "        flow_loss_depth=2\n",
    "    )\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_PATCHES = 16 \n",
    "    HIDDEN_SIZE = 128\n",
    "    \n",
    "    # 模拟来自Backbone层的输出\n",
    "    backbone_output = torch.randn(BATCH_SIZE, NUM_PATCHES, HIDDEN_SIZE)\n",
    "    print(f\"来自Backbone层的输入形状: {backbone_output.shape}\")\n",
    "\n",
    "    # 2. 实例化Task Head\n",
    "    prediction_head = SundialPredictionHead(config)\n",
    "\n",
    "    # --- 演示推理模式 ---\n",
    "    print(\"\\n--- 3a. 推理模式 (Sampling) ---\")\n",
    "    prediction_head.eval()\n",
    "    with torch.no_grad():\n",
    "        NUM_SAMPLES = 3\n",
    "        outputs = prediction_head(hidden_states=backbone_output, num_samples=NUM_SAMPLES)\n",
    "        predictions = outputs[\"predictions\"]\n",
    "\n",
    "    # 预测输出形状应为: (batch_size, num_samples, prediction_length)\n",
    "    print(f\"生成的预测形状: {predictions.shape}\")\n",
    "\n",
    "    # --- 演示训练模式 ---\n",
    "    print(\"\\n--- 3b. 训练模式 (Loss Calculation) ---\")\n",
    "    prediction_head.train()\n",
    "    \n",
    "    # 准备模拟的标签和掩码\n",
    "    # 标签形状应与hidden_states的 (bsz*seq_len, patch_len) 对应\n",
    "    labels_unfolded = torch.randn(BATCH_SIZE, NUM_PATCHES, config.output_token_lens[-1])\n",
    "    loss_masks_unfolded = torch.ones(BATCH_SIZE, NUM_PATCHES)\n",
    "    mask_y = torch.ones(BATCH_SIZE, config.output_token_lens[-1])\n",
    "    \n",
    "    # 计算损失\n",
    "    loss_output = prediction_head(\n",
    "        hidden_states=backbone_output, \n",
    "        labels=labels_unfolded,\n",
    "        loss_masks=loss_masks_unfolded,\n",
    "        mask_y=mask_y\n",
    "    )\n",
    "    print(f\"计算得到的损失值: {loss_output['loss'].item():.4f}\")\n",
    "    \n",
    "    print(\"\\nTask Head Demo 运行完毕!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8677a",
   "metadata": {},
   "source": [
    "# flow loss 对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc1dde",
   "metadata": {},
   "source": [
    "## mean_flow in DIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208713c3",
   "metadata": {},
   "source": [
    "## flow loss in DIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e3da7",
   "metadata": {},
   "source": [
    "## flow loss in sundial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
