"""
PHM-Vibench Pydanticé…ç½®æ¨¡å‹
=============================

åŸºäºPydanticçš„æ™ºèƒ½é…ç½®ç³»ç»Ÿï¼Œæä¾›ï¼š
- ğŸ” è‡ªåŠ¨ç±»å‹éªŒè¯
- ğŸ“ IDEè‡ªåŠ¨è¡¥å…¨æ”¯æŒ
- âš™ï¸ æ™ºèƒ½é»˜è®¤å€¼ç®¡ç†
- ğŸ“š è‡ªåŠ¨æ–‡æ¡£ç”Ÿæˆ
- ğŸ”— é…ç½®ç»§æ‰¿å’Œç»„åˆ

ä½¿ç”¨æ–¹å¼ï¼š
    from src.configs.config_schema import PHMConfig
    
    config = PHMConfig(
        experiment_name="my_experiment",
        model__d_model=256,
        trainer__num_epochs=100
    )

ä½œè€…: PHM-Vibench Team
"""

from typing import Dict, List, Optional, Union, Literal, Any
from pathlib import Path
from pydantic import BaseModel, Field, field_validator, model_validator
import os
import torch


# ==================== åŸºç¡€é…ç½®ç±» ====================

class EnvironmentConfig(BaseModel):
    """ç¯å¢ƒé…ç½® - æ§åˆ¶å®éªŒè¿è¡Œç¯å¢ƒ"""
    
    # å®éªŒå…ƒä¿¡æ¯
    experiment_name: str = Field(default="phm_experiment", description="å®éªŒåç§°")
    project: str = Field(default="phm_vibench", description="é¡¹ç›®åç§°")  
    notes: str = Field(default="", description="å®éªŒå¤‡æ³¨")
    
    # éšæœºæ€§æ§åˆ¶
    seed: int = Field(default=42, description="éšæœºç§å­", ge=0, le=2**32-1)
    iterations: int = Field(default=1, description="å®éªŒé‡å¤æ¬¡æ•°", ge=1, le=100)
    
    # æ—¥å¿—å’Œç›‘æ§
    wandb: bool = Field(default=False, description="å¯ç”¨WandBæ—¥å¿—")
    swanlab: bool = Field(default=False, description="å¯ç”¨SwanLabæ—¥å¿—")
    WANDB_MODE: str = Field(default="disabled", description="WandBæ¨¡å¼")
    
    # è·¯å¾„é…ç½®
    VBENCH_HOME: Optional[str] = Field(default=None, description="é¡¹ç›®æ ¹ç›®å½•")
    output_dir: str = Field(default="save", description="è¾“å‡ºç›®å½•")
    
    class Config:
        extra = "allow"  # å…è®¸é¢å¤–å­—æ®µ


class DataConfig(BaseModel):
    """æ•°æ®é…ç½® - æ§åˆ¶æ•°æ®åŠ è½½å’Œé¢„å¤„ç†"""
    
    # æ•°æ®æº
    data_dir: str = Field(..., description="æ•°æ®æ ¹ç›®å½•")
    metadata_file: str = Field(..., description="å…ƒæ•°æ®æ–‡ä»¶å")
    
    # æ•°æ®åŠ è½½
    batch_size: int = Field(default=32, description="æ‰¹æ¬¡å¤§å°", ge=1, le=1024)
    num_workers: int = Field(default=4, description="æ•°æ®åŠ è½½è¿›ç¨‹æ•°", ge=0, le=32)
    pin_memory: bool = Field(default=True, description="å¯ç”¨å†…å­˜å›ºå®š")
    persistent_workers: bool = Field(default=False, description="ä¿æŒå·¥ä½œè¿›ç¨‹")
    
    # æ•°æ®åˆ’åˆ†
    train_ratio: float = Field(default=0.7, description="è®­ç»ƒé›†æ¯”ä¾‹", ge=0.1, le=0.9)
    val_ratio: float = Field(default=0.15, description="éªŒè¯é›†æ¯”ä¾‹", ge=0.1, le=0.5)
    
    # ä¿¡å·å¤„ç†
    normalization: Union[bool, str] = Field(default=True, description="å½’ä¸€åŒ–æ–¹å¼")
    window_size: int = Field(default=1024, description="çª—å£å¤§å°", ge=32)
    stride: int = Field(default=512, description="æ»‘åŠ¨æ­¥é•¿", ge=1)
    truncate_lenth: int = Field(default=8192, description="æœ€å¤§é•¿åº¦é™åˆ¶", ge=32)
    
    # æ•°æ®ç±»å‹
    dtype: str = Field(default="float32", description="æ•°æ®ç±»å‹")
    num_window: Optional[int] = Field(default=None, description="çª—å£æ•°é‡")
    
    @field_validator('stride')
    @classmethod
    def validate_stride(cls, v, info):
        if hasattr(info, 'data') and 'window_size' in info.data and v > info.data['window_size']:
            raise ValueError("strideä¸èƒ½å¤§äºwindow_size")
        return v


class ModelConfig(BaseModel):
    """æ¨¡å‹é…ç½® - æ§åˆ¶æ¨¡å‹æ¶æ„å’Œå‚æ•°"""
    
    # åŸºç¡€ä¿¡æ¯
    name: str = Field(..., description="æ¨¡å‹åç§°")
    type: str = Field(..., description="æ¨¡å‹ç±»å‹")
    
    # é€šç”¨å‚æ•°
    input_dim: int = Field(default=1, description="è¾“å…¥ç»´åº¦", ge=1)
    num_classes: Optional[int] = Field(default=None, description="åˆ†ç±»ç±»åˆ«æ•°", ge=2)
    dropout: float = Field(default=0.1, description="Dropoutæ¦‚ç‡", ge=0.0, le=1.0)
    activation: str = Field(default="relu", description="æ¿€æ´»å‡½æ•°")
    
    # Transformerå‚æ•°
    d_model: int = Field(default=128, description="æ¨¡å‹ç»´åº¦", ge=16)
    num_heads: int = Field(default=8, description="æ³¨æ„åŠ›å¤´æ•°", ge=1)
    num_layers: int = Field(default=6, description="å±‚æ•°", ge=1, le=50)
    d_ff: Optional[int] = Field(default=None, description="å‰é¦ˆç½‘ç»œç»´åº¦")
    
    # ISFMç‰¹æœ‰å‚æ•°
    embedding: Optional[str] = Field(default=None, description="åµŒå…¥å±‚ç±»å‹")
    backbone: Optional[str] = Field(default=None, description="éª¨å¹²ç½‘ç»œç±»å‹")
    task_head: Optional[str] = Field(default=None, description="ä»»åŠ¡å¤´ç±»å‹")
    
    # Patchå‚æ•°
    patch_size_L: int = Field(default=16, description="æ—¶é—´ç»´åº¦patchå¤§å°", ge=1)
    patch_size_C: int = Field(default=1, description="é€šé“ç»´åº¦patchå¤§å°", ge=1)
    num_patches: int = Field(default=64, description="patchæ•°é‡", ge=1)
    output_dim: int = Field(default=128, description="è¾“å‡ºç»´åº¦", ge=16)
    
    # CNNå‚æ•°
    depth: Optional[int] = Field(default=None, description="ç½‘ç»œæ·±åº¦", ge=1)
    in_channels: Optional[int] = Field(default=None, description="è¾“å…¥é€šé“æ•°", ge=1)
    hidden_dim: Optional[int] = Field(default=None, description="éšè—å±‚ç»´åº¦")
    
    @field_validator('d_ff')
    @classmethod
    def set_d_ff_default(cls, v, info):
        if v is None and hasattr(info, 'data') and 'd_model' in info.data:
            return info.data['d_model'] * 4
        return v
    
    @model_validator(mode='after')
    def validate_isfm_config(self):
        """éªŒè¯ISFMæ¨¡å‹é…ç½®å®Œæ•´æ€§"""
        if self.type == 'ISFM':
            required_fields = ['embedding', 'backbone', 'task_head']
            missing = [f for f in required_fields if not getattr(self, f, None)]
            if missing:
                raise ValueError(f"ISFMæ¨¡å‹ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing}")
        return self


class TaskConfig(BaseModel):
    """ä»»åŠ¡é…ç½® - æ§åˆ¶å­¦ä¹ ä»»åŠ¡å’Œè®­ç»ƒå‚æ•°"""
    
    # ä»»åŠ¡å®šä¹‰
    name: str = Field(..., description="ä»»åŠ¡åç§°")
    type: str = Field(..., description="ä»»åŠ¡ç±»å‹")
    
    # æ•°æ®è®¾ç½®
    target_system_id: Optional[List[int]] = Field(default=None, description="ç›®æ ‡ç³»ç»ŸID")
    source_domain_id: Optional[List[int]] = Field(default=None, description="æºåŸŸID")
    target_domain_id: Optional[List[int]] = Field(default=None, description="ç›®æ ‡åŸŸID")
    target_domain_num: Optional[int] = Field(default=None, description="ç›®æ ‡åŸŸæ•°é‡")
    
    # è®­ç»ƒå‚æ•°
    epochs: int = Field(default=50, description="è®­ç»ƒè½®æ•°", ge=1, le=1000)
    lr: float = Field(default=0.001, description="å­¦ä¹ ç‡", ge=1e-6, le=1.0)
    weight_decay: float = Field(default=0.0001, description="æƒé‡è¡°å‡", ge=0.0, le=1.0)
    optimizer: str = Field(default="adam", description="ä¼˜åŒ–å™¨")
    
    # æŸå¤±å’ŒæŒ‡æ ‡
    loss: str = Field(default="CE", description="æŸå¤±å‡½æ•°")
    metrics: List[str] = Field(default=["acc"], description="è¯„ä¼°æŒ‡æ ‡")
    
    # è°ƒåº¦å™¨
    scheduler: bool = Field(default=False, description="å¯ç”¨å­¦ä¹ ç‡è°ƒåº¦å™¨")
    scheduler_type: str = Field(default="step", description="è°ƒåº¦å™¨ç±»å‹")
    step_size: int = Field(default=10, description="è°ƒåº¦å™¨æ­¥é•¿", ge=1)
    gamma: float = Field(default=0.5, description="å­¦ä¹ ç‡è¡°å‡å› å­", ge=0.1, le=1.0)
    
    # æ—©åœ
    early_stopping: bool = Field(default=True, description="å¯ç”¨æ—©åœ")
    es_patience: int = Field(default=10, description="æ—©åœè€å¿ƒå€¼", ge=1, le=100)
    
    # æ•°æ®åŠ è½½ï¼ˆä»»åŠ¡çº§è¦†ç›–ï¼‰
    batch_size: Optional[int] = Field(default=None, description="ä»»åŠ¡ç‰¹å®šæ‰¹æ¬¡å¤§å°")
    num_workers: Optional[int] = Field(default=None, description="ä»»åŠ¡ç‰¹å®šå·¥ä½œè¿›ç¨‹æ•°")
    pin_memory: Optional[bool] = Field(default=None, description="ä»»åŠ¡ç‰¹å®šå†…å­˜å›ºå®š")
    shuffle: bool = Field(default=True, description="æ‰“ä¹±æ•°æ®")
    log_interval: int = Field(default=50, description="æ—¥å¿—é—´éš”", ge=1)
    
    # å¤šä»»åŠ¡ç‰¹æœ‰
    task_list: Optional[List[str]] = Field(default=None, description="å¤šä»»åŠ¡åˆ—è¡¨")
    loss_weights: Optional[Dict[str, float]] = Field(default=None, description="æŸå¤±æƒé‡")
    
    # Few-shotç‰¹æœ‰
    num_support: Optional[int] = Field(default=None, description="æ”¯æ’‘é›†å¤§å°", ge=1)
    num_query: Optional[int] = Field(default=None, description="æŸ¥è¯¢é›†å¤§å°", ge=1)
    num_episodes: Optional[int] = Field(default=None, description="è®­ç»ƒepisodes", ge=1)


class TrainerConfig(BaseModel):
    """è®­ç»ƒå™¨é…ç½® - æ§åˆ¶è®­ç»ƒè¿‡ç¨‹å’Œç¡¬ä»¶è®¾ç½®"""
    
    # åŸºç¡€è®¾ç½®
    name: str = Field(default="Default_trainer", description="è®­ç»ƒå™¨åç§°")
    num_epochs: int = Field(default=50, description="è®­ç»ƒè½®æ•°", ge=1, le=1000)
    
    # ç¡¬ä»¶è®¾ç½®
    gpus: Union[int, List[int]] = Field(default=1, description="GPUè®¾ç½®")
    device: str = Field(default="auto", description="è®¡ç®—è®¾å¤‡")
    accelerator: str = Field(default="auto", description="åŠ é€Ÿå™¨ç±»å‹")
    
    # è®­ç»ƒä¼˜åŒ–
    mixed_precision: bool = Field(default=False, description="æ··åˆç²¾åº¦è®­ç»ƒ")
    gradient_clip_val: Optional[float] = Field(default=None, description="æ¢¯åº¦è£å‰ª", ge=0.0)
    accumulate_grad_batches: int = Field(default=1, description="æ¢¯åº¦ç´¯ç§¯", ge=1)
    
    # éªŒè¯å’Œæ£€æŸ¥ç‚¹
    check_val_every_n_epoch: int = Field(default=1, description="éªŒè¯é¢‘ç‡", ge=1)
    val_check_interval: Union[int, float] = Field(default=1.0, description="éªŒè¯é—´éš”")
    enable_checkpointing: bool = Field(default=True, description="å¯ç”¨æ£€æŸ¥ç‚¹")
    save_top_k: int = Field(default=3, description="ä¿å­˜æœ€ä½³kä¸ªæ¨¡å‹", ge=1)
    monitor_metric: str = Field(default="val_loss", description="ç›‘æ§æŒ‡æ ‡")
    mode: str = Field(default="min", description="ç›‘æ§æ¨¡å¼")
    
    # æ—©åœ
    early_stopping: bool = Field(default=True, description="å¯ç”¨æ—©åœ")
    patience: int = Field(default=10, description="æ—©åœè€å¿ƒå€¼", ge=1)
    min_delta: float = Field(default=0.001, description="æœ€å°å˜åŒ–é‡", ge=0.0)
    
    # æ—¥å¿—å’Œç›‘æ§
    wandb: bool = Field(default=False, description="å¯ç”¨WandB")
    swanlab: bool = Field(default=False, description="å¯ç”¨SwanLab")
    log_every_n_steps: int = Field(default=50, description="æ—¥å¿—é¢‘ç‡", ge=1)
    enable_progress_bar: bool = Field(default=True, description="æ˜¾ç¤ºè¿›åº¦æ¡")
    
    # é«˜çº§åŠŸèƒ½
    pruning: bool = Field(default=False, description="å¯ç”¨æ¨¡å‹å‰ªæ")
    profiler: Optional[str] = Field(default=None, description="æ€§èƒ½åˆ†æå™¨")
    auto_scale_batch_size: bool = Field(default=False, description="è‡ªåŠ¨æ‰¹æ¬¡å¤§å°")
    auto_lr_find: bool = Field(default=False, description="è‡ªåŠ¨å­¦ä¹ ç‡æœç´¢")
    
    @field_validator('device')
    @classmethod
    def set_device_auto(cls, v):
        if v == "auto":
            return "cuda" if torch.cuda.is_available() else "cpu"
        return v


# ==================== ä¸»é…ç½®ç±» ====================

class PHMConfig(BaseModel):
    """PHM-Vibenchä¸»é…ç½®ç±»"""
    
    environment: EnvironmentConfig = Field(default_factory=EnvironmentConfig)
    data: DataConfig
    model: ModelConfig  
    task: TaskConfig
    trainer: TrainerConfig = Field(default_factory=TrainerConfig)
    
    class Config:
        # å…è®¸é€šè¿‡ model__d_model æ–¹å¼è®¾ç½®åµŒå¥—å±æ€§
        allow_population_by_field_name = True
        validate_assignment = True
    
    def __init__(self, **kwargs):
        """æ”¯æŒåŒä¸‹åˆ’çº¿è¯­æ³•è®¾ç½®åµŒå¥—å‚æ•°"""
        # å¤„ç†åŒä¸‹åˆ’çº¿è¯­æ³•
        nested_updates = {}
        regular_kwargs = {}
        
        for key, value in kwargs.items():
            if '__' in key:
                section, param = key.split('__', 1)
                if section not in nested_updates:
                    nested_updates[section] = {}
                nested_updates[section][param] = value
            else:
                regular_kwargs[key] = value
        
        # åˆå¹¶åµŒå¥—æ›´æ–°
        for section, updates in nested_updates.items():
            if section in regular_kwargs:
                if isinstance(regular_kwargs[section], dict):
                    regular_kwargs[section].update(updates)
                else:
                    # å¦‚æœå·²ç»æ˜¯å¯¹è±¡ï¼Œéœ€è¦è½¬æ¢
                    section_dict = regular_kwargs[section].dict() if hasattr(regular_kwargs[section], 'dict') else {}
                    section_dict.update(updates)
                    regular_kwargs[section] = section_dict
            else:
                regular_kwargs[section] = updates
        
        super().__init__(**regular_kwargs)
    
    @model_validator(mode='after')
    def validate_consistency(self):
        """éªŒè¯é…ç½®é—´çš„ä¸€è‡´æ€§"""
        
        # éªŒè¯è®­ç»ƒè½®æ•°ä¸€è‡´æ€§
        task_epochs = self.task.epochs if hasattr(self.task, 'epochs') else None
        trainer_epochs = self.trainer.num_epochs if hasattr(self.trainer, 'num_epochs') else None
        
        if task_epochs and trainer_epochs and task_epochs != trainer_epochs:
            # è‡ªåŠ¨åŒæ­¥ä¸ºtrainerçš„å€¼
            if hasattr(self.task, 'epochs'):
                self.task.epochs = trainer_epochs
        
        # éªŒè¯æ‰¹æ¬¡å¤§å°ä¸€è‡´æ€§
        data_batch = self.data.batch_size if hasattr(self.data, 'batch_size') else None
        task_batch = getattr(self.task, 'batch_size', None)
        
        if task_batch and data_batch and task_batch != data_batch:
            # ä»»åŠ¡çº§åˆ«çš„æ‰¹æ¬¡å¤§å°ä¼˜å…ˆ
            if hasattr(self.data, 'batch_size'):
                self.data.batch_size = task_batch
        
        return self
    
    def to_legacy_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºæ—§æ ¼å¼å­—å…¸ï¼Œç”¨äºå‘åå…¼å®¹"""
        return {
            'environment': self.environment.dict(),
            'data': self.data.dict(), 
            'model': self.model.dict(),
            'task': self.task.dict(),
            'trainer': self.trainer.dict()
        }
    
    def save_yaml(self, path: Union[str, Path], minimal: bool = False) -> None:
        """ä¿å­˜ä¸ºYAMLæ ¼å¼"""
        import yaml
        
        config_dict = self.to_legacy_dict()
        
        if minimal:
            # åªä¿å­˜éé»˜è®¤å€¼
            config_dict = self._filter_defaults(config_dict)
        
        with open(path, 'w', encoding='utf-8') as f:
            yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
    
    def _filter_defaults(self, config_dict: Dict) -> Dict:
        """è¿‡æ»¤é»˜è®¤å€¼ï¼Œåªä¿ç•™ä¿®æ”¹è¿‡çš„å‚æ•°"""
        # åˆ›å»ºé»˜è®¤é…ç½®ç”¨äºæ¯”è¾ƒ
        default_env = EnvironmentConfig().dict()
        default_trainer = TrainerConfig().dict()
        
        filtered = {}
        
        # ç¯å¢ƒé…ç½®è¿‡æ»¤
        env_filtered = {k: v for k, v in config_dict['environment'].items() 
                       if k not in default_env or v != default_env[k]}
        if env_filtered:
            filtered['environment'] = env_filtered
        
        # æ•°æ®å’Œæ¨¡å‹é…ç½®é€šå¸¸éƒ½éœ€è¦ä¿ç•™ï¼ˆå› ä¸ºæœ‰å¿…éœ€å­—æ®µï¼‰
        filtered['data'] = config_dict['data']
        filtered['model'] = config_dict['model'] 
        filtered['task'] = config_dict['task']
        
        # è®­ç»ƒå™¨é…ç½®è¿‡æ»¤
        trainer_filtered = {k: v for k, v in config_dict['trainer'].items()
                           if k not in default_trainer or v != default_trainer[k]}
        if trainer_filtered:
            filtered['trainer'] = trainer_filtered
        
        return filtered


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_model_choices() -> Dict[str, List[str]]:
    """è·å–å¯ç”¨çš„æ¨¡å‹é€‰æ‹©"""
    return {
        'CNN': ['ResNet1D', 'AttentionCNN', 'MultiScaleCNN', 'MobileNet1D', 'TCN'],
        'RNN': ['AttentionLSTM', 'AttentionGRU', 'ConvLSTM', 'ResidualRNN'],
        'Transformer': ['PatchTST', 'Autoformer', 'Informer', 'Linformer'],
        'ISFM': ['M_01_ISFM', 'M_02_ISFM'],  # M_03ä¸æ¨è
        'MLP': ['Dlinear', 'MLPMixer', 'ResNetMLP', 'DenseNetMLP'],
        'NO': ['FNO', 'DeepONet', 'GraphNO', 'NeuralODE'],
        'FewShot': ['ProtoNet', 'Matching']
    }


def get_task_choices() -> Dict[str, List[str]]:
    """è·å–å¯ç”¨çš„ä»»åŠ¡é€‰æ‹©"""
    return {
        'DG': ['classification', 'prediction'],
        'CDDG': ['classification'],
        'FS': ['classification'],
        'GFS': ['classification'],
        'Pretrain': ['pretraining', 'prediction'],
        'Multitask': ['multitask']
    }


def validate_config(config: PHMConfig) -> List[str]:
    """éªŒè¯é…ç½®å¹¶è¿”å›è­¦å‘Šä¿¡æ¯"""
    warnings = []
    
    # æ£€æŸ¥æ¨¡å‹é€‰æ‹©
    model_choices = get_model_choices()
    if config.model.type in model_choices:
        if config.model.name not in model_choices[config.model.type]:
            warnings.append(f"æ¨¡å‹ç»„åˆå¯èƒ½æ— æ•ˆ: {config.model.type}.{config.model.name}")
    
    # æ£€æŸ¥ä»»åŠ¡é€‰æ‹©
    task_choices = get_task_choices()
    if config.task.type in task_choices:
        if config.task.name not in task_choices[config.task.type]:
            warnings.append(f"ä»»åŠ¡ç»„åˆå¯èƒ½æ— æ•ˆ: {config.task.type}.{config.task.name}")
    
    # æ€§èƒ½å»ºè®®
    if config.data.num_workers < 4:
        warnings.append("å»ºè®®å¢åŠ data.num_workersåˆ°4-8ä»¥æå‡æ€§èƒ½")
    
    if not config.data.pin_memory:
        warnings.append("å»ºè®®å¯ç”¨data.pin_memoryä»¥åŠ é€ŸGPUè®­ç»ƒ")
    
    if config.model.dropout == 0:
        warnings.append("å»ºè®®è®¾ç½®model.dropout>0ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ")
    
    return warnings


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    # åˆ›å»ºåŸºç¡€é…ç½®
    config = PHMConfig(
        data=DataConfig(
            data_dir="./data",
            metadata_file="metadata.xlsx"
        ),
        model=ModelConfig(
            name="ResNet1D",
            type="CNN",
            num_classes=4
        ),
        task=TaskConfig(
            name="classification",
            type="DG"
        )
    )
    
    print("âœ… åŸºç¡€é…ç½®åˆ›å»ºæˆåŠŸ")
    print(f"æ¨¡å‹: {config.model.type}.{config.model.name}")
    print(f"ä»»åŠ¡: {config.task.type}.{config.task.name}")
    
    # ä½¿ç”¨åŒä¸‹åˆ’çº¿è¯­æ³•
    advanced_config = PHMConfig(
        data__data_dir="./data",
        data__metadata_file="metadata.xlsx",
        model__name="M_01_ISFM",
        model__type="ISFM",
        model__embedding="E_01_HSE",
        model__backbone="B_08_PatchTST",
        model__task_head="H_01_Linear_cla",
        model__d_model=256,
        task__name="classification",
        task__type="DG",
        trainer__num_epochs=100
    )
    
    print("\nâœ… é«˜çº§é…ç½®åˆ›å»ºæˆåŠŸ")
    print(f"æ¨¡å‹ç»´åº¦: {advanced_config.model.d_model}")
    print(f"è®­ç»ƒè½®æ•°: {advanced_config.trainer.num_epochs}")
    
    # éªŒè¯é…ç½®
    warnings = validate_config(config)
    if warnings:
        print(f"\nâš ï¸  é…ç½®è­¦å‘Š: {warnings}")
    else:
        print("\nâœ… é…ç½®éªŒè¯é€šè¿‡")