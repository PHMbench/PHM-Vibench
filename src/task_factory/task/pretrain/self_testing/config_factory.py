"""
Flowé…ç½®å·¥å‚ (Flow Configuration Factory)

è¿™ä¸ªæ¨¡å—æä¾›Flowé¢„è®­ç»ƒä»»åŠ¡è‡ªæµ‹è¯•çš„é…ç½®ç”ŸæˆåŠŸèƒ½ï¼Œä½¿ç”¨argparse.Namespaceæ¨¡å¼
ç”Ÿæˆä¸PHM-Vibenchæ¡†æ¶å…¼å®¹çš„æ¨¡æ‹Ÿé…ç½®å¯¹è±¡ã€‚

Author: PHM-Vibench Team
Date: 2025-09-10
"""

from argparse import Namespace
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
import torch


@dataclass
class FlowConfigTemplate:
    """
    Flowé…ç½®æ¨¡æ¿ (Flow Configuration Template)
    
    å®šä¹‰Flowè‡ªæµ‹è¯•ä¸­ä½¿ç”¨çš„å„ç§é…ç½®æ¨¡æ¿å‚æ•°ã€‚
    """
    # æ•°æ®é…ç½®
    batch_size: int = 8
    sequence_length: int = 64
    input_dim: int = 3
    num_classes: int = 4
    
    # æ¨¡å‹é…ç½®
    hidden_dim: int = 128
    time_dim: int = 32
    condition_dim: int = 32
    
    # ä»»åŠ¡é…ç½®
    lr: float = 1e-4
    weight_decay: float = 1e-5
    num_steps: int = 50
    
    # è®­ç»ƒå™¨é…ç½®
    max_epochs: int = 5
    gpus: int = 1 if torch.cuda.is_available() else 0
    precision: int = 32
    
    # ç¯å¢ƒé…ç½®
    seed: int = 42


class FlowConfigurationFactory:
    """
    Flowé…ç½®å·¥å‚ç±» (Flow Configuration Factory Class)
    
    ä½¿ç”¨argparse.Namespaceæ¨¡å¼ç”ŸæˆFlowé¢„è®­ç»ƒä»»åŠ¡è‡ªæµ‹è¯•æ‰€éœ€çš„å„ç§é…ç½®å¯¹è±¡ã€‚
    éµå¾ªtest/conftest.pyä¸­basic_model_configsçš„æ¨¡å¼ï¼Œç¡®ä¿ä¸PHM-Vibenchæ¡†æ¶å…¼å®¹ã€‚
    """
    
    def __init__(self, template: Optional[FlowConfigTemplate] = None):
        """
        åˆå§‹åŒ–é…ç½®å·¥å‚
        
        Args:
            template: é…ç½®æ¨¡æ¿ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡æ¿
        """
        self.template = template or FlowConfigTemplate()
        
    def create_flow_task_config(
        self,
        use_contrastive: bool = True,
        enable_visualization: bool = False,
        custom_params: Optional[Dict[str, Any]] = None
    ) -> Namespace:
        """
        åˆ›å»ºFlowä»»åŠ¡é…ç½® (Create Flow task configuration)
        
        ç”Ÿæˆargs_task Namespaceå¯¹è±¡ï¼Œéµå¾ªPHM-Vibenchçš„ä»»åŠ¡é…ç½®æ¨¡å¼ã€‚
        
        Args:
            use_contrastive: æ˜¯å¦ä½¿ç”¨å¯¹æ¯”å­¦ä¹ 
            enable_visualization: æ˜¯å¦å¯ç”¨å¯è§†åŒ–
            custom_params: è‡ªå®šä¹‰å‚æ•°å­—å…¸
            
        Returns:
            Namespace: ä»»åŠ¡é…ç½®å¯¹è±¡
        """
        config = {
            # åŸºæœ¬ä»»åŠ¡ä¿¡æ¯
            'name': 'flow_pretrain',
            'type': 'pretrain',
            
            # Flowå‚æ•°
            'num_steps': self.template.num_steps,
            'flow_lr': self.template.lr,
            'sigma_min': 0.001,
            'sigma_max': 1.0,
            
            # å¯¹æ¯”å­¦ä¹ å‚æ•°
            'use_contrastive': use_contrastive,
            'lambda_flow': 1.0,
            'lambda_contrastive': 0.1,
            'temperature': 0.1,
            'contrastive_samples': 256,
            
            # ç”Ÿæˆå‚æ•°
            'use_conditional': True,
            'generation_steps': 50,
            'generation_batch_size': 16,
            
            # è®­ç»ƒå‚æ•°
            'lr': self.template.lr,
            'weight_decay': self.template.weight_decay,
            'max_epochs': self.template.max_epochs,
            'optimizer': 'adam',
            'scheduler': True,
            'scheduler_type': 'cosine',
            
            # ç›‘æ§å‚æ•°
            'enable_visualization': enable_visualization,
            'track_memory': True,
            'track_gradients': True,
            'log_generation_samples': False,
            
            # éªŒè¯å‚æ•°
            'validation_interval': 1.0,
            'validation_samples': 64,
            'compute_metrics': True,
            'metrics_interval': 5,
            
            # æ—©åœå‚æ•°
            'early_stopping': False,
            'es_patience': 10,
            'es_min_delta': 1e-4,
        }
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config.update(custom_params)
            
        return Namespace(**config)
    
    def create_model_config(
        self,
        model_size: str = "small",
        custom_params: Optional[Dict[str, Any]] = None
    ) -> Namespace:
        """
        åˆ›å»ºæ¨¡å‹é…ç½® (Create model configuration)
        
        ç”Ÿæˆargs_model Namespaceå¯¹è±¡ï¼Œéµå¾ªconftest.pyä¸­basic_model_configsçš„æ¨¡å¼ã€‚
        
        Args:
            model_size: æ¨¡å‹å¤§å° ("small", "medium", "large")
            custom_params: è‡ªå®šä¹‰å‚æ•°å­—å…¸
            
        Returns:
            Namespace: æ¨¡å‹é…ç½®å¯¹è±¡
        """
        # åŸºäºæ¨¡å‹å¤§å°è°ƒæ•´å‚æ•°
        size_configs = {
            "small": {
                "hidden_dim": 64,
                "time_dim": 16,
                "condition_dim": 16,
                "num_layers": 2,
            },
            "medium": {
                "hidden_dim": 128,
                "time_dim": 32,
                "condition_dim": 32,
                "num_layers": 4,
            },
            "large": {
                "hidden_dim": 256,
                "time_dim": 64,
                "condition_dim": 64,
                "num_layers": 6,
            }
        }
        
        size_config = size_configs.get(model_size, size_configs["small"])
        
        config = {
            # åŸºæœ¬æ¨¡å‹ä¿¡æ¯
            'name': 'M_04_ISFM_Flow',
            'model_name': 'M_04_ISFM_Flow',
            
            # è¾“å…¥ç»´åº¦
            'input_dim': self.template.input_dim,
            'sequence_length': self.template.sequence_length,
            
            # æ¶æ„å‚æ•°
            'hidden_dim': size_config["hidden_dim"],
            'time_dim': size_config["time_dim"],
            'condition_dim': size_config["condition_dim"],
            'num_layers': size_config["num_layers"],
            
            # Flowç‰¹å®šå‚æ•°
            'use_conditional': True,
            'time_embedding_type': 'sinusoidal',
            'condition_embedding_type': 'linear',
            
            # æ­£åˆ™åŒ–å‚æ•°
            'dropout': 0.1,
            'layer_norm': True,
            'activation': 'gelu',
            
            # è¾“å‡ºå‚æ•°
            'num_classes': self.template.num_classes,
            'output_dim': self.template.input_dim,
        }
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config.update(custom_params)
            
        return Namespace(**config)
    
    def create_data_config(
        self,
        dataset_name: str = "CWRU",
        custom_params: Optional[Dict[str, Any]] = None
    ) -> Namespace:
        """
        åˆ›å»ºæ•°æ®é…ç½® (Create data configuration)
        
        ç”Ÿæˆargs_data Namespaceå¯¹è±¡ã€‚
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            custom_params: è‡ªå®šä¹‰å‚æ•°å­—å…¸
            
        Returns:
            Namespace: æ•°æ®é…ç½®å¯¹è±¡
        """
        config = {
            # æ•°æ®é›†ä¿¡æ¯
            'data_dir': 'data',
            'dataset': dataset_name,
            'metadata_file': f'metadata_{dataset_name}.xlsx',
            
            # æ•°æ®åŠ è½½å‚æ•°
            'batch_size': self.template.batch_size,
            'sequence_length': self.template.sequence_length,
            'channels': self.template.input_dim,
            'num_workers': 0,  # æµ‹è¯•æ—¶ä½¿ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            
            # æ•°æ®å¤„ç†å‚æ•°
            'normalize': True,
            'standardize': False,
            'augmentation': False,
            'train_ratio': 0.8,
            'val_ratio': 0.1,
            'test_ratio': 0.1,
            
            # åŸŸä¿¡æ¯
            'num_domains': 1,
            'domain_id': 1,
            'source_domains': [1],
            'target_domains': [1],
            
            # é‡‡æ ·å‚æ•°
            'sampling_rate': 1000.0,
            'overlap_ratio': 0.0,
            'signal_length': self.template.sequence_length,
        }
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config.update(custom_params)
            
        return Namespace(**config)
    
    def create_trainer_config(
        self,
        fast_mode: bool = True,
        custom_params: Optional[Dict[str, Any]] = None
    ) -> Namespace:
        """
        åˆ›å»ºè®­ç»ƒå™¨é…ç½® (Create trainer configuration)
        
        ç”Ÿæˆargs_trainer Namespaceå¯¹è±¡ï¼Œé€‚ç”¨äºPyTorch Lightningè®­ç»ƒå™¨ã€‚
        
        Args:
            fast_mode: æ˜¯å¦ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            custom_params: è‡ªå®šä¹‰å‚æ•°å­—å…¸
            
        Returns:
            Namespace: è®­ç»ƒå™¨é…ç½®å¯¹è±¡
        """
        if fast_mode:
            # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
            config = {
                'max_epochs': 2,
                'max_steps': 10,
                'limit_train_batches': 3,
                'limit_val_batches': 2,
                'limit_test_batches': 2,
                'log_every_n_steps': 1,
                'val_check_interval': 1.0,
                'check_val_every_n_epoch': 1,
                'enable_checkpointing': False,
                'enable_progress_bar': False,
                'enable_model_summary': False,
                'logger': False,
            }
        else:
            # æ ‡å‡†æ¨¡å¼
            config = {
                'max_epochs': self.template.max_epochs,
                'log_every_n_steps': 50,
                'val_check_interval': 1.0,
                'check_val_every_n_epoch': 1,
                'enable_checkpointing': True,
                'enable_progress_bar': True,
                'enable_model_summary': True,
            }
        
        # é€šç”¨é…ç½®
        common_config = {
            'gpus': self.template.gpus,
            'precision': self.template.precision,
            'gradient_clip_val': 1.0,
            'gradient_clip_algorithm': 'norm',
            'accumulate_grad_batches': 1,
            'deterministic': True,
            'benchmark': False,
        }
        
        config.update(common_config)
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config.update(custom_params)
            
        return Namespace(**config)
    
    def create_environment_config(
        self,
        custom_params: Optional[Dict[str, Any]] = None
    ) -> Namespace:
        """
        åˆ›å»ºç¯å¢ƒé…ç½® (Create environment configuration)
        
        ç”Ÿæˆargs_environment Namespaceå¯¹è±¡ã€‚
        
        Args:
            custom_params: è‡ªå®šä¹‰å‚æ•°å­—å…¸
            
        Returns:
            Namespace: ç¯å¢ƒé…ç½®å¯¹è±¡
        """
        config = {
            # éšæœºç§å­
            'seed': self.template.seed,
            'deterministic': True,
            'benchmark': False,
            
            # è®¾å¤‡é…ç½®
            'device': 'auto',
            'gpus': self.template.gpus,
            'precision': self.template.precision,
            
            # å¹¶è¡Œé…ç½®
            'num_workers': 0,
            'pin_memory': False,
            'persistent_workers': False,
            
            # æ—¥å¿—é…ç½®
            'logging_level': 'WARNING',  # æµ‹è¯•æ—¶å‡å°‘æ—¥å¿—è¾“å‡º
            'log_dir': 'logs/self_test',
            'experiment_name': 'flow_self_test',
            
            # ä¿å­˜é…ç½®
            'save_dir': 'outputs/self_test',
            'save_predictions': False,
            'save_checkpoints': False,
        }
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            config.update(custom_params)
            
        return Namespace(**config)
    
    def create_complete_config_set(
        self,
        test_scenario: str = "basic",
        custom_overrides: Optional[Dict[str, Dict[str, Any]]] = None
    ) -> Dict[str, Namespace]:
        """
        åˆ›å»ºå®Œæ•´é…ç½®é›†åˆ (Create complete configuration set)
        
        ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„é…ç½®å¯¹è±¡ï¼Œç”¨äºä»»åŠ¡å·¥å‚å®ä¾‹åŒ–ã€‚
        
        Args:
            test_scenario: æµ‹è¯•åœºæ™¯ ("basic", "contrastive", "performance")
            custom_overrides: è‡ªå®šä¹‰è¦†ç›–å‚æ•°ï¼Œæ ¼å¼ä¸º {config_type: {param: value}}
            
        Returns:
            Dict[str, Namespace]: åŒ…å«æ‰€æœ‰é…ç½®çš„å­—å…¸
        """
        overrides = custom_overrides or {}
        
        # æ ¹æ®æµ‹è¯•åœºæ™¯è°ƒæ•´å‚æ•°
        scenario_configs = {
            "basic": {
                "use_contrastive": False,
                "fast_mode": True,
                "model_size": "small"
            },
            "contrastive": {
                "use_contrastive": True,
                "fast_mode": True,
                "model_size": "medium"
            },
            "performance": {
                "use_contrastive": True,
                "fast_mode": False,
                "model_size": "large"
            }
        }
        
        scenario = scenario_configs.get(test_scenario, scenario_configs["basic"])
        
        # ç”Ÿæˆå„ä¸ªé…ç½®
        configs = {
            'args_task': self.create_flow_task_config(
                use_contrastive=scenario["use_contrastive"],
                custom_params=overrides.get('task', {})
            ),
            'args_model': self.create_model_config(
                model_size=scenario["model_size"],
                custom_params=overrides.get('model', {})
            ),
            'args_data': self.create_data_config(
                custom_params=overrides.get('data', {})
            ),
            'args_trainer': self.create_trainer_config(
                fast_mode=scenario["fast_mode"],
                custom_params=overrides.get('trainer', {})
            ),
            'args_environment': self.create_environment_config(
                custom_params=overrides.get('environment', {})
            )
        }
        
        return configs
    
    def get_config_summary(self, configs: Dict[str, Namespace]) -> Dict[str, Any]:
        """
        è·å–é…ç½®æ‘˜è¦ (Get configuration summary)
        
        Args:
            configs: é…ç½®å­—å…¸
            
        Returns:
            åŒ…å«é…ç½®æ‘˜è¦çš„å­—å…¸
        """
        summary = {}
        
        for config_name, config_obj in configs.items():
            config_dict = vars(config_obj)
            summary[config_name] = {
                "total_params": len(config_dict),
                "key_params": {k: v for k, v in config_dict.items() 
                             if k in ['name', 'type', 'batch_size', 'hidden_dim', 
                                    'lr', 'max_epochs', 'use_contrastive']},
                "param_types": {k: type(v).__name__ for k, v in config_dict.items()}
            }
        
        return summary


# ä¾¿æ·å‡½æ•°ï¼Œéµå¾ªconftest.pyçš„å‘½åçº¦å®š
def create_flow_test_configs(
    scenario: str = "basic",
    batch_size: int = 8,
    seq_len: int = 64,
    input_dim: int = 3
) -> Dict[str, Namespace]:
    """
    åˆ›å»ºFlowæµ‹è¯•é…ç½®çš„ä¾¿æ·å‡½æ•° (Convenience function for creating Flow test configs)
    
    Args:
        scenario: æµ‹è¯•åœºæ™¯
        batch_size: æ‰¹æ¬¡å¤§å°
        seq_len: åºåˆ—é•¿åº¦
        input_dim: è¾“å…¥ç»´åº¦
        
    Returns:
        Dict[str, Namespace]: é…ç½®å­—å…¸
    """
    template = FlowConfigTemplate(
        batch_size=batch_size,
        sequence_length=seq_len,
        input_dim=input_dim
    )
    
    factory = FlowConfigurationFactory(template)
    return factory.create_complete_config_set(test_scenario=scenario)


# å¯¼å‡ºçš„ç±»å’Œå‡½æ•°
__all__ = [
    'FlowConfigTemplate',
    'FlowConfigurationFactory',
    'create_flow_test_configs',
]


if __name__ == "__main__":
    """
    Flowé…ç½®å·¥å‚è‡ªæµ‹è¯• (Flow Configuration Factory Self-Test)
    
    æµ‹è¯•é…ç½®å·¥å‚çš„å„ç§åŠŸèƒ½ï¼Œç¡®ä¿ç”Ÿæˆçš„é…ç½®å¯¹è±¡ç¬¦åˆPHM-Vibenchæ¡†æ¶è¦æ±‚ã€‚
    """
    print("=" * 60)
    print("Flowé…ç½®å·¥å‚è‡ªæµ‹è¯• (Flow Configuration Factory Self-Test)")
    print("=" * 60)
    
    try:
        # æµ‹è¯•1: åŸºæœ¬é…ç½®å·¥å‚åˆ›å»º
        print("\n1. æµ‹è¯•åŸºæœ¬é…ç½®å·¥å‚åˆ›å»º...")
        factory = FlowConfigurationFactory()
        print("âœ“ FlowConfigurationFactoryåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•2: å•ä¸ªé…ç½®å¯¹è±¡åˆ›å»º
        print("\n2. æµ‹è¯•å•ä¸ªé…ç½®å¯¹è±¡åˆ›å»º...")
        
        # ä»»åŠ¡é…ç½®
        task_config = factory.create_flow_task_config()
        print(f"âœ“ ä»»åŠ¡é…ç½®åˆ›å»ºæˆåŠŸ: {task_config.name}.{task_config.type}")
        print(f"  - ä½¿ç”¨å¯¹æ¯”å­¦ä¹ : {task_config.use_contrastive}")
        print(f"  - å­¦ä¹ ç‡: {task_config.lr}")
        
        # æ¨¡å‹é…ç½®
        model_config = factory.create_model_config()
        print(f"âœ“ æ¨¡å‹é…ç½®åˆ›å»ºæˆåŠŸ: {model_config.name}")
        print(f"  - éšè—ç»´åº¦: {model_config.hidden_dim}")
        print(f"  - è¾“å…¥ç»´åº¦: {model_config.input_dim}")
        
        # æ•°æ®é…ç½®
        data_config = factory.create_data_config()
        print(f"âœ“ æ•°æ®é…ç½®åˆ›å»ºæˆåŠŸ: {data_config.dataset}")
        print(f"  - æ‰¹æ¬¡å¤§å°: {data_config.batch_size}")
        print(f"  - åºåˆ—é•¿åº¦: {data_config.sequence_length}")
        
        # è®­ç»ƒå™¨é…ç½®
        trainer_config = factory.create_trainer_config()
        print(f"âœ“ è®­ç»ƒå™¨é…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"  - æœ€å¤§è½®æ•°: {trainer_config.max_epochs}")
        print(f"  - GPUæ•°é‡: {trainer_config.gpus}")
        
        # ç¯å¢ƒé…ç½®
        env_config = factory.create_environment_config()
        print(f"âœ“ ç¯å¢ƒé…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"  - éšæœºç§å­: {env_config.seed}")
        print(f"  - ç¡®å®šæ€§: {env_config.deterministic}")
        
        # æµ‹è¯•3: ä¸åŒæ¨¡å‹å¤§å°é…ç½®
        print("\n3. æµ‹è¯•ä¸åŒæ¨¡å‹å¤§å°é…ç½®...")
        for size in ["small", "medium", "large"]:
            model_config = factory.create_model_config(model_size=size)
            print(f"âœ“ {size}æ¨¡å‹é…ç½®: hidden_dim={model_config.hidden_dim}, "
                  f"time_dim={model_config.time_dim}")
        
        # æµ‹è¯•4: ä¸åŒæµ‹è¯•åœºæ™¯
        print("\n4. æµ‹è¯•ä¸åŒæµ‹è¯•åœºæ™¯...")
        for scenario in ["basic", "contrastive", "performance"]:
            configs = factory.create_complete_config_set(test_scenario=scenario)
            print(f"âœ“ {scenario}åœºæ™¯é…ç½®é›†åˆ›å»ºæˆåŠŸ")
            print(f"  - é…ç½®æ•°é‡: {len(configs)}")
            print(f"  - é…ç½®ç±»å‹: {list(configs.keys())}")
            print(f"  - ä½¿ç”¨å¯¹æ¯”å­¦ä¹ : {configs['args_task'].use_contrastive}")
        
        # æµ‹è¯•5: è‡ªå®šä¹‰å‚æ•°è¦†ç›–
        print("\n5. æµ‹è¯•è‡ªå®šä¹‰å‚æ•°è¦†ç›–...")
        custom_overrides = {
            'task': {'lr': 1e-3, 'use_contrastive': False},
            'model': {'hidden_dim': 512},
            'trainer': {'max_epochs': 10}
        }
        configs = factory.create_complete_config_set(
            test_scenario="basic",
            custom_overrides=custom_overrides
        )
        print(f"âœ“ è‡ªå®šä¹‰è¦†ç›–æˆåŠŸ")
        print(f"  - å­¦ä¹ ç‡: {configs['args_task'].lr}")
        print(f"  - éšè—ç»´åº¦: {configs['args_model'].hidden_dim}")
        print(f"  - æœ€å¤§è½®æ•°: {configs['args_trainer'].max_epochs}")
        
        # æµ‹è¯•6: é…ç½®æ‘˜è¦ç”Ÿæˆ
        print("\n6. æµ‹è¯•é…ç½®æ‘˜è¦ç”Ÿæˆ...")
        summary = factory.get_config_summary(configs)
        print(f"âœ“ é…ç½®æ‘˜è¦ç”ŸæˆæˆåŠŸ")
        for config_name, config_summary in summary.items():
            print(f"  - {config_name}: {config_summary['total_params']}ä¸ªå‚æ•°")
        
        # æµ‹è¯•7: ä¾¿æ·å‡½æ•°æµ‹è¯•
        print("\n7. æµ‹è¯•ä¾¿æ·å‡½æ•°...")
        conv_configs = create_flow_test_configs(scenario="contrastive")
        print(f"âœ“ ä¾¿æ·å‡½æ•°åˆ›å»ºé…ç½®æˆåŠŸ")
        print(f"  - é…ç½®æ•°é‡: {len(conv_configs)}")
        
        # æµ‹è¯•8: Namespaceå¯¹è±¡éªŒè¯
        print("\n8. æµ‹è¯•Namespaceå¯¹è±¡éªŒè¯...")
        task_config = factory.create_flow_task_config()
        
        # éªŒè¯æ˜¯å¦æ˜¯Namespaceå¯¹è±¡
        from argparse import Namespace
        is_namespace = isinstance(task_config, Namespace)
        print(f"âœ“ Namespaceç±»å‹éªŒè¯: {'é€šè¿‡' if is_namespace else 'å¤±è´¥'}")
        
        # éªŒè¯å±æ€§è®¿é—®
        has_required_attrs = all(hasattr(task_config, attr) for attr in 
                               ['name', 'type', 'lr', 'use_contrastive'])
        print(f"âœ“ å¿…éœ€å±æ€§éªŒè¯: {'é€šè¿‡' if has_required_attrs else 'å¤±è´¥'}")
        
        # æµ‹è¯•9: è®¾å¤‡å…¼å®¹æ€§
        print("\n9. æµ‹è¯•è®¾å¤‡å…¼å®¹æ€§...")
        # CPUé…ç½®
        cpu_template = FlowConfigTemplate(gpus=0)
        cpu_factory = FlowConfigurationFactory(cpu_template)
        cpu_configs = cpu_factory.create_complete_config_set()
        print(f"âœ“ CPUé…ç½®åˆ›å»ºæˆåŠŸ: GPUs={cpu_configs['args_trainer'].gpus}")
        
        # GPUé…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if torch.cuda.is_available():
            gpu_template = FlowConfigTemplate(gpus=1)
            gpu_factory = FlowConfigurationFactory(gpu_template)
            gpu_configs = gpu_factory.create_complete_config_set()
            print(f"âœ“ GPUé…ç½®åˆ›å»ºæˆåŠŸ: GPUs={gpu_configs['args_trainer'].gpus}")
        else:
            print("âœ“ GPUä¸å¯ç”¨ï¼Œè·³è¿‡GPUé…ç½®æµ‹è¯•")
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Flowé…ç½®å·¥å‚å·¥ä½œæ­£å¸¸ã€‚")
        print("ğŸ”§ ç”Ÿæˆçš„é…ç½®å¯¹è±¡ä¸PHM-Vibenchæ¡†æ¶å®Œå…¨å…¼å®¹ã€‚")
        print("ğŸ“ æ”¯æŒå¤šç§æµ‹è¯•åœºæ™¯å’Œè‡ªå®šä¹‰å‚æ•°è¦†ç›–ã€‚")
        print("âš™ï¸ å¯ç”¨äºFlowé¢„è®­ç»ƒä»»åŠ¡çš„è‡ªæµ‹è¯•é…ç½®ç”Ÿæˆã€‚")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("è¯·æ£€æŸ¥ä»£ç å®ç°å¹¶ä¿®å¤é—®é¢˜ã€‚")
        import traceback
        traceback.print_exc()
        raise