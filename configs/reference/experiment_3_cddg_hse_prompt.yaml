# Experiment 3 (CDDG view): HSE-Prompt Pretraining + CDDG Finetuning
# 基于 unified 配置 configs/experiment_3_unified.yaml，但将 stage2 视为 CDDG 分类

environment:
  VBENCH_HOME: "/home/user/LQ/B_Signal/Signal_foundation_model/Vbench"
  project: "experiment_3_cddg_hse_prompt"
  seed: 42
  output_dir: "paper/2025-10_foundation_model_0_metric/results/cddg/exp3_hse_prompt"
  notes: "Experiment 3 (CDDG): HSE-Prompt unified method (pretraining + CDDG finetuning)"
  iterations: 1

data:
  data_dir: "/home/user/data/PHMbenchdata/PHM-Vibench"
  metadata_file: "metadata.xlsx"
  batch_size: 256
  num_workers: 0
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  normalization: "standardization"
  window_size: 4096
  stride: 5
  num_window: 64
  dtype: "float32"
  pin_memory: true

model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"
  embedding: "HSE_prompt"
  backbone: "B_04_Dlinear"
  task_head: "H_01_Linear_cla"
  input_dim: 1
  d_model: 256
  output_dim: 128
  num_heads: 8
  num_layers: 4
  e_layers: 4
  d_ff: 512
  dropout: 0.1
  activation: "relu"
  factor: 5
  patch_size_L: 64
  patch_size_C: 1
  num_patches: 64
  use_prompt: true
  prompt_dim: 128
  fusion_type: "attention"
  system_prompt_dim: 64
  sample_prompt_dim: 32
  gradient_checkpointing: true
  mixed_precision: true

task:
  type: "pretrain"
  name: "hse_contrastive"
  target_system_id: [1, 13, 6, 12, 19]
  target_domain_num: 1
  loss: "INFONCE"
  contrast_loss: "INFONCE"
  contrast_weight: 0.4
  classification_weight: 0.1
  temperature: 0.07
  optimizer: "adamw"
  lr: 0.0005
  weight_decay: 0.0001
  metrics: ["acc", "f1", "precision", "recall"]

trainer:
  name: "Default_trainer"
  max_epochs: 50
  devices: 1
  accelerator: "cuda"
  precision: 32
  monitor: "val_loss"
  check_val_every_n_epoch: 5
  deterministic: true
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  save_checkpoints: true
  log_every_n_steps: 50

stages:
  - name: "pretraining"
    description: "HSE-Prompt 对比预训练阶段，学习跨系统共享表征（CDDG 视角）"
    overrides:
      task:
        type: "pretrain"
        name: "hse_contrastive"
        hse_prompt_objectives:
          - "hse_contrastive"
          - "prompt_consistency"
          - "domain_alignment"
          - "masked_prediction"
        multi_objective_loss:
          hse_contrastive_weight: 0.4
          prompt_consistency_weight: 0.2
          domain_alignment_weight: 0.2
          masked_prediction_weight: 0.2
        contrast_loss: "INFONCE"
        contrast_weight: 0.4
        classification_weight: 0.1
        temperature: 0.07
        use_system_sampling: true
        cross_system_contrast: true
        prompt_weight: 0.6
      trainer:
        max_epochs: 30
        save_dir: "results/experiment_3_unified/pretrain"
        early_stopping: false
      data:
        num_window: 64
        stride: 5

  - name: "finetuning"
    description: "HSE-Prompt 预训练后的 CDDG 分类微调阶段"
    overrides:
      task:
        type: "CDDG"
        name: "classification"
        loss: "CE"
        target_system_id: [1, 13, 6, 12, 19]
        target_domain_num: 1
        optimizer: "adamw"
        lr: 0.0001
        weight_decay: 0.0001
      trainer:
        max_epochs: 20
        save_dir: "results/experiment_3_unified/finetune"
        early_stopping: true
        patience: 10
      data:
        num_window: 64
        stride: 5

pipeline:
  name: "Pipeline_02_pretrain_fewshot"
