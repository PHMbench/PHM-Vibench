# Experiment 4 (CDDG, Two-Stage): HSE-Prompt Component Ablation
#
# 说明：
# - Stage1：HSE-Prompt 对比/多目标预训练（与 Experiment 3 一致）；
# - Stage2：CDDG 分类微调，Prompt 组件消融通过 CLI override 控制：
#     * full        : 默认配置（use_prompt=true, system_prompt_dim>0, sample_prompt_dim>0）
#     * no_prompt   : use_prompt=false
#     * system_only : use_prompt=true, system_prompt_dim>0, sample_prompt_dim=0
#     * sample_only : use_prompt=true, system_prompt_dim=0, sample_prompt_dim>0

environment:
  VBENCH_HOME: "/home/user/LQ/B_Signal/Signal_foundation_model/Vbench"
  project: "experiment_4_cddg_ablation_twostage"
  seed: 42
  output_dir: "paper/2025-10_foundation_model_0_metric/results/cddg/exp4_ablation_twostage"
  notes: "Experiment 4 (CDDG, Two-Stage): HSE-Prompt pretrain + CDDG component ablation"
  iterations: 1

data:
  data_dir: "/home/user/data/PHMbenchdata/PHM-Vibench"
  metadata_file: "metadata.xlsx"
  batch_size: 256
  num_workers: 0
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  normalization: "standardization"
  window_size: 4096
  stride: 5
  num_window: 64
  dtype: "float32"
  pin_memory: true

model:
  name: "M_02_ISFM_Prompt"
  type: "ISFM_Prompt"

  embedding: "HSE_prompt"
  backbone: "B_04_Dlinear"
  task_head: "H_01_Linear_cla"

  input_dim: 1
  d_model: 256
  output_dim: 128

  num_heads: 8
  num_layers: 4
  e_layers: 4
  d_ff: 512
  dropout: 0.1
  activation: "relu"
  factor: 5

  patch_size_L: 64
  patch_size_C: 1
  num_patches: 64

  use_prompt: true
  prompt_dim: 128
  fusion_type: "attention"
  system_prompt_dim: 64
  sample_prompt_dim: 32

  gradient_checkpointing: true
  mixed_precision: true

task:
  type: "pretrain"
  name: "hse_contrastive"
  target_system_id: [1, 13, 6, 12, 19]
  target_domain_num: 1
  loss: "INFONCE"
  contrast_loss: "INFONCE"
  contrast_weight: 0.4
  classification_weight: 0.1
  temperature: 0.07
  optimizer: "adamw"
  lr: 0.0005
  weight_decay: 0.0001
  metrics: ["acc", "f1", "precision", "recall"]

trainer:
  name: "Default_trainer"
  max_epochs: 50
  devices: 1
  accelerator: "cuda"
  precision: 32
  monitor: "val_loss"
  check_val_every_n_epoch: 5
  deterministic: true
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  save_checkpoints: true
  log_every_n_steps: 50

stages:
  - name: "pretraining"
    description: "Stage1: HSE-Prompt 对比预训练（共享 backbone 与 Prompt 配置）"
    overrides:
      task:
        type: "pretrain"
        name: "hse_contrastive"
        hse_prompt_objectives:
          - "hse_contrastive"
          - "prompt_consistency"
          - "domain_alignment"
          - "masked_prediction"
        multi_objective_loss:
          hse_contrastive_weight: 0.4
          prompt_consistency_weight: 0.2
          domain_alignment_weight: 0.2
          masked_prediction_weight: 0.2
        contrast_loss: "INFONCE"
        contrast_weight: 0.4
        classification_weight: 0.1
        temperature: 0.07
        use_system_sampling: true
        cross_system_contrast: true
        prompt_weight: 0.6
      trainer:
        max_epochs: 30
        save_dir: "results/experiment_4_cddg_ablation_twostage/pretrain"
        early_stopping: false
      data:
        num_window: 64
        stride: 5

  - name: "finetuning"
    description: "Stage2: CDDG 分类微调 + Prompt 组件消融（通过 CLI override 控制）"
    overrides:
      task:
        type: "CDDG"
        name: "classification"
        loss: "CE"
        target_system_id: [1, 13, 6, 12, 19]
        target_domain_num: 1
        optimizer: "adamw"
        lr: 0.0001
        weight_decay: 0.0001
      trainer:
        max_epochs: 20
        save_dir: "results/experiment_4_cddg_ablation_twostage/finetune"
        early_stopping: true
        patience: 10
      data:
        num_window: 64
        stride: 5

pipeline:
  name: "Pipeline_02_pretrain_fewshot"

