# PHM-Vibench ç”Ÿæˆæ¨¡å‹(GM)é¢„è®­ç»ƒé›†æˆæ–¹æ¡ˆ - ä¼˜åŒ–ç‰ˆ

**åˆ›å»ºæ—¥æœŸï¼š2025å¹´8æœˆ29æ—¥**  
**ä½œè€…ï¼šPHM-Vibench å¼€å‘å›¢é˜Ÿ**  
**åŸºäºï¼šCFL.ipynb ç¬”è®°æœ¬åˆ†æ**  
**ç‰ˆæœ¬ï¼šä¼˜åŒ–ç‰ˆ v2.0**

---

## æ‰§è¡Œæ‘˜è¦

æœ¬æ–‡æ¡£æ˜¯æµæŸå¤±é¢„è®­ç»ƒæ–¹æ¡ˆçš„ä¼˜åŒ–ç‰ˆï¼Œå°†åŸæ–¹æ¡ˆä¸­çš„Flowæ¨¡å‹é‡æ–°å®šä½ä¸ºç”Ÿæˆæ¨¡å‹ï¼ˆGenerative Model, GMï¼‰ï¼Œå¼ºè°ƒå…¶ç”Ÿæˆèƒ½åŠ›å’Œæ•°æ®å¢å¼ºæ½œåŠ›ã€‚é‡‡ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æ–¹æ³•ï¼Œæ¯ä¸ªæ¨¡å—éƒ½é›†æˆç‹¬ç«‹çš„æµ‹è¯•ä»£ç ï¼Œç¡®ä¿ä»£ç è´¨é‡å’Œå¯é æ€§ã€‚

### å…³é”®ä¼˜åŒ–

- **ç”Ÿæˆæ¨¡å‹å®šä½**ï¼šæ˜ç¡®å°†æ¨¡å‹å®šä½ä¸ºå…·æœ‰å®Œæ•´ç”Ÿæˆèƒ½åŠ›çš„GMæ¨¡å‹
- **å†…åµŒå¼æµ‹è¯•**ï¼šæ¯ä¸ªæ¨¡å—åŒ…å« `if __name__ == '__main__'` æµ‹è¯•ä»£ç 
- **TDDå¼€å‘æµç¨‹**ï¼šæµ‹è¯•é©±åŠ¨çš„å¼€å‘æ–¹æ³•ï¼Œå…ˆå†™æµ‹è¯•å†å†™å®ç°
- **ç”Ÿæˆåº”ç”¨æ‰©å±•**ï¼šçªå‡ºæ•°æ®å¢å¼ºã€å¼‚å¸¸æ£€æµ‹ã€ä¿¡å·åˆæˆèƒ½åŠ›

### æ ¸å¿ƒæŠ€æœ¯ç‰¹ç‚¹

- **çŸ«æ­£æµåŒ¹é…ï¼ˆRectified Flow Matchingï¼‰**ï¼šå™ªå£°ä¸æ•°æ®åˆ†å¸ƒä¹‹é—´çš„ç›´æ¥çº¿æ€§æ’å€¼
- **å±‚æ¬¡å¯¹æ¯”å­¦ä¹ ï¼ˆHierarchical Contrastive Learningï¼‰**ï¼šæ½œåœ¨ç©ºé—´ä¸­çš„ åŸŸ > ç³»ç»Ÿ > å®ä¾‹ ç»„ç»‡ç»“æ„
- **å¤šç›®æ ‡æŸå¤±å‡½æ•°ï¼ˆMulti-Objective Loss Functionï¼‰**ï¼šç»“åˆé‡å»ºã€æµã€å¯¹æ¯”å’Œå±‚æ¬¡ç›®æ ‡
- **æ¡ä»¶ç”Ÿæˆï¼ˆConditional Generationï¼‰**ï¼šåŸºäºåŸŸå’Œç³»ç»Ÿçš„å¯æ§ç”Ÿæˆ

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç”Ÿæˆæ¨¡å‹æŠ€æœ¯åŸºç¡€

### 1.1 ç”Ÿæˆæ¨¡å‹å®šä½

#### æ ¸å¿ƒç”Ÿæˆèƒ½åŠ›
- **æ•°æ®ç”Ÿæˆ**ï¼šåˆæˆå…·æœ‰ç‰¹å®šåŸŸå’Œç³»ç»Ÿç‰¹å¾çš„æŒ¯åŠ¨ä¿¡å·
- **å¼‚å¸¸ç”Ÿæˆ**ï¼šç”Ÿæˆå„ç§æ•…éšœæ¨¡å¼çš„ä¿¡å·ç”¨äºè®­ç»ƒ
- **æ•°æ®å¢å¼º**ï¼šå¹³è¡¡æ•°æ®é›†ä¸­çš„ç±»åˆ«åˆ†å¸ƒ
- **æ’å€¼ç”Ÿæˆ**ï¼šåœ¨ä¸åŒçŠ¶æ€ä¹‹é—´ç”Ÿæˆä¸­é—´æ€ä¿¡å·

#### ç”Ÿæˆæ¨¡å‹çš„ä¸‰å¤§åº”ç”¨åœºæ™¯
```python
# 1. æ•°æ®å¢å¼º
synthetic_signals = gm_model.generate(
    domain_id=1, system_id=2, num_samples=1000, 
    condition_type="fault_class_0"
)

# 2. å¼‚å¸¸æ£€æµ‹
anomaly_score = gm_model.likelihood_score(signal)
is_anomaly = anomaly_score < threshold

# 3. ä¿¡å·ä¿®å¤
restored_signal = gm_model.inpaint(
    corrupted_signal, mask=missing_indices
)
```

### 1.2 çŸ«æ­£æµç”ŸæˆåŸç†

#### æµåŒ¹é…ç”Ÿæˆè¿‡ç¨‹
```python
# ç”Ÿæˆè¿‡ç¨‹ï¼šä»å™ªå£°åˆ°æ•°æ®
def generate_sample(self, condition, num_steps=50):
    """ä»éšæœºå™ªå£°ç”Ÿæˆé«˜è´¨é‡ä¿¡å·"""
    # 1. ä»æ ‡å‡†é«˜æ–¯åˆ†å¸ƒé‡‡æ ·å™ªå£°
    z = torch.randn(batch_size, latent_dim)
    
    # 2. é€šè¿‡æµåŒ¹é…ç§¯åˆ†ç”Ÿæˆ
    dt = 1.0 / num_steps
    for step in range(num_steps):
        t = torch.ones(batch_size, 1) * step * dt
        v = self.flow_net(z, t, condition)  # é¢„æµ‹é€Ÿåº¦
        z = z + v * dt  # æ¬§æ‹‰ç§¯åˆ†
    
    # 3. è§£ç åˆ°ä¿¡å·ç©ºé—´
    signal = self.decoder(z)
    return signal
```

### 1.3 å±‚æ¬¡æ¡ä»¶ç”Ÿæˆ

#### å¤šçº§æ¡ä»¶æ§åˆ¶
- **åŸŸçº§æ§åˆ¶**ï¼šä¸åŒå·¥ä¸šç¯å¢ƒï¼ˆè½´æ‰¿ã€é½¿è½®ã€æ³µç­‰ï¼‰
- **ç³»ç»Ÿçº§æ§åˆ¶**ï¼šç‰¹å®šè®¾å¤‡å‹å·å’Œé…ç½®
- **å®ä¾‹çº§æ§åˆ¶**ï¼šå…·ä½“çš„è¿è¡ŒçŠ¶æ€å’Œæ•…éšœç±»å‹

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šç”Ÿæˆæ¨¡å‹æ¶æ„è®¾è®¡

### 2.1 çŸ«æ­£æµç”Ÿæˆç½‘ç»œ

#### ä½ç½®ï¼š`src/model_factory/ISFM/generative/GM_01_RectifiedFlow.py`

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np

class GM_01_RectifiedFlow(nn.Module):
    """
    çŸ«æ­£æµç”Ÿæˆç½‘ç»œ - å·¥ä¸šä¿¡å·ç”Ÿæˆçš„æ ¸å¿ƒç»„ä»¶
    
    åŠŸèƒ½ï¼š
    - é€Ÿåº¦åœºé¢„æµ‹ç”¨äºæµåŒ¹é…
    - æ”¯æŒæ¡ä»¶ç”Ÿæˆå’Œæ— æ¡ä»¶ç”Ÿæˆ
    - æ•°å€¼ç¨³å®šçš„æ—¶é—´åµŒå…¥
    - é«˜æ•ˆçš„æ‰¹é‡ç”Ÿæˆ
    
    Architecture:
    - Time embedding: sinusoidal + MLP
    - Condition fusion: cross-attention mechanism
    - Velocity network: ResNet-style with skip connections
    """
    
    def __init__(self, configs):
        super().__init__()
        self.latent_dim = configs.latent_dim
        self.condition_dim = configs.condition_dim
        self.hidden_dim = getattr(configs, 'flow_hidden_dim', 256)
        self.num_layers = getattr(configs, 'flow_num_layers', 3)
        
        # æ”¹è¿›çš„æ—¶é—´åµŒå…¥
        self.time_embed = SinusoidalTimeEmbedding(
            dim=self.hidden_dim // 4,
            max_period=10000
        )
        
        # æ¡ä»¶èåˆå±‚
        self.condition_fusion = nn.MultiheadAttention(
            embed_dim=self.condition_dim,
            num_heads=4,
            dropout=0.1,
            batch_first=True
        )
        
        # ä¸»ç”Ÿæˆç½‘ç»œï¼ˆResNeté£æ ¼ï¼‰
        self.input_proj = nn.Linear(
            self.latent_dim + self.condition_dim + self.hidden_dim // 4,
            self.hidden_dim
        )
        
        self.layers = nn.ModuleList([
            ResNetBlock(self.hidden_dim, dropout=0.1)
            for _ in range(self.num_layers)
        ])
        
        self.output_proj = nn.Linear(self.hidden_dim, self.latent_dim)
        
        # åˆå§‹åŒ–æƒé‡
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        """Xavieråˆå§‹åŒ–æƒé‡"""
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
    
    def forward(self, z_t, t, condition):
        """
        é¢„æµ‹ç»™å®šçŠ¶æ€ä¸‹çš„é€Ÿåº¦åœº
        
        Args:
            z_t: æ’å€¼çŠ¶æ€ (B, latent_dim)
            t: æ—¶é—´å‚æ•° (B, 1), èŒƒå›´[0,1]
            condition: æ¡ä»¶å‘é‡ (B, condition_dim)
            
        Returns:
            v_pred: é¢„æµ‹é€Ÿåº¦ (B, latent_dim)
        """
        batch_size = z_t.shape[0]
        
        # æ—¶é—´åµŒå…¥
        t_embed = self.time_embed(t)  # (B, hidden_dim//4)
        
        # æ¡ä»¶èåˆï¼ˆè‡ªæ³¨æ„åŠ›ï¼‰
        condition_fused, _ = self.condition_fusion(
            condition.unsqueeze(1), condition.unsqueeze(1), condition.unsqueeze(1)
        )
        condition_fused = condition_fused.squeeze(1)  # (B, condition_dim)
        
        # ç‰¹å¾èåˆ
        x = torch.cat([z_t, condition_fused, t_embed], dim=1)
        x = self.input_proj(x)
        
        # ResNetå‰å‘ä¼ æ’­
        for layer in self.layers:
            x = layer(x)
        
        # è¾“å‡ºé€Ÿåº¦
        v_pred = self.output_proj(x)
        
        return v_pred
    
    def generate(self, condition, num_samples=1, num_steps=50, 
                 temperature=1.0, device='cuda'):
        """
        ç”Ÿæˆæ–°çš„ä¿¡å·æ ·æœ¬
        
        Args:
            condition: ç”Ÿæˆæ¡ä»¶ (B, condition_dim)
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            num_steps: ç§¯åˆ†æ­¥æ•°
            temperature: æ¸©åº¦å‚æ•°æ§åˆ¶å¤šæ ·æ€§
            
        Returns:
            samples: ç”Ÿæˆçš„æ½œåœ¨å‘é‡ (num_samples, latent_dim)
        """
        self.eval()
        with torch.no_grad():
            # åˆå§‹å™ªå£°
            z = torch.randn(num_samples, self.latent_dim, device=device) * temperature
            
            # æ‰©å±•æ¡ä»¶
            if condition.shape[0] == 1:
                condition = condition.expand(num_samples, -1)
            
            # æµåŒ¹é…ç§¯åˆ†
            dt = 1.0 / num_steps
            for step in range(num_steps):
                t = torch.ones(num_samples, 1, device=device) * step * dt
                v = self.forward(z, t, condition)
                z = z + v * dt
                
        return z

class SinusoidalTimeEmbedding(nn.Module):
    """æ­£å¼¦æ—¶é—´åµŒå…¥"""
    def __init__(self, dim, max_period=10000):
        super().__init__()
        self.dim = dim
        self.max_period = max_period
        
    def forward(self, t):
        """
        Args:
            t: (B, 1) æ—¶é—´å‚æ•°
        Returns:
            (B, dim) æ—¶é—´åµŒå…¥
        """
        half_dim = self.dim // 2
        freqs = torch.exp(
            -np.log(self.max_period) * 
            torch.arange(half_dim, dtype=torch.float32, device=t.device) / half_dim
        )
        args = t.squeeze(-1)[:, None] * freqs[None, :]
        embedding = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)
        return embedding

class ResNetBlock(nn.Module):
    """ResNetæ®‹å·®å—"""
    def __init__(self, dim, dropout=0.1):
        super().__init__()
        self.layers = nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.SiLU(),
            nn.Dropout(dropout),
            nn.Linear(dim, dim),
        )
        
    def forward(self, x):
        return x + self.layers(x)

# ================ æ¨¡å—æµ‹è¯•ä»£ç  ================
if __name__ == '__main__':
    """çŸ«æ­£æµç”Ÿæˆç½‘ç»œæµ‹è¯•"""
    import time
    
    print("ğŸ§ª æµ‹è¯• GM_01_RectifiedFlow æ¨¡å—")
    print("=" * 50)
    
    # åˆ›å»ºmocké…ç½®
    class MockConfig:
        def __init__(self):
            self.latent_dim = 128
            self.condition_dim = 64
            self.flow_hidden_dim = 256
            self.flow_num_layers = 3
    
    config = MockConfig()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
    print("\n1ï¸âƒ£ æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•")
    try:
        model = GM_01_RectifiedFlow(config).to(device)
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)
    
    # 2. å‰å‘ä¼ æ’­æµ‹è¯•
    print("\n2ï¸âƒ£ å‰å‘ä¼ æ’­æµ‹è¯•")
    batch_size = 32
    z_t = torch.randn(batch_size, config.latent_dim, device=device)
    t = torch.rand(batch_size, 1, device=device)
    condition = torch.randn(batch_size, config.condition_dim, device=device)
    
    try:
        start_time = time.time()
        v_pred = model(z_t, t, condition)
        forward_time = time.time() - start_time
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: z_t={z_t.shape}, t={t.shape}, condition={condition.shape}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {v_pred.shape}")
        print(f"   æ¨ç†æ—¶é—´: {forward_time:.4f}s")
        print(f"   è¾“å‡ºèŒƒå›´: [{v_pred.min().item():.4f}, {v_pred.max().item():.4f}]")
        
        # éªŒè¯è¾“å‡ºå½¢çŠ¶
        assert v_pred.shape == (batch_size, config.latent_dim), f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {v_pred.shape}"
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        exit(1)
    
    # 3. æ¢¯åº¦æµ‹è¯•
    print("\n3ï¸âƒ£ æ¢¯åº¦æµæµ‹è¯•")
    try:
        loss = v_pred.mean()
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        has_grad = 0
        total_params = 0
        for name, param in model.named_parameters():
            if param.requires_grad:
                total_params += 1
                if param.grad is not None:
                    has_grad += 1
                    grad_norm = param.grad.norm().item()
                    if grad_norm < 1e-7:
                        print(f"âš ï¸  å‚æ•° {name} æ¢¯åº¦è¿‡å°: {grad_norm:.2e}")
                    elif grad_norm > 10:
                        print(f"âš ï¸  å‚æ•° {name} æ¢¯åº¦è¿‡å¤§: {grad_norm:.2e}")
        
        print(f"âœ… æ¢¯åº¦è®¡ç®—æˆåŠŸ")
        print(f"   æœ‰æ¢¯åº¦çš„å‚æ•°: {has_grad}/{total_params}")
        
        # æ¸…é™¤æ¢¯åº¦
        model.zero_grad()
        
    except Exception as e:
        print(f"âŒ æ¢¯åº¦è®¡ç®—å¤±è´¥: {e}")
        exit(1)
    
    # 4. ç”Ÿæˆæµ‹è¯•
    print("\n4ï¸âƒ£ ä¿¡å·ç”Ÿæˆæµ‹è¯•")
    try:
        num_samples = 8
        condition_single = torch.randn(1, config.condition_dim, device=device)
        
        start_time = time.time()
        generated = model.generate(
            condition=condition_single,
            num_samples=num_samples,
            num_steps=20,  # å‡å°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
            temperature=1.0,
            device=device
        )
        generation_time = time.time() - start_time
        
        print(f"âœ… ä¿¡å·ç”ŸæˆæˆåŠŸ")
        print(f"   ç”Ÿæˆæ ·æœ¬æ•°: {num_samples}")
        print(f"   ç”Ÿæˆå½¢çŠ¶: {generated.shape}")
        print(f"   ç”Ÿæˆæ—¶é—´: {generation_time:.4f}s")
        print(f"   æ¯æ ·æœ¬æ—¶é—´: {generation_time/num_samples:.4f}s")
        
        # éªŒè¯ç”Ÿæˆè´¨é‡
        gen_mean = generated.mean().item()
        gen_std = generated.std().item()
        print(f"   ç”Ÿæˆç»Ÿè®¡: å‡å€¼={gen_mean:.4f}, æ ‡å‡†å·®={gen_std:.4f}")
        
    except Exception as e:
        print(f"âŒ ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
        exit(1)
    
    # 5. æ‰¹é‡ç”Ÿæˆæµ‹è¯•
    print("\n5ï¸âƒ£ æ‰¹é‡ç”Ÿæˆæ€§èƒ½æµ‹è¯•")
    try:
        batch_sizes = [1, 4, 16, 64]
        for bs in batch_sizes:
            condition_batch = torch.randn(bs, config.condition_dim, device=device)
            
            start_time = time.time()
            batch_generated = model.generate(
                condition=condition_batch,
                num_samples=bs,
                num_steps=10,
                device=device
            )
            batch_time = time.time() - start_time
            
            print(f"   æ‰¹æ¬¡å¤§å° {bs:2d}: {batch_time:.4f}s ({batch_time/bs:.4f}s/æ ·æœ¬)")
            
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
    
    # 6. å†…å­˜ä½¿ç”¨æµ‹è¯•
    print("\n6ï¸âƒ£ å†…å­˜ä½¿ç”¨æµ‹è¯•")
    if device == 'cuda':
        try:
            torch.cuda.empty_cache()
            memory_before = torch.cuda.memory_allocated()
            
            # å¤§æ‰¹æ¬¡æµ‹è¯•
            large_batch = 128
            z_large = torch.randn(large_batch, config.latent_dim, device=device)
            t_large = torch.rand(large_batch, 1, device=device)
            condition_large = torch.randn(large_batch, config.condition_dim, device=device)
            
            v_large = model(z_large, t_large, condition_large)
            
            memory_after = torch.cuda.memory_allocated()
            memory_used = (memory_after - memory_before) / 1024**2  # MB
            
            print(f"âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•å®Œæˆ")
            print(f"   æ‰¹æ¬¡å¤§å°: {large_batch}")
            print(f"   å†…å­˜ä½¿ç”¨: {memory_used:.2f} MB")
            
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"âŒ å†…å­˜æµ‹è¯•å¤±è´¥: {e}")
    else:
        print("â„¹ï¸  CPUæ¨¡å¼ï¼Œè·³è¿‡GPUå†…å­˜æµ‹è¯•")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    print("æ¨¡å—çŠ¶æ€ï¼šâœ… å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
```

### 2.2 æ¡ä»¶ç¼–ç å™¨å¢å¼º

#### ä½ç½®ï¼š`src/model_factory/ISFM/encoder/E_03_ConditionalEncoder.py`

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Optional, Tuple

class E_03_ConditionalEncoder(nn.Module):
    """
    æ¡ä»¶ç¼–ç å™¨ - æ”¯æŒå±‚æ¬¡åŒ–åŸŸå’Œç³»ç»Ÿæ¡ä»¶
    
    åŠŸèƒ½ï¼š
    - åŸŸåµŒå…¥ï¼šè·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›
    - ç³»ç»ŸåµŒå…¥ï¼šè®¾å¤‡ç‰¹å®šæ¨¡å¼è¯†åˆ«
    - å±‚æ¬¡åŒ–ç‰¹å¾æå–ï¼šå¤šçº§æŠ½è±¡
    - æ³¨æ„åŠ›æœºåˆ¶ï¼šå…³é”®ç‰¹å¾èšç„¦
    
    Architecture:
    - Hierarchical embeddings with learnable positions
    - Multi-head self-attention for feature refinement
    - Residual connections and layer normalization
    - Adaptive feature scaling based on domain/system
    """
    
    def __init__(self, configs):
        super().__init__()
        self.input_dim = configs.input_dim
        self.latent_dim = configs.latent_dim
        self.num_domains = getattr(configs, 'num_domains', 2)
        self.num_systems = getattr(configs, 'num_systems', 2)
        self.cond_embed_dim = getattr(configs, 'cond_embed_dim', 32)
        self.use_attention = getattr(configs, 'use_attention', True)
        
        # å±‚æ¬¡åŒ–åµŒå…¥
        self.domain_embed = nn.Embedding(self.num_domains, self.cond_embed_dim)
        self.system_embed = nn.Embedding(self.num_systems, self.cond_embed_dim)
        
        # ä½ç½®ç¼–ç ï¼ˆå¯å­¦ä¹ ï¼‰
        self.domain_pos_embed = nn.Parameter(torch.randn(1, self.cond_embed_dim))
        self.system_pos_embed = nn.Parameter(torch.randn(1, self.cond_embed_dim))
        
        # æ¡ä»¶èåˆå±‚
        total_cond_dim = 2 * self.cond_embed_dim
        self.condition_proj = nn.Linear(total_cond_dim, self.cond_embed_dim)
        
        # ä¸»ç¼–ç ç½‘ç»œ
        total_input_dim = self.input_dim + self.cond_embed_dim
        
        # å¤šå±‚ç¼–ç å™¨
        self.input_proj = nn.Linear(total_input_dim, 256)
        self.encoder_layers = nn.ModuleList([
            EncoderBlock(256, num_heads=8, dropout=0.1),
            EncoderBlock(256, num_heads=8, dropout=0.1),
            EncoderBlock(256, num_heads=4, dropout=0.1),
        ])
        
        self.output_proj = nn.Linear(256, self.latent_dim)
        
        # è‡ªé€‚åº”ç‰¹å¾ç¼©æ”¾
        self.feature_scale = AdaptiveFeatureScaling(
            self.latent_dim, self.num_domains, self.num_systems
        )
        
        # åˆå§‹åŒ–
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        """æƒé‡åˆå§‹åŒ–"""
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, std=0.02)
    
    def forward(self, x, domain_id, system_id):
        """
        æ¡ä»¶ç¼–ç å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ä¿¡å· (B, input_dim)
            domain_id: åŸŸID (B,) 
            system_id: ç³»ç»ŸID (B,)
            
        Returns:
            h: æ½œåœ¨è¡¨ç¤º (B, latent_dim)
        """
        batch_size = x.shape[0]
        
        # 1. è·å–å±‚æ¬¡åµŒå…¥
        domain_emb = self.domain_embed(domain_id) + self.domain_pos_embed
        system_emb = self.system_embed(system_id) + self.system_pos_embed
        
        # 2. èåˆæ¡ä»¶ä¿¡æ¯
        condition = torch.cat([domain_emb, system_emb], dim=1)  # (B, 2*cond_embed_dim)
        condition_fused = self.condition_proj(condition)  # (B, cond_embed_dim)
        
        # 3. è¾“å…¥ä¸æ¡ä»¶èåˆ
        x_cond = torch.cat([x, condition_fused], dim=1)  # (B, input_dim + cond_embed_dim)
        
        # 4. ç¼–ç å¤„ç†
        h = self.input_proj(x_cond)  # (B, 256)
        
        # é€šè¿‡ç¼–ç å™¨å±‚
        for layer in self.encoder_layers:
            h = layer(h)
        
        # 5. è¾“å‡ºæŠ•å½±
        h = self.output_proj(h)  # (B, latent_dim)
        
        # 6. è‡ªé€‚åº”ç‰¹å¾ç¼©æ”¾
        h = self.feature_scale(h, domain_id, system_id)
        
        return h
    
    def get_condition_embedding(self, domain_id, system_id):
        """è·å–æ¡ä»¶åµŒå…¥ï¼ˆç”¨äºç”Ÿæˆï¼‰"""
        domain_emb = self.domain_embed(domain_id) + self.domain_pos_embed
        system_emb = self.system_embed(system_id) + self.system_pos_embed
        condition = torch.cat([domain_emb, system_emb], dim=1)
        return self.condition_proj(condition)

class EncoderBlock(nn.Module):
    """ç¼–ç å™¨å—"""
    def __init__(self, dim, num_heads=8, dropout=0.1):
        super().__init__()
        self.attention = nn.MultiheadAttention(
            embed_dim=dim, num_heads=num_heads, dropout=dropout, batch_first=True
        )
        self.norm1 = nn.LayerNorm(dim)
        self.ffn = nn.Sequential(
            nn.Linear(dim, dim * 4),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * 4, dim),
        )
        self.norm2 = nn.LayerNorm(dim)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # x shape: (B, dim)
        x = x.unsqueeze(1)  # (B, 1, dim) for attention
        
        # Self-attention
        attn_out, _ = self.attention(x, x, x)
        x = self.norm1(x + self.dropout(attn_out))
        
        # FFN
        ffn_out = self.ffn(x)
        x = self.norm2(x + self.dropout(ffn_out))
        
        return x.squeeze(1)  # (B, dim)

class AdaptiveFeatureScaling(nn.Module):
    """åŸºäºåŸŸå’Œç³»ç»Ÿçš„è‡ªé€‚åº”ç‰¹å¾ç¼©æ”¾"""
    def __init__(self, feature_dim, num_domains, num_systems):
        super().__init__()
        self.domain_scale = nn.Embedding(num_domains, feature_dim)
        self.system_scale = nn.Embedding(num_systems, feature_dim)
        
        # åˆå§‹åŒ–ä¸ºæ¥è¿‘1çš„å€¼
        nn.init.normal_(self.domain_scale.weight, mean=1.0, std=0.1)
        nn.init.normal_(self.system_scale.weight, mean=1.0, std=0.1)
    
    def forward(self, features, domain_id, system_id):
        domain_scale = torch.sigmoid(self.domain_scale(domain_id))  # (B, feature_dim)
        system_scale = torch.sigmoid(self.system_scale(system_id))  # (B, feature_dim)
        
        # ç»„åˆç¼©æ”¾
        combined_scale = domain_scale * system_scale
        return features * combined_scale

# ================ æ¨¡å—æµ‹è¯•ä»£ç  ================
if __name__ == '__main__':
    """æ¡ä»¶ç¼–ç å™¨æµ‹è¯•"""
    import time
    from collections import defaultdict
    
    print("ğŸ§ª æµ‹è¯• E_03_ConditionalEncoder æ¨¡å—")
    print("=" * 50)
    
    # Mocké…ç½®
    class MockConfig:
        def __init__(self):
            self.input_dim = 1024  # ä¿¡å·ç»´åº¦
            self.latent_dim = 128
            self.num_domains = 4    # 4ä¸ªåŸŸ
            self.num_systems = 8    # 8ä¸ªç³»ç»Ÿ
            self.cond_embed_dim = 32
            self.use_attention = True
    
    config = MockConfig()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
    print("\n1ï¸âƒ£ æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•")
    try:
        model = E_03_ConditionalEncoder(config).to(device)
        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ€»å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # åˆ†æå‚æ•°åˆ†å¸ƒ
        param_groups = defaultdict(int)
        for name, param in model.named_parameters():
            if 'embed' in name:
                param_groups['embedding'] += param.numel()
            elif 'attention' in name:
                param_groups['attention'] += param.numel()
            elif 'ffn' in name:
                param_groups['feedforward'] += param.numel()
            else:
                param_groups['other'] += param.numel()
        
        print("   å‚æ•°åˆ†å¸ƒ:")
        for group, count in param_groups.items():
            print(f"     {group}: {count:,}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)
    
    # 2. å‰å‘ä¼ æ’­æµ‹è¯•
    print("\n2ï¸âƒ£ å‰å‘ä¼ æ’­æµ‹è¯•")
    batch_size = 32
    x = torch.randn(batch_size, config.input_dim, device=device)
    domain_ids = torch.randint(0, config.num_domains, (batch_size,), device=device)
    system_ids = torch.randint(0, config.num_systems, (batch_size,), device=device)
    
    try:
        start_time = time.time()
        h = model(x, domain_ids, system_ids)
        forward_time = time.time() - start_time
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å…¥å½¢çŠ¶: x={x.shape}")
        print(f"   åŸŸIDèŒƒå›´: {domain_ids.min().item()} - {domain_ids.max().item()}")
        print(f"   ç³»ç»ŸIDèŒƒå›´: {system_ids.min().item()} - {system_ids.max().item()}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {h.shape}")
        print(f"   æ¨ç†æ—¶é—´: {forward_time:.4f}s")
        
        # éªŒè¯è¾“å‡º
        assert h.shape == (batch_size, config.latent_dim)
        print(f"   è¾“å‡ºç»Ÿè®¡: å‡å€¼={h.mean().item():.4f}, æ ‡å‡†å·®={h.std().item():.4f}")
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        exit(1)
    
    # 3. æ¡ä»¶åµŒå…¥æµ‹è¯•
    print("\n3ï¸âƒ£ æ¡ä»¶åµŒå…¥æµ‹è¯•")
    try:
        # æµ‹è¯•ä¸åŒæ¡ä»¶çš„åµŒå…¥å·®å¼‚
        domain1 = torch.tensor([0], device=device)
        domain2 = torch.tensor([1], device=device)
        system1 = torch.tensor([0], device=device)
        system2 = torch.tensor([1], device=device)
        
        emb1 = model.get_condition_embedding(domain1, system1)
        emb2 = model.get_condition_embedding(domain1, system2)  # ä¸åŒç³»ç»Ÿ
        emb3 = model.get_condition_embedding(domain2, system1)  # ä¸åŒåŸŸ
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        sim_system = F.cosine_similarity(emb1, emb2, dim=1).item()
        sim_domain = F.cosine_similarity(emb1, emb3, dim=1).item()
        
        print(f"âœ… æ¡ä»¶åµŒå…¥æµ‹è¯•å®Œæˆ")
        print(f"   åµŒå…¥ç»´åº¦: {emb1.shape}")
        print(f"   åŒåŸŸä¸åŒç³»ç»Ÿç›¸ä¼¼åº¦: {sim_system:.4f}")
        print(f"   ä¸åŒåŸŸåŒç³»ç»Ÿç›¸ä¼¼åº¦: {sim_domain:.4f}")
        
        # ç†æƒ³æƒ…å†µä¸‹ï¼ŒåŒåŸŸä¸åŒç³»ç»Ÿåº”è¯¥æ¯”ä¸åŒåŸŸæ›´ç›¸ä¼¼
        if sim_system > sim_domain:
            print("   âœ… å±‚æ¬¡åŒ–åµŒå…¥æ­£å¸¸ï¼šåŒåŸŸå†…ç›¸ä¼¼åº¦æ›´é«˜")
        else:
            print("   âš ï¸  å±‚æ¬¡åŒ–åµŒå…¥å¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒ")
            
    except Exception as e:
        print(f"âŒ æ¡ä»¶åµŒå…¥æµ‹è¯•å¤±è´¥: {e}")
    
    # 4. æ¢¯åº¦æµæµ‹è¯•
    print("\n4ï¸âƒ£ æ¢¯åº¦æµæµ‹è¯•")
    try:
        # è®¡ç®—ä¸€ä¸ªç®€å•æŸå¤±
        target = torch.randn_like(h)
        loss = F.mse_loss(h, target)
        loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        grad_stats = {}
        for name, param in model.named_parameters():
            if param.requires_grad and param.grad is not None:
                grad_norm = param.grad.norm().item()
                if 'embed' in name:
                    grad_stats.setdefault('embedding', []).append(grad_norm)
                elif 'attention' in name:
                    grad_stats.setdefault('attention', []).append(grad_norm)
                else:
                    grad_stats.setdefault('other', []).append(grad_norm)
        
        print(f"âœ… æ¢¯åº¦è®¡ç®—æˆåŠŸ")
        print("   æ¢¯åº¦ç»Ÿè®¡:")
        for component, norms in grad_stats.items():
            avg_norm = np.mean(norms)
            print(f"     {component}: å¹³å‡={avg_norm:.6f}, èŒƒå›´=[{min(norms):.6f}, {max(norms):.6f}]")
            
        model.zero_grad()
        
    except Exception as e:
        print(f"âŒ æ¢¯åº¦æµ‹è¯•å¤±è´¥: {e}")
    
    # 5. æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•
    print("\n5ï¸âƒ£ æ‰¹é‡å¤„ç†æ€§èƒ½æµ‹è¯•")
    batch_sizes = [1, 8, 32, 128]
    for bs in batch_sizes:
        try:
            x_batch = torch.randn(bs, config.input_dim, device=device)
            d_batch = torch.randint(0, config.num_domains, (bs,), device=device)
            s_batch = torch.randint(0, config.num_systems, (bs,), device=device)
            
            start_time = time.time()
            h_batch = model(x_batch, d_batch, s_batch)
            batch_time = time.time() - start_time
            
            print(f"   æ‰¹æ¬¡ {bs:3d}: {batch_time:.4f}s ({batch_time/bs*1000:.2f}ms/æ ·æœ¬)")
            
        except Exception as e:
            print(f"   æ‰¹æ¬¡ {bs} å¤±è´¥: {e}")
    
    # 6. å†…å­˜æ•ˆç‡æµ‹è¯•
    print("\n6ï¸âƒ£ å†…å­˜ä½¿ç”¨æµ‹è¯•")
    if device == 'cuda':
        try:
            torch.cuda.empty_cache()
            memory_start = torch.cuda.memory_allocated()
            
            # å¤§æ‰¹æ¬¡å¤„ç†
            large_batch = 256
            x_large = torch.randn(large_batch, config.input_dim, device=device)
            d_large = torch.randint(0, config.num_domains, (large_batch,), device=device)
            s_large = torch.randint(0, config.num_systems, (large_batch,), device=device)
            
            h_large = model(x_large, d_large, s_large)
            
            memory_end = torch.cuda.memory_allocated()
            memory_used = (memory_end - memory_start) / 1024**2
            
            print(f"âœ… å†…å­˜ä½¿ç”¨: {memory_used:.2f} MB (æ‰¹æ¬¡={large_batch})")
            print(f"   å•æ ·æœ¬å†…å­˜: {memory_used/large_batch:.4f} MB")
            
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"âŒ å†…å­˜æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ æ¡ä»¶ç¼–ç å™¨æµ‹è¯•å®Œæˆï¼")
    print("=" * 50)
    print("æ¨¡å—çŠ¶æ€ï¼šâœ… å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
```

### 2.3 ç”Ÿæˆæ¨¡å‹ä¸»ä½“

#### ä½ç½®ï¼š`src/model_factory/ISFM/M_04_ISFM_GM.py`

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Optional, Tuple, Union
from .generative.GM_01_RectifiedFlow import GM_01_RectifiedFlow
from .encoder.E_03_ConditionalEncoder import E_03_ConditionalEncoder

class Model(nn.Module):
    """
    ISFMç”Ÿæˆæ¨¡å‹ - å·¥ä¸šä¿¡å·åŸºç¡€ç”Ÿæˆæ¨¡å‹
    
    åŠŸèƒ½ç‰¹ç‚¹:
    - æ¡ä»¶ç”Ÿæˆï¼šåŸºäºåŸŸå’Œç³»ç»Ÿçš„å¯æ§ç”Ÿæˆ
    - ä¿¡å·é‡å»ºï¼šé«˜ä¿çœŸåº¦ä¿¡å·é‡æ„
    - å¼‚å¸¸æ£€æµ‹ï¼šé€šè¿‡é‡å»ºè¯¯å·®æ£€æµ‹å¼‚å¸¸
    - æ•°æ®å¢å¼ºï¼šç”Ÿæˆå¹³è¡¡çš„è®­ç»ƒæ•°æ®
    
    Architecture:
    - Conditional encoder with hierarchical embeddings
    - Rectified flow generative model
    - Multi-task output heads (reconstruction + generation)
    - Optional classifier for supervised guidance
    """
    
    def __init__(self, args_m, metadata):
        super().__init__()
        self.args_m = args_m
        self.metadata = metadata
        
        # æ ¸å¿ƒç”Ÿæˆç»„ä»¶
        self.encoder = E_03_ConditionalEncoder(args_m)
        
        # è§£ç å™¨ï¼ˆé‡å»ºç½‘ç»œï¼‰
        self.decoder = GenerativeDecoder(
            latent_dim=args_m.latent_dim,
            output_dim=args_m.input_dim,
            hidden_dim=getattr(args_m, 'decoder_hidden_dim', 256),
            num_layers=getattr(args_m, 'decoder_num_layers', 3)
        )
        
        # æµç”Ÿæˆç½‘ç»œ
        self.flow_net = GM_01_RectifiedFlow(args_m)
        
        # å¯é€‰åˆ†ç±»å™¨
        if getattr(args_m, 'use_classifier', False):
            self.classifier = nn.Sequential(
                nn.Linear(args_m.latent_dim, 256),
                nn.ReLU(),
                nn.Dropout(0.1),
                nn.Linear(256, args_m.num_classes)
            )
        else:
            self.classifier = None
            
        # EMAæ¨¡å‹ï¼ˆç”¨äºæ›´ç¨³å®šçš„ç”Ÿæˆï¼‰
        self.use_ema = getattr(args_m, 'use_ema', True)
        if self.use_ema:
            self.ema_decay = getattr(args_m, 'ema_decay', 0.995)
            self.ema_model = self._create_ema_model()
            
        # ç”Ÿæˆå‚æ•°
        self.generation_config = GenerationConfig(args_m)
        
    def _create_ema_model(self):
        """åˆ›å»ºEMAæ¨¡å‹"""
        ema_model = type(self)(self.args_m, self.metadata)
        ema_model.load_state_dict(self.state_dict())
        for param in ema_model.parameters():
            param.requires_grad_(False)
        return ema_model
    
    def update_ema(self):
        """æ›´æ–°EMAæ¨¡å‹"""
        if not self.use_ema:
            return
            
        with torch.no_grad():
            for ema_param, current_param in zip(
                self.ema_model.parameters(), self.parameters()
            ):
                ema_param.data.mul_(self.ema_decay).add_(
                    current_param.data, alpha=1 - self.ema_decay
                )
    
    def forward(self, x, domain_id, system_id, t=None, return_components=False):
        """
        å‰å‘ä¼ æ’­ - æ”¯æŒè®­ç»ƒå’Œç”Ÿæˆä¸¤ç§æ¨¡å¼
        
        Args:
            x: è¾“å…¥ä¿¡å· (B, input_dim)
            domain_id: åŸŸID (B,)
            system_id: ç³»ç»ŸID (B,)
            t: æ—¶é—´å‚æ•° (B, 1) - è®­ç»ƒæ—¶ä½¿ç”¨
            return_components: æ˜¯å¦è¿”å›æ‰€æœ‰ç»„ä»¶
            
        Returns:
            æ ¹æ®return_componentsè¿”å›ä¸åŒå†…å®¹
        """
        # 1. æ¡ä»¶ç¼–ç 
        h = self.encoder(x, domain_id, system_id)
        
        # 2. ä¿¡å·é‡å»º
        x_recon = self.decoder(h)
        
        # 3. æµé¢„æµ‹ï¼ˆè®­ç»ƒæ—¶ï¼‰
        v_pred = None
        if t is not None:
            # è·å–æ¡ä»¶åµŒå…¥
            condition = self.encoder.get_condition_embedding(domain_id, system_id)
            
            # åˆ›å»ºæ’å€¼çŠ¶æ€
            z0 = torch.randn_like(h)
            z_t = (1 - t) * z0 + t * h
            
            # é¢„æµ‹é€Ÿåº¦
            v_pred = self.flow_net(z_t, t, condition)
        
        # 4. åˆ†ç±»ï¼ˆå¯é€‰ï¼‰
        y_pred = None
        if self.classifier is not None:
            y_pred = self.classifier(h)
        
        if return_components:
            return x_recon, h, v_pred, y_pred
        else:
            return x_recon
    
    def generate(self, domain_id, system_id, num_samples=1, 
                 num_steps=50, temperature=1.0, use_ema=None):
        """
        ç”Ÿæˆæ–°çš„ä¿¡å·æ ·æœ¬
        
        Args:
            domain_id: ç›®æ ‡åŸŸID (1,) æˆ– (num_samples,)
            system_id: ç›®æ ‡ç³»ç»ŸID (1,) æˆ– (num_samples,)
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            num_steps: æµåŒ¹é…ç§¯åˆ†æ­¥æ•°
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶å¤šæ ·æ€§ï¼‰
            use_ema: æ˜¯å¦ä½¿ç”¨EMAæ¨¡å‹
            
        Returns:
            generated_signals: ç”Ÿæˆçš„ä¿¡å· (num_samples, input_dim)
        """
        if use_ema is None:
            use_ema = self.use_ema
            
        # é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹
        model_to_use = self.ema_model if (use_ema and hasattr(self, 'ema_model')) else self
        
        model_to_use.eval()
        with torch.no_grad():
            device = next(model_to_use.parameters()).device
            
            # æ‰©å±•IDåˆ°æ‰€éœ€æ ·æœ¬æ•°
            if domain_id.shape[0] == 1:
                domain_id = domain_id.expand(num_samples)
            if system_id.shape[0] == 1:
                system_id = system_id.expand(num_samples)
                
            # è·å–æ¡ä»¶åµŒå…¥
            condition = model_to_use.encoder.get_condition_embedding(domain_id, system_id)
            
            # æµç”Ÿæˆ
            z_generated = model_to_use.flow_net.generate(
                condition=condition,
                num_samples=num_samples,
                num_steps=num_steps,
                temperature=temperature,
                device=device
            )
            
            # è§£ç åˆ°ä¿¡å·ç©ºé—´
            generated_signals = model_to_use.decoder(z_generated)
            
        return generated_signals
    
    def interpolate(self, signal1, signal2, domain_id, system_id, 
                   num_steps=10, interpolation_mode='spherical'):
        """
        åœ¨ä¸¤ä¸ªä¿¡å·ä¹‹é—´è¿›è¡Œæ’å€¼
        
        Args:
            signal1, signal2: è¾“å…¥ä¿¡å· (1, input_dim)
            domain_id, system_id: æ¡ä»¶ID (1,)
            num_steps: æ’å€¼æ­¥æ•°
            interpolation_mode: 'linear' æˆ– 'spherical'
            
        Returns:
            interpolated_signals: æ’å€¼ä¿¡å· (num_steps, input_dim)
        """
        self.eval()
        with torch.no_grad():
            # ç¼–ç åˆ°æ½œåœ¨ç©ºé—´
            h1 = self.encoder(signal1, domain_id, system_id)
            h2 = self.encoder(signal2, domain_id, system_id)
            
            # æ’å€¼
            alphas = torch.linspace(0, 1, num_steps, device=h1.device)
            interpolated_h = []
            
            for alpha in alphas:
                if interpolation_mode == 'spherical':
                    # çƒé¢æ’å€¼
                    omega = torch.acos(torch.clamp(
                        (h1 * h2).sum(dim=1, keepdim=True) / 
                        (torch.norm(h1, dim=1, keepdim=True) * torch.norm(h2, dim=1, keepdim=True)),
                        -1, 1
                    ))
                    sin_omega = torch.sin(omega)
                    if sin_omega.abs() < 1e-6:
                        h_interp = (1 - alpha) * h1 + alpha * h2
                    else:
                        h_interp = (torch.sin((1 - alpha) * omega) * h1 + 
                                   torch.sin(alpha * omega) * h2) / sin_omega
                else:
                    # çº¿æ€§æ’å€¼
                    h_interp = (1 - alpha) * h1 + alpha * h2
                
                interpolated_h.append(h_interp)
            
            # æ‰¹é‡è§£ç 
            interpolated_h = torch.cat(interpolated_h, dim=0)
            interpolated_signals = self.decoder(interpolated_h)
            
        return interpolated_signals
    
    def compute_likelihood(self, x, domain_id, system_id, num_steps=50):
        """
        è®¡ç®—ä¿¡å·çš„ä¼¼ç„¶åº¦ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼‰
        
        Args:
            x: è¾“å…¥ä¿¡å· (B, input_dim)
            domain_id, system_id: æ¡ä»¶ID (B,)
            num_steps: æµåŒ¹é…æ­¥æ•°
            
        Returns:
            likelihood_scores: ä¼¼ç„¶åº¦åˆ†æ•° (B,)
        """
        self.eval()
        with torch.no_grad():
            # ç¼–ç 
            h = self.encoder(x, domain_id, system_id)
            condition = self.encoder.get_condition_embedding(domain_id, system_id)
            
            # é€šè¿‡é€†å‘æµåŒ¹é…è®¡ç®—ä¼¼ç„¶
            z = h.clone()
            log_likelihood = torch.zeros(h.shape[0], device=h.device)
            
            dt = 1.0 / num_steps
            for step in range(num_steps):
                t = torch.ones(h.shape[0], 1, device=h.device) * (1 - step * dt)
                
                # é¢„æµ‹é€Ÿåº¦
                v = self.flow_net(z, t, condition)
                
                # é€†å‘ç§¯åˆ†
                z = z - v * dt
                
                # ç´¯ç§¯logä¼¼ç„¶ï¼ˆè¿‘ä¼¼ï¼‰
                log_likelihood -= (v ** 2).sum(dim=1) * dt * 0.5
            
        return log_likelihood

class GenerativeDecoder(nn.Module):
    """ç”Ÿæˆè§£ç å™¨"""
    def __init__(self, latent_dim, output_dim, hidden_dim=256, num_layers=3):
        super().__init__()
        
        layers = []
        current_dim = latent_dim
        
        # éšè—å±‚
        for _ in range(num_layers):
            layers.extend([
                nn.Linear(current_dim, hidden_dim),
                nn.LayerNorm(hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.1)
            ])
            current_dim = hidden_dim
            
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(current_dim, output_dim))
        
        self.decoder = nn.Sequential(*layers)
        
    def forward(self, h):
        return self.decoder(h)

class GenerationConfig:
    """ç”Ÿæˆé…ç½®"""
    def __init__(self, args_m):
        self.num_steps = getattr(args_m, 'generation_steps', 50)
        self.temperature = getattr(args_m, 'generation_temperature', 1.0)
        self.use_ema = getattr(args_m, 'use_ema_for_generation', True)

# ================ æ¨¡å—æµ‹è¯•ä»£ç  ================
if __name__ == '__main__':
    """ISFMç”Ÿæˆæ¨¡å‹æµ‹è¯•"""
    import time
    import matplotlib.pyplot as plt
    
    print("ğŸ§ª æµ‹è¯• M_04_ISFM_GM æ¨¡å—")
    print("=" * 60)
    
    # Mocké…ç½®å’Œå…ƒæ•°æ®
    class MockConfig:
        def __init__(self):
            self.input_dim = 1024
            self.latent_dim = 128
            self.condition_dim = 64
            self.flow_hidden_dim = 256
            self.decoder_hidden_dim = 256
            self.num_domains = 3
            self.num_systems = 6
            self.cond_embed_dim = 32
            self.use_classifier = True
            self.num_classes = 5
            self.use_ema = True
            self.ema_decay = 0.995
    
    config = MockConfig()
    metadata = {}  # Mock metadata
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
    print("\n1ï¸âƒ£ ç”Ÿæˆæ¨¡å‹åˆå§‹åŒ–æµ‹è¯•")
    try:
        model = Model(config, metadata).to(device)
        print(f"âœ… ç”Ÿæˆæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"   æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        
        # ç»„ä»¶å‚æ•°ç»Ÿè®¡
        encoder_params = sum(p.numel() for p in model.encoder.parameters())
        decoder_params = sum(p.numel() for p in model.decoder.parameters())
        flow_params = sum(p.numel() for p in model.flow_net.parameters())
        
        print(f"   ç¼–ç å™¨å‚æ•°: {encoder_params:,}")
        print(f"   è§£ç å™¨å‚æ•°: {decoder_params:,}")
        print(f"   æµç½‘ç»œå‚æ•°: {flow_params:,}")
        
        if model.classifier:
            classifier_params = sum(p.numel() for p in model.classifier.parameters())
            print(f"   åˆ†ç±»å™¨å‚æ•°: {classifier_params:,}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)
    
    # 2. å‰å‘ä¼ æ’­æµ‹è¯•
    print("\n2ï¸âƒ£ å‰å‘ä¼ æ’­æµ‹è¯•")
    batch_size = 16
    x = torch.randn(batch_size, config.input_dim, device=device)
    domain_ids = torch.randint(0, config.num_domains, (batch_size,), device=device)
    system_ids = torch.randint(0, config.num_systems, (batch_size,), device=device)
    t = torch.rand(batch_size, 1, device=device)
    
    try:
        start_time = time.time()
        x_recon, h, v_pred, y_pred = model(
            x, domain_ids, system_ids, t=t, return_components=True
        )
        forward_time = time.time() - start_time
        
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   é‡å»ºä¿¡å·å½¢çŠ¶: {x_recon.shape}")
        print(f"   æ½œåœ¨è¡¨ç¤ºå½¢çŠ¶: {h.shape}")
        print(f"   é€Ÿåº¦é¢„æµ‹å½¢çŠ¶: {v_pred.shape}")
        if y_pred is not None:
            print(f"   åˆ†ç±»é¢„æµ‹å½¢çŠ¶: {y_pred.shape}")
        print(f"   å‰å‘æ—¶é—´: {forward_time:.4f}s")
        
        # é‡å»ºè´¨é‡æ£€æŸ¥
        recon_error = F.mse_loss(x_recon, x)
        print(f"   é‡å»ºè¯¯å·®: {recon_error.item():.6f}")
        
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        exit(1)
    
    # 3. ç”Ÿæˆæµ‹è¯•
    print("\n3ï¸âƒ£ ä¿¡å·ç”Ÿæˆæµ‹è¯•")
    try:
        num_samples = 8
        target_domain = torch.tensor([0], device=device)
        target_system = torch.tensor([1], device=device)
        
        start_time = time.time()
        generated = model.generate(
            domain_id=target_domain,
            system_id=target_system,
            num_samples=num_samples,
            num_steps=25,
            temperature=1.0
        )
        generation_time = time.time() - start_time
        
        print(f"âœ… ä¿¡å·ç”ŸæˆæˆåŠŸ")
        print(f"   ç”Ÿæˆä¿¡å·å½¢çŠ¶: {generated.shape}")
        print(f"   ç”Ÿæˆæ—¶é—´: {generation_time:.4f}s")
        print(f"   å•æ ·æœ¬ç”Ÿæˆæ—¶é—´: {generation_time/num_samples:.4f}s")
        
        # ç”Ÿæˆè´¨é‡åˆ†æ
        gen_mean = generated.mean().item()
        gen_std = generated.std().item()
        real_mean = x.mean().item()
        real_std = x.std().item()
        
        print(f"   ç”Ÿæˆä¿¡å·ç»Ÿè®¡: å‡å€¼={gen_mean:.4f}, æ ‡å‡†å·®={gen_std:.4f}")
        print(f"   çœŸå®ä¿¡å·ç»Ÿè®¡: å‡å€¼={real_mean:.4f}, æ ‡å‡†å·®={real_std:.4f}")
        print(f"   ç»Ÿè®¡ç›¸ä¼¼åº¦: å‡å€¼å·®={abs(gen_mean-real_mean):.4f}, æ ‡å‡†å·®å·®={abs(gen_std-real_std):.4f}")
        
    except Exception as e:
        print(f"âŒ ä¿¡å·ç”Ÿæˆå¤±è´¥: {e}")
    
    # 4. æ’å€¼æµ‹è¯•
    print("\n4ï¸âƒ£ ä¿¡å·æ’å€¼æµ‹è¯•")
    try:
        signal1 = x[:1]  # ç¬¬ä¸€ä¸ªä¿¡å·
        signal2 = x[1:2]  # ç¬¬äºŒä¸ªä¿¡å·
        domain_id = domain_ids[:1]
        system_id = system_ids[:1]
        
        start_time = time.time()
        interpolated = model.interpolate(
            signal1, signal2, domain_id, system_id,
            num_steps=10, interpolation_mode='spherical'
        )
        interp_time = time.time() - start_time
        
        print(f"âœ… ä¿¡å·æ’å€¼æˆåŠŸ")
        print(f"   æ’å€¼åºåˆ—å½¢çŠ¶: {interpolated.shape}")
        print(f"   æ’å€¼æ—¶é—´: {interp_time:.4f}s")
        
        # æ£€æŸ¥æ’å€¼çš„è¿ç»­æ€§
        start_diff = F.mse_loss(interpolated[0:1], signal1)
        end_diff = F.mse_loss(interpolated[-1:], signal2)
        
        print(f"   èµ·ç‚¹è¯¯å·®: {start_diff.item():.6f}")
        print(f"   ç»ˆç‚¹è¯¯å·®: {end_diff.item():.6f}")
        
        if start_diff < 1e-3 and end_diff < 1e-3:
            print("   âœ… æ’å€¼ç«¯ç‚¹æ­£ç¡®")
        else:
            print("   âš ï¸  æ’å€¼ç«¯ç‚¹è¯¯å·®è¾ƒå¤§")
            
    except Exception as e:
        print(f"âŒ ä¿¡å·æ’å€¼å¤±è´¥: {e}")
    
    # 5. ä¼¼ç„¶åº¦è®¡ç®—æµ‹è¯•ï¼ˆå¼‚å¸¸æ£€æµ‹ï¼‰
    print("\n5ï¸âƒ£ å¼‚å¸¸æ£€æµ‹æµ‹è¯•")
    try:
        # æ­£å¸¸ä¿¡å·
        normal_signals = x[:8]
        normal_domains = domain_ids[:8]
        normal_systems = system_ids[:8]
        
        # åˆ›å»ºå¼‚å¸¸ä¿¡å·ï¼ˆæ·»åŠ å¤§å™ªå£°ï¼‰
        abnormal_signals = normal_signals + torch.randn_like(normal_signals) * 2
        
        # è®¡ç®—ä¼¼ç„¶åº¦
        start_time = time.time()
        normal_likelihood = model.compute_likelihood(
            normal_signals, normal_domains, normal_systems, num_steps=20
        )
        abnormal_likelihood = model.compute_likelihood(
            abnormal_signals, normal_domains, normal_systems, num_steps=20
        )
        likelihood_time = time.time() - start_time
        
        print(f"âœ… å¼‚å¸¸æ£€æµ‹æµ‹è¯•å®Œæˆ")
        print(f"   æ­£å¸¸ä¿¡å·ä¼¼ç„¶åº¦: {normal_likelihood.mean().item():.4f} Â± {normal_likelihood.std().item():.4f}")
        print(f"   å¼‚å¸¸ä¿¡å·ä¼¼ç„¶åº¦: {abnormal_likelihood.mean().item():.4f} Â± {abnormal_likelihood.std().item():.4f}")
        print(f"   è®¡ç®—æ—¶é—´: {likelihood_time:.4f}s")
        
        # å¼‚å¸¸æ£€æµ‹æ•ˆæœ
        if abnormal_likelihood.mean() < normal_likelihood.mean():
            print("   âœ… å¼‚å¸¸æ£€æµ‹æœ‰æ•ˆï¼šå¼‚å¸¸ä¿¡å·ä¼¼ç„¶åº¦æ›´ä½")
        else:
            print("   âš ï¸  å¼‚å¸¸æ£€æµ‹æ•ˆæœæœ‰é™ï¼Œéœ€è¦æ›´å¤šè®­ç»ƒ")
            
    except Exception as e:
        print(f"âŒ å¼‚å¸¸æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")
    
    # 6. EMAæ¨¡å‹æµ‹è¯•
    print("\n6ï¸âƒ£ EMAæ¨¡å‹æµ‹è¯•")
    if hasattr(model, 'ema_model'):
        try:
            # æ›´æ–°EMAå‡ æ¬¡
            for _ in range(5):
                model.update_ema()
            
            # æ¯”è¾ƒEMAå’Œæ™®é€šæ¨¡å‹çš„ç”Ÿæˆç»“æœ
            normal_gen = model.generate(
                target_domain, target_system, num_samples=4, 
                num_steps=10, use_ema=False
            )
            ema_gen = model.generate(
                target_domain, target_system, num_samples=4, 
                num_steps=10, use_ema=True
            )
            
            # è®¡ç®—å·®å¼‚
            diff = F.mse_loss(normal_gen, ema_gen)
            
            print(f"âœ… EMAæ¨¡å‹æµ‹è¯•å®Œæˆ")
            print(f"   æ™®é€šç”Ÿæˆå½¢çŠ¶: {normal_gen.shape}")
            print(f"   EMAç”Ÿæˆå½¢çŠ¶: {ema_gen.shape}")
            print(f"   ç”Ÿæˆå·®å¼‚: {diff.item():.6f}")
            
        except Exception as e:
            print(f"âŒ EMAæµ‹è¯•å¤±è´¥: {e}")
    else:
        print("â„¹ï¸  EMAæ¨¡å‹æœªå¯ç”¨")
    
    # 7. å†…å­˜å’Œæ€§èƒ½æµ‹è¯•
    print("\n7ï¸âƒ£ æ€§èƒ½æµ‹è¯•")
    try:
        # æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°çš„æ€§èƒ½
        batch_sizes = [1, 4, 16, 32]
        print("   æ‰¹æ¬¡å¤§å°æ€§èƒ½æµ‹è¯•:")
        
        for bs in batch_sizes:
            x_test = torch.randn(bs, config.input_dim, device=device)
            d_test = torch.randint(0, config.num_domains, (bs,), device=device)
            s_test = torch.randint(0, config.num_systems, (bs,), device=device)
            
            # å‰å‘ä¼ æ’­æ—¶é—´
            start_time = time.time()
            with torch.no_grad():
                x_recon_test = model(x_test, d_test, s_test)
            forward_time = time.time() - start_time
            
            # ç”Ÿæˆæ—¶é—´
            start_time = time.time()
            gen_test = model.generate(d_test[:1], s_test[:1], num_samples=bs, num_steps=10)
            gen_time = time.time() - start_time
            
            print(f"     æ‰¹æ¬¡ {bs:2d}: å‰å‘={forward_time:.4f}s, ç”Ÿæˆ={gen_time:.4f}s")
            
        # GPUå†…å­˜æµ‹è¯•
        if device == 'cuda':
            torch.cuda.empty_cache()
            memory_before = torch.cuda.memory_allocated()
            
            # å¤§æ‰¹æ¬¡æµ‹è¯•
            large_x = torch.randn(64, config.input_dim, device=device)
            large_d = torch.randint(0, config.num_domains, (64,), device=device)
            large_s = torch.randint(0, config.num_systems, (64,), device=device)
            
            with torch.no_grad():
                large_recon = model(large_x, large_d, large_s)
            
            memory_after = torch.cuda.memory_allocated()
            memory_used = (memory_after - memory_before) / 1024**2
            
            print(f"   å†…å­˜ä½¿ç”¨: {memory_used:.2f} MB (æ‰¹æ¬¡=64)")
            torch.cuda.empty_cache()
            
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    print("âœ… ISFMç”Ÿæˆæ¨¡å‹ - å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
    print("ğŸ“Š ä¸»è¦åŠŸèƒ½: ä¿¡å·ç”Ÿæˆã€é‡å»ºã€æ’å€¼ã€å¼‚å¸¸æ£€æµ‹")
    print("ğŸš€ å»ºè®®ä¸‹ä¸€æ­¥: å¼€å§‹é¢„è®­ç»ƒå®éªŒ")
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šæµ‹è¯•é©±åŠ¨å¼€å‘(TDD)æ–¹æ¡ˆ

### 3.1 TDDå¼€å‘æµç¨‹

#### å¼€å‘å¾ªç¯
```
1. ğŸ”´ ç¼–å†™å¤±è´¥çš„æµ‹è¯• â†’ 2. ğŸŸ¢ ç¼–å†™æœ€å°å¯è¡Œä»£ç  â†’ 3. ğŸ”µ é‡æ„ä¼˜åŒ– â†’ é‡å¤
```

#### æµ‹è¯•å±‚æ¬¡
- **å•å…ƒæµ‹è¯•**ï¼šæ¨¡å—å†… `if __name__ == '__main__'` æµ‹è¯•
- **é›†æˆæµ‹è¯•**ï¼šæ¨¡å—é—´äº¤äº’æµ‹è¯•
- **ç³»ç»Ÿæµ‹è¯•**ï¼šå®Œæ•´ç”Ÿæˆç®¡é“æµ‹è¯•
- **æ€§èƒ½æµ‹è¯•**ï¼šå†…å­˜ã€é€Ÿåº¦ã€è´¨é‡åŸºå‡†

### 3.2 æ¯æ¨¡å—æµ‹è¯•ä»£ç æ¨¡æ¿

```python
# ================ æ¨¡å—æµ‹è¯•ä»£ç æ¨¡æ¿ ================
if __name__ == '__main__':
    """æ¨¡å—åç§°æµ‹è¯•å¥—ä»¶"""
    import time
    import torch
    import numpy as np
    from collections import defaultdict
    
    print(f"ğŸ§ª æµ‹è¯• {æ¨¡å—åç§°} æ¨¡å—")
    print("=" * 50)
    
    # 1. Mocké…ç½®è®¾ç½®
    class MockConfig:
        def __init__(self):
            # è®¾ç½®æµ‹è¯•é…ç½®å‚æ•°
            pass
    
    config = MockConfig()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # 2. åˆå§‹åŒ–æµ‹è¯•
    print("\n1ï¸âƒ£ æ¨¡å—åˆå§‹åŒ–æµ‹è¯•")
    try:
        model = ModuleClass(config)
        print("âœ… åˆå§‹åŒ–æˆåŠŸ")
        # å‚æ•°ç»Ÿè®¡ã€å†…å­˜æ£€æŸ¥ç­‰
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        exit(1)
    
    # 3. å‰å‘ä¼ æ’­æµ‹è¯•
    print("\n2ï¸âƒ£ å‰å‘ä¼ æ’­æµ‹è¯•")
    # åˆ›å»ºmockè¾“å…¥ã€éªŒè¯è¾“å‡ºå½¢çŠ¶ã€æ£€æŸ¥æ•°å€¼èŒƒå›´
    
    # 4. æ¢¯åº¦æµæµ‹è¯•
    print("\n3ï¸âƒ£ æ¢¯åº¦æµæµ‹è¯•")
    # åå‘ä¼ æ’­ã€æ¢¯åº¦æ£€æŸ¥ã€æ•°å€¼ç¨³å®šæ€§
    
    # 5. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
    print("\n4ï¸âƒ£ è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
    # æç«¯è¾“å…¥ã€å¼‚å¸¸å¤„ç†ã€é²æ£’æ€§
    
    # 6. æ€§èƒ½æµ‹è¯•
    print("\n5ï¸âƒ£ æ€§èƒ½æµ‹è¯•")
    # é€Ÿåº¦åŸºå‡†ã€å†…å­˜ä½¿ç”¨ã€æ‰¹é‡å¤„ç†
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("æ¨¡å—çŠ¶æ€ï¼šâœ… å¯ç”¨äºç”Ÿäº§ç¯å¢ƒ")
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šå®æ–½è·¯çº¿å›¾ - ä¼˜åŒ–ç‰ˆ

### 4.1 ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆæ¨¡å—å®ç°ï¼ˆç¬¬1-2å‘¨ï¼‰

#### ç¬¬1-3å¤©ï¼šçŸ«æ­£æµç”Ÿæˆç½‘ç»œ
- [ ] åˆ›å»º `src/model_factory/ISFM/generative/` ç›®å½•
- [ ] å®ç° `GM_01_RectifiedFlow.py` åŒ…å«å®Œæ•´æµ‹è¯•ä»£ç 
- [ ] æ—¶é—´åµŒå…¥ä¼˜åŒ–ï¼šæ­£å¼¦åµŒå…¥ + MLP
- [ ] ResNeté£æ ¼çš„é€Ÿåº¦ç½‘ç»œ
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: å•å…ƒæµ‹è¯• >95%

#### ç¬¬4-6å¤©ï¼šæ¡ä»¶ç¼–ç å™¨å¢å¼º  
- [ ] å®ç° `E_03_ConditionalEncoder.py` åŒ…å«æµ‹è¯•
- [ ] å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
- [ ] è‡ªé€‚åº”ç‰¹å¾ç¼©æ”¾
- [ ] å±‚æ¬¡åŒ–åµŒå…¥éªŒè¯
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: æ¡ä»¶ç”Ÿæˆå‡†ç¡®æ€§ >90%

#### ç¬¬7-10å¤©ï¼šç”Ÿæˆæ¨¡å‹ä¸»ä½“
- [ ] å®ç° `M_04_ISFM_GM.py` å®Œæ•´ç”Ÿæˆæ¨¡å‹
- [ ] EMAæ¨¡å‹é›†æˆ
- [ ] å¤šç§ç”Ÿæˆæ¨¡å¼ï¼šæ— æ¡ä»¶/æ¡ä»¶/æ’å€¼
- [ ] å¼‚å¸¸æ£€æµ‹åŠŸèƒ½
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: ç«¯åˆ°ç«¯ç”Ÿæˆæµç¨‹æµ‹è¯•

#### ç¬¬11-14å¤©ï¼šæŸå¤±å‡½æ•°ä¼˜åŒ–
- [ ] å®ç° `gm_pretrain_loss.py` ç”Ÿæˆæ¨¡å‹ä¸“ç”¨æŸå¤±
- [ ] æµåŒ¹é…æŸå¤±ä¼˜åŒ–
- [ ] å±‚æ¬¡å¯¹æ¯”å­¦ä¹ æŸå¤±
- [ ] ç”Ÿæˆè´¨é‡æŸå¤±ï¼ˆFID, ISç­‰ï¼‰
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: æŸå¤±ç»„ä»¶ç‹¬ç«‹éªŒè¯

### 4.2 ç¬¬äºŒé˜¶æ®µï¼šä»»åŠ¡ä¸ç®¡é“é›†æˆï¼ˆç¬¬3å‘¨ï¼‰

#### ç¬¬15-17å¤©ï¼šLightningä»»åŠ¡æ¨¡å—
- [ ] åˆ›å»º `gm_pretrain_task.py` åŒ…å«è®­ç»ƒé€»è¾‘
- [ ] ç”Ÿæˆæ ·æœ¬è´¨é‡ç›‘æ§
- [ ] å¤šGPUè®­ç»ƒæ”¯æŒ
- [ ] å¯è§†åŒ–å›è°ƒå‡½æ•°
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: è®­ç»ƒç¨³å®šæ€§éªŒè¯

#### ç¬¬18-21å¤©ï¼šç®¡é“é›†æˆä¸é…ç½®
- [ ] æ›´æ–°ç®¡é“æ”¯æŒç”Ÿæˆæ¨¡å‹è®­ç»ƒ
- [ ] åˆ›å»ºç”Ÿæˆæ¨¡å‹ä¸“ç”¨é…ç½®
- [ ] æ•°æ®å¢å¼ºé›†æˆ
- [ ] å¼‚å¸¸æ£€æµ‹é›†æˆ
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: å®Œæ•´ç®¡é“æµ‹è¯•

### 4.3 ç¬¬ä¸‰é˜¶æ®µï¼šè´¨é‡ä¿è¯ä¸ä¼˜åŒ–ï¼ˆç¬¬4å‘¨ï¼‰

#### ç¬¬22-25å¤©ï¼šç”Ÿæˆè´¨é‡è¯„ä¼°
- [ ] FID (FrÃ©chet Inception Distance) è¯„ä¼°
- [ ] ä¿¡å·å¤šæ ·æ€§æŒ‡æ ‡
- [ ] æ¡ä»¶ç”Ÿæˆå‡†ç¡®æ€§æµ‹è¯•
- [ ] å¼‚å¸¸æ£€æµ‹ROCæ›²çº¿
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: è´¨é‡åŸºå‡†å»ºç«‹

#### ç¬¬26-28å¤©ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æ–‡æ¡£
- [ ] å†…å­˜ä¼˜åŒ–ï¼ˆæ¢¯åº¦æ£€æŸ¥ç‚¹ï¼‰
- [ ] ç”Ÿæˆé€Ÿåº¦ä¼˜åŒ–
- [ ] å®Œæ•´æ–‡æ¡£å’Œç¤ºä¾‹
- [ ] ç”¨æˆ·æŒ‡å—
- [ ] âœ… **æµ‹è¯•è¦†ç›–ç›®æ ‡**: æ€§èƒ½åŸºå‡†è¾¾æ ‡

---

## ç¬¬äº”éƒ¨åˆ†ï¼šæ–‡ä»¶ç»„ç»‡ä¸å‘½åè§„èŒƒ

### 5.1 æ–°å»ºæ–‡ä»¶æ¸…å•ï¼ˆ18ä¸ªæ–‡ä»¶ï¼‰

#### ç”Ÿæˆæ¨¡å‹æ ¸å¿ƒæ–‡ä»¶
1. `src/model_factory/ISFM/generative/__init__.py`
2. `src/model_factory/ISFM/generative/GM_01_RectifiedFlow.py`
3. `src/model_factory/ISFM/generative/base_generative.py`
4. `src/model_factory/ISFM/encoder/E_03_ConditionalEncoder.py`
5. `src/model_factory/ISFM/M_04_ISFM_GM.py`

#### ä»»åŠ¡å’ŒæŸå¤±å‡½æ•°
6. `src/task_factory/Components/gm_pretrain_loss.py`
7. `src/task_factory/task/pretrain/gm_pretrain_task.py`

#### é…ç½®æ–‡ä»¶
8. `configs/demo/GenerativeModel/gm_pretrain.yaml`
9. `configs/demo/GenerativeModel/gm_pretrain_basic.yaml`
10. `configs/demo/GenerativeModel/gm_pretrain_advanced.yaml`

#### æµ‹è¯•æ–‡ä»¶
11. `test/unit/test_gm_rectified_flow.py`
12. `test/unit/test_conditional_encoder.py`
13. `test/unit/test_isfm_gm.py`
14. `test/unit/test_gm_pretrain_loss.py`
15. `test/integration/test_gm_pipeline.py`

#### åº”ç”¨ç¤ºä¾‹
16. `examples/gm_data_augmentation.py`
17. `examples/gm_anomaly_detection.py`
18. `examples/gm_signal_generation.py`

### 5.2 ä¿®æ”¹æ–‡ä»¶æ¸…å•ï¼ˆ8ä¸ªæ–‡ä»¶ï¼‰

1. **`src/model_factory/ISFM/__init__.py`**
   - æ·»åŠ ç”Ÿæˆæ¨¡å‹ç»„ä»¶æ³¨å†Œ
   - æ›´æ–°æ¨¡å‹å­—å…¸

2. **`src/task_factory/task_factory.py`**
   - æ³¨å†Œç”Ÿæˆæ¨¡å‹é¢„è®­ç»ƒä»»åŠ¡

3. **`src/Pipeline_03_multitask_pretrain_finetune.py`**
   - æ·»åŠ ç”Ÿæˆæ¨¡å‹é¢„è®­ç»ƒé˜¶æ®µ

4. **`src/data_factory/ID_dataset.py`**
   - æ”¯æŒç”Ÿæˆæ ·æœ¬æ ‡æ³¨

5. **`src/utils/evaluation_metrics.py`**
   - æ·»åŠ ç”Ÿæˆè´¨é‡è¯„ä¼°æŒ‡æ ‡

6. **`src/utils/visualization.py`**
   - ç”Ÿæˆæ ·æœ¬å¯è§†åŒ–å·¥å…·

7. **`src/utils/pipeline_config.py`**
   - ç”Ÿæˆæ¨¡å‹é…ç½®éªŒè¯

8. **`docs/GM_TUTORIAL.md`**
   - ç”Ÿæˆæ¨¡å‹ä½¿ç”¨æ•™ç¨‹

---

## ç¬¬å…­éƒ¨åˆ†ï¼šç”Ÿæˆè´¨é‡è¯„ä¼°ä½“ç³»

### 6.1 å®šé‡è¯„ä¼°æŒ‡æ ‡

#### ç»Ÿè®¡åˆ†å¸ƒç›¸ä¼¼æ€§
```python
# ç”Ÿæˆä¿¡å·ä¸çœŸå®ä¿¡å·çš„åˆ†å¸ƒæ¯”è¾ƒ
def evaluate_distribution_similarity(real_signals, generated_signals):
    metrics = {}
    
    # 1. Kolmogorov-Smirnovæ£€éªŒ
    ks_stat, ks_pvalue = ks_2samp(real_signals.flatten(), 
                                 generated_signals.flatten())
    metrics['ks_statistic'] = ks_stat
    metrics['ks_pvalue'] = ks_pvalue
    
    # 2. Wassersteinè·ç¦»
    w_distance = wasserstein_distance(real_signals.flatten(), 
                                    generated_signals.flatten())
    metrics['wasserstein_distance'] = w_distance
    
    # 3. é¢‘åŸŸç›¸ä¼¼æ€§
    real_fft = np.abs(np.fft.fft(real_signals, axis=1))
    gen_fft = np.abs(np.fft.fft(generated_signals, axis=1))
    freq_mse = np.mean((real_fft - gen_fft) ** 2)
    metrics['frequency_mse'] = freq_mse
    
    return metrics
```

#### æ¡ä»¶ç”Ÿæˆå‡†ç¡®æ€§
```python
# éªŒè¯ç”Ÿæˆæ ·æœ¬æ˜¯å¦ç¬¦åˆæŒ‡å®šæ¡ä»¶
def evaluate_conditional_accuracy(model, test_conditions, num_samples=100):
    accuracies = {}
    
    for domain_id, system_id in test_conditions:
        # ç”Ÿæˆæ ·æœ¬
        generated = model.generate(
            domain_id=torch.tensor([domain_id]),
            system_id=torch.tensor([system_id]),
            num_samples=num_samples
        )
        
        # ä½¿ç”¨åˆ†ç±»å™¨éªŒè¯æ¡ä»¶ç¬¦åˆåº¦
        predicted_conditions = condition_classifier(generated)
        
        # è®¡ç®—å‡†ç¡®ç‡
        domain_acc = (predicted_conditions['domain'] == domain_id).float().mean()
        system_acc = (predicted_conditions['system'] == system_id).float().mean()
        
        accuracies[f'domain_{domain_id}_system_{system_id}'] = {
            'domain_accuracy': domain_acc.item(),
            'system_accuracy': system_acc.item()
        }
    
    return accuracies
```

### 6.2 å®šæ€§è¯„ä¼°æ–¹æ³•

#### ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ
```python
class ExpertEvaluationSystem:
    """ä¸“å®¶è¯„ä¼°ç³»ç»Ÿ"""
    def __init__(self):
        self.criteria = {
            'signal_realism': {'weight': 0.3, 'scale': 1-10},
            'fault_pattern_clarity': {'weight': 0.3, 'scale': 1-10},
            'noise_characteristics': {'weight': 0.2, 'scale': 1-10},
            'temporal_consistency': {'weight': 0.2, 'scale': 1-10}
        }
    
    def evaluate_batch(self, generated_signals, expert_scores):
        """æ‰¹é‡ä¸“å®¶è¯„ä¼°"""
        weighted_scores = {}
        for criterion, config in self.criteria.items():
            if criterion in expert_scores:
                weighted_scores[criterion] = (
                    expert_scores[criterion] * config['weight']
                )
        
        overall_score = sum(weighted_scores.values())
        return overall_score, weighted_scores
```

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šåº”ç”¨åœºæ™¯ä¸éƒ¨ç½²

### 7.1 æ•°æ®å¢å¼ºåº”ç”¨

#### ç±»åˆ«å¹³è¡¡ç”Ÿæˆ
```python
def balance_dataset_with_generation(model, dataset, target_samples_per_class=1000):
    """ä½¿ç”¨ç”Ÿæˆæ¨¡å‹å¹³è¡¡æ•°æ®é›†"""
    balanced_data = []
    class_counts = dataset.get_class_distribution()
    
    for (domain_id, system_id, class_id), current_count in class_counts.items():
        if current_count < target_samples_per_class:
            # ç”Ÿæˆéœ€è¦çš„æ ·æœ¬æ•°é‡
            needed_samples = target_samples_per_class - current_count
            
            generated_signals = model.generate(
                domain_id=torch.tensor([domain_id]),
                system_id=torch.tensor([system_id]),
                num_samples=needed_samples,
                temperature=0.8  # ç¨å¾®é™ä½å¤šæ ·æ€§ç¡®ä¿è´¨é‡
            )
            
            # æ·»åŠ åˆ°å¹³è¡¡æ•°æ®é›†
            for signal in generated_signals:
                balanced_data.append({
                    'signal': signal,
                    'domain': domain_id,
                    'system': system_id,
                    'class': class_id,
                    'synthetic': True
                })
    
    return balanced_data
```

### 7.2 å¼‚å¸¸æ£€æµ‹éƒ¨ç½²

#### å®æ—¶å¼‚å¸¸ç›‘æ§
```python
class RealTimeAnomalyDetector:
    """å®æ—¶å¼‚å¸¸æ£€æµ‹å™¨"""
    def __init__(self, gm_model, threshold_percentile=95):
        self.gm_model = gm_model
        self.threshold = None
        self.threshold_percentile = threshold_percentile
        
    def calibrate_threshold(self, normal_samples):
        """ä½¿ç”¨æ­£å¸¸æ ·æœ¬æ ¡å‡†é˜ˆå€¼"""
        with torch.no_grad():
            likelihoods = []
            for sample in normal_samples:
                likelihood = self.gm_model.compute_likelihood(
                    sample['signal'], sample['domain'], sample['system']
                )
                likelihoods.append(likelihood.item())
        
        self.threshold = np.percentile(likelihoods, 
                                     100 - self.threshold_percentile)
        
    def detect_anomaly(self, signal, domain_id, system_id):
        """æ£€æµ‹å•ä¸ªä¿¡å·æ˜¯å¦å¼‚å¸¸"""
        with torch.no_grad():
            likelihood = self.gm_model.compute_likelihood(
                signal, domain_id, system_id
            )
            
            is_anomaly = likelihood.item() < self.threshold
            confidence = abs(likelihood.item() - self.threshold) / self.threshold
            
            return {
                'is_anomaly': is_anomaly,
                'likelihood': likelihood.item(),
                'confidence': confidence,
                'threshold': self.threshold
            }
```

---

## ç¬¬å…«éƒ¨åˆ†ï¼šæˆåŠŸæ ‡å‡†ä¸éªŒè¯

### 8.1 æŠ€æœ¯æŒ‡æ ‡è¦æ±‚

#### ç”Ÿæˆè´¨é‡æ ‡å‡†
- **é‡å»ºè¯¯å·®**: MSE < 0.01ï¼ˆå½’ä¸€åŒ–ä¿¡å·ï¼‰
- **ç”Ÿæˆå¤šæ ·æ€§**: ç”Ÿæˆæ ·æœ¬è¦†ç›–çœŸå®æ•°æ®90%ä»¥ä¸Šçš„ç‰¹å¾ç©ºé—´
- **æ¡ä»¶å‡†ç¡®æ€§**: æ¡ä»¶ç”Ÿæˆå‡†ç¡®ç‡ > 85%
- **é¢‘åŸŸä¸€è‡´æ€§**: åŠŸç‡è°±å¯†åº¦ç›¸ä¼¼åº¦ > 0.8

#### æ€§èƒ½æ ‡å‡†
- **ç”Ÿæˆé€Ÿåº¦**: å•æ ·æœ¬ç”Ÿæˆ < 100msï¼ˆGPUï¼‰
- **å†…å­˜æ•ˆç‡**: æ‰¹æ¬¡256æ ·æœ¬ < 4GBæ˜¾å­˜
- **è®­ç»ƒç¨³å®šæ€§**: 1000è½®æ”¶æ•›ï¼ŒæŸå¤±æ–¹å·® < 0.1

### 8.2 åº”ç”¨æ•ˆæœéªŒè¯

#### ä¸‹æ¸¸ä»»åŠ¡æ”¹è¿›
```python
def validate_downstream_improvement(gm_model, downstream_tasks):
    """éªŒè¯ç”Ÿæˆæ¨¡å‹å¯¹ä¸‹æ¸¸ä»»åŠ¡çš„æ”¹è¿›æ•ˆæœ"""
    results = {}
    
    for task_name, task_config in downstream_tasks.items():
        # åŸºçº¿æ€§èƒ½ï¼ˆæ— æ•°æ®å¢å¼ºï¼‰
        baseline_performance = train_and_evaluate(
            task_config, use_augmentation=False
        )
        
        # ä½¿ç”¨ç”Ÿæˆæ•°æ®å¢å¼ºåçš„æ€§èƒ½
        augmented_performance = train_and_evaluate_with_generation(
            task_config, gm_model, augmentation_ratio=0.5
        )
        
        improvement = (augmented_performance - baseline_performance) / baseline_performance
        
        results[task_name] = {
            'baseline': baseline_performance,
            'augmented': augmented_performance,
            'improvement_ratio': improvement
        }
    
    return results
```

---

## ç¬¬ä¹éƒ¨åˆ†ï¼šé£é™©æ§åˆ¶ä¸è´¨é‡ä¿è¯

### 9.1 ä»£ç è´¨é‡æ§åˆ¶

#### è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹
```yaml
# .github/workflows/gm_ci.yml
name: ç”Ÿæˆæ¨¡å‹æŒç»­é›†æˆ
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, 3.10]
        
    steps:
    - uses: actions/checkout@v3
    - name: è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v3
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: å®‰è£…ä¾èµ–
      run: |
        pip install -r requirements-test.txt
        pip install -e .
        
    - name: ä»£ç é£æ ¼æ£€æŸ¥
      run: |
        flake8 src/model_factory/ISFM/generative/ --max-line-length=100
        black --check src/model_factory/ISFM/generative/
        
    - name: å•å…ƒæµ‹è¯•
      run: |
        python -m pytest test/unit/test_gm_*.py -v --cov=src
        
    - name: é›†æˆæµ‹è¯•
      run: |
        python -m pytest test/integration/test_gm_*.py -v
        
    - name: æ€§èƒ½æµ‹è¯•
      run: |
        python test/performance/benchmark_gm.py
```

### 9.2 æ¨¡å‹å®‰å…¨æ€§æ£€æŸ¥

#### ç”Ÿæˆå†…å®¹å®‰å…¨éªŒè¯
```python
class GeneratedContentValidator:
    """ç”Ÿæˆå†…å®¹å®‰å…¨éªŒè¯å™¨"""
    def __init__(self):
        self.safety_checks = [
            self.check_signal_bounds,
            self.check_frequency_range,
            self.check_amplitude_distribution,
            self.check_temporal_consistency
        ]
    
    def validate_generated_batch(self, generated_signals):
        """éªŒè¯ç”Ÿæˆä¿¡å·æ‰¹æ¬¡çš„å®‰å…¨æ€§"""
        validation_results = {
            'passed': True,
            'warnings': [],
            'errors': []
        }
        
        for check in self.safety_checks:
            try:
                result = check(generated_signals)
                if not result['passed']:
                    validation_results['errors'].extend(result.get('errors', []))
                    validation_results['warnings'].extend(result.get('warnings', []))
                    validation_results['passed'] = False
            except Exception as e:
                validation_results['errors'].append(f"éªŒè¯æ£€æŸ¥å¤±è´¥: {e}")
                validation_results['passed'] = False
        
        return validation_results
    
    def check_signal_bounds(self, signals):
        """æ£€æŸ¥ä¿¡å·å€¼åŸŸ"""
        min_val, max_val = signals.min(), signals.max()
        if min_val < -10 or max_val > 10:  # å‡è®¾åˆç†èŒƒå›´
            return {
                'passed': False,
                'errors': [f"ä¿¡å·å€¼è¶…å‡ºåˆç†èŒƒå›´: [{min_val}, {max_val}]"]
            }
        return {'passed': True}
```

---

## ç»“è®º

è¿™ä»½ä¼˜åŒ–ç‰ˆç”Ÿæˆæ¨¡å‹é›†æˆæ–¹æ¡ˆä¸ºPHM-Vibenchæ¡†æ¶æä¾›äº†å®Œæ•´çš„ç”Ÿæˆèƒ½åŠ›å‡çº§è·¯å¾„ã€‚é€šè¿‡å°†Flowæ¨¡å‹æ˜ç¡®å®šä½ä¸ºç”Ÿæˆæ¨¡å‹ï¼Œå¹¶é‡‡ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘æ–¹æ³•ï¼Œç¡®ä¿äº†ä»£ç è´¨é‡å’ŒåŠŸèƒ½å¯é æ€§ã€‚

### æ ¸å¿ƒä¼˜åŠ¿

1. **å®Œæ•´ç”Ÿæˆèƒ½åŠ›**: æ•°æ®å¢å¼ºã€å¼‚å¸¸æ£€æµ‹ã€ä¿¡å·åˆæˆä¸€ä½“åŒ–
2. **è´¨é‡ä¿è¯ä½“ç³»**: TDD + å†…åµŒæµ‹è¯• + æŒç»­é›†æˆ
3. **å·¥ä¸šåŒ–éƒ¨ç½²**: å®æ—¶å¼‚å¸¸æ£€æµ‹ã€ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–
4. **å¯æ‰©å±•æ¶æ„**: æ¨¡å—åŒ–è®¾è®¡æ”¯æŒæœªæ¥å¢å¼º

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. ğŸš€ **ç«‹å³å¼€å§‹**: æŒ‰ç…§å®æ–½è·¯çº¿å›¾æ‰§è¡Œç¬¬ä¸€é˜¶æ®µ
2. ğŸ“Š **æŒç»­ç›‘æ§**: ä½¿ç”¨è´¨é‡è¯„ä¼°ä½“ç³»è·Ÿè¸ªè¿›å±•
3. ğŸ”„ **è¿­ä»£æ”¹è¿›**: åŸºäºå®é™…æµ‹è¯•ç»“æœä¼˜åŒ–æ¨¡å‹
4. ğŸ“ **æ–‡æ¡£ç»´æŠ¤**: ä¿æŒæ–‡æ¡£ä¸ä»£ç åŒæ­¥æ›´æ–°

---

**æ–‡æ¡£çŠ¶æ€**: âœ… å‡†å¤‡å®æ–½  
**å¼€å‘åˆ†æ”¯**: cc_flow_1  
**ç‰ˆæœ¬**: ä¼˜åŒ–ç‰ˆ v2.0  
**é¢„è®¡å®Œæˆæ—¶é—´**: 4å‘¨