# Flowæ¨¡å‹é¢„è®­ç»ƒè¯¦ç»†å®æ–½è®¡åˆ’

**åˆ›å»ºæ—¥æœŸï¼š2025å¹´8æœˆ30æ—¥**  
**ç‰ˆæœ¬ï¼šV4.0 - è¯¦ç»†å®æ–½ç‰ˆ**  
**åŸºäºï¼šGM_FLOW_PLAN_OPTIMIZED_2025-08-30.md åˆ†æç»“æœ**

---

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

åŸºäºå¯¹ç°æœ‰Flowè®¡åˆ’çš„æ·±åº¦åˆ†æï¼Œæœ¬è®¡åˆ’è§£å†³äº†å…³é”®çš„æŠ€æœ¯é›†æˆé—®é¢˜ï¼Œæä¾›äº†å¯æ‰§è¡Œçš„åˆ†é˜¶æ®µå®æ–½æ–¹æ¡ˆï¼Œç¡®ä¿Rectified Flowç”Ÿæˆæ¨¡å‹æˆåŠŸé›†æˆåˆ°PHM-Vibenchæ¡†æ¶ä¸­ã€‚

### æ ¸å¿ƒæ”¹è¿›ç‚¹
- âœ… **ç»´åº¦å…¼å®¹æ€§ä¿®å¤**: é€‚é…(B,L,C)å¼ é‡æ ¼å¼
- âœ… **å…ƒæ•°æ®é›†æˆ**: ä½¿ç”¨file_idæå–å±‚æ¬¡åŒ–æ¡ä»¶ä¿¡æ¯  
- âœ… **å·¥å‚æ¨¡å¼åˆè§„**: éµå¾ªPHM-Vibenchæ¶æ„æ¨¡å¼
- âœ… **æ•°å€¼ç¨³å®šæ€§**: å®Œæ•´çš„é”™è¯¯å¤„ç†å’ŒéªŒè¯
- âœ… **æµ‹è¯•é©±åŠ¨**: å…¨é¢çš„å•å…ƒå’Œé›†æˆæµ‹è¯•

---

## ğŸ“Š æŠ€æœ¯æ¶æ„è¯¦ç»†è®¾è®¡

### 1. æ ¸å¿ƒç»„ä»¶æ¶æ„

```
Flow-based Pretraining System
â”œâ”€â”€ Sequence Adapter          # ç»´åº¦é€‚é…å±‚
â”‚   â”œâ”€â”€ flatten_sequence()   # (B,L,C) â†’ (B,L*C)
â”‚   â””â”€â”€ unflatten_sequence() # (B,L*C) â†’ (B,L,C)
â”œâ”€â”€ Rectified Flow Model      # æ ¸å¿ƒç”Ÿæˆæ¨¡å‹
â”‚   â”œâ”€â”€ velocity_network()   # é€Ÿåº¦åœºé¢„æµ‹
â”‚   â”œâ”€â”€ flow_matching()      # æµåŒ¹é…è®­ç»ƒ
â”‚   â””â”€â”€ ode_sampling()       # ODEç§¯åˆ†é‡‡æ ·
â”œâ”€â”€ Conditional Encoder       # å±‚æ¬¡åŒ–æ¡ä»¶ç¼–ç 
â”‚   â”œâ”€â”€ domain_encoder()     # åŸŸçº§ç¼–ç 
â”‚   â”œâ”€â”€ system_encoder()     # ç³»ç»Ÿçº§ç¼–ç 
â”‚   â””â”€â”€ instance_encoder()   # å®ä¾‹çº§ç¼–ç 
â””â”€â”€ Flow Utilities           # è¾…åŠ©å·¥å…·
    â”œâ”€â”€ solvers/            # ODEæ±‚è§£å™¨
    â”œâ”€â”€ schedulers/         # å™ªå£°è°ƒåº¦
    â””â”€â”€ metrics/           # è¯„ä¼°æŒ‡æ ‡
```

### 2. ç»´åº¦å¤„ç†ç­–ç•¥

#### é—®é¢˜åˆ†æ
- **ç°æœ‰ä»£ç **: å‡è®¾è¾“å…¥ä¸º`(batch_size, latent_dim)`
- **PHM-Vibenchå®é™…**: ä½¿ç”¨`(batch_size, sequence_length, channels)`æ ¼å¼
- **å…¸å‹å‚æ•°**: sequence_length=1024, channels=1-3

#### è§£å†³æ–¹æ¡ˆè®¾è®¡

```python
class SequenceAdapter(nn.Module):
    """åºåˆ—ç»´åº¦é€‚é…å™¨ - å¤„ç†3Då¼ é‡æ ¼å¼è½¬æ¢"""
    
    def __init__(self, seq_len: int, channels: int, latent_dim: int):
        super().__init__()
        self.seq_len = seq_len
        self.channels = channels
        self.latent_dim = latent_dim
        
        # æ–¹æ¡ˆ1: ç›´æ¥å±•å¼€(æ¨è)
        self.use_flatten = True
        
        # æ–¹æ¡ˆ2: å·ç§¯é™ç»´(å¤‡é€‰)
        if not self.use_flatten:
            self.conv_encoder = nn.Conv1d(channels, latent_dim//seq_len, 1)
            self.conv_decoder = nn.Conv1d(latent_dim//seq_len, channels, 1)
    
    def encode(self, x: torch.Tensor) -> torch.Tensor:
        """
        ç¼–ç : (B, L, C) -> (B, D)
        """
        B, L, C = x.shape
        if self.use_flatten:
            return x.view(B, L * C)
        else:
            # ä½¿ç”¨å·ç§¯é™ç»´
            x = x.transpose(1, 2)  # (B, C, L)
            x = self.conv_encoder(x)  # (B, D/L, L)
            return x.view(B, -1)  # (B, D)
    
    def decode(self, x: torch.Tensor) -> torch.Tensor:
        """
        è§£ç : (B, D) -> (B, L, C)
        """
        B = x.shape[0]
        if self.use_flatten:
            return x.view(B, self.seq_len, self.channels)
        else:
            # ä½¿ç”¨å·ç§¯å‡ç»´
            x = x.view(B, self.latent_dim//self.seq_len, self.seq_len)
            x = self.conv_decoder(x)  # (B, C, L)
            return x.transpose(1, 2)  # (B, L, C)
```

### 3. å…ƒæ•°æ®é›†æˆç³»ç»Ÿ

#### å±‚æ¬¡åŒ–ä¿¡æ¯æå–

```python
class MetadataConditionExtractor:
    """
    ä»PHM-Vibenchç°æœ‰metadataç›´æ¥æå–æ¡ä»¶ä¿¡æ¯
    é¿å…å†—ä½™æ˜ å°„è¡¨ï¼Œæ”¯æŒæœªçŸ¥åŸŸå’Œç³»ç»Ÿå¤„ç†
    """
    
    @staticmethod
    def extract_conditions(metadata_dict: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»metadataå­—å…¸æå–æ¡ä»¶ä¿¡æ¯
        
        Args:
            metadata_dict: å•ä¸ªæ ·æœ¬çš„metadataä¿¡æ¯ï¼ˆmetadata[file_id]ï¼‰
            
        Returns:
            åŒ…å«domain_id, system_idç­‰çš„æ¡ä»¶å­—å…¸
        """
        # ç›´æ¥ä½¿ç”¨PHM-Vibench metadataä¸­çš„å€¼
        domain_id = metadata_dict.get('Domain_id', -1)  # -1è¡¨ç¤ºæœªçŸ¥
        system_id = metadata_dict.get('Dataset_id', -1)  # -1è¡¨ç¤ºæœªçŸ¥
        
        # å¤„ç†pandas NaNå’ŒNoneå€¼
        if pd.isna(domain_id) or domain_id is None:
            domain_id = -1  # æœªçŸ¥åŸŸ
        if pd.isna(system_id) or system_id is None:
            system_id = -1  # æœªçŸ¥ç³»ç»Ÿ
            
        return {
            'domain_id': int(domain_id),
            'system_id': int(system_id),
            'dataset_name': metadata_dict.get('Name', 'unknown'),
            'label': metadata_dict.get('Label', -1),
            'sample_rate': metadata_dict.get('Sample_rate', 0)
        }
    
    @staticmethod
    def get_metadata_statistics(metadata_df) -> Dict[str, int]:
        """
        ä»metadata DataFrameç»Ÿè®¡åŸŸå’Œç³»ç»Ÿçš„æ•°é‡
        
        Args:
            metadata_df: PHM-Vibenchçš„metadata DataFrame
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        # ç»Ÿè®¡æœ‰æ•ˆçš„åŸŸå’Œç³»ç»ŸID
        valid_domains = metadata_df['Domain_id'].dropna()
        valid_systems = metadata_df['Dataset_id'].dropna()
        
        # è½¬æ¢ä¸ºæ•´æ•°ç±»å‹
        try:
            valid_domains = valid_domains.astype(int)
            valid_systems = valid_systems.astype(int)
        except:
            pass  # å¦‚æœæ— æ³•è½¬æ¢ï¼Œä¿æŒåŸç±»å‹
        
        unique_domains = valid_domains.unique()
        unique_systems = valid_systems.unique()
        
        return {
            'num_domains': len(unique_domains),
            'num_systems': len(unique_systems),
            'max_domain_id': int(max(unique_domains)) if len(unique_domains) > 0 else -1,
            'max_system_id': int(max(unique_systems)) if len(unique_systems) > 0 else -1,
            'domain_ids': sorted(unique_domains.tolist()),
            'system_ids': sorted(unique_systems.tolist())
        }
```

### 4. å¢å¼ºçš„ODEæ±‚è§£å™¨

```python
class FlowODESolver:
    """é«˜ç²¾åº¦ODEæ±‚è§£å™¨é›†åˆ"""
    
    def __init__(self, solver_type: str = 'euler'):
        self.solver_type = solver_type
        self.solver_registry = {
            'euler': self.euler_step,
            'heun': self.heun_step,
            'rk4': self.rk4_step,
            'adaptive': self.adaptive_step
        }
    
    def euler_step(self, model, x, t, dt, condition=None):
        """ä¸€é˜¶æ¬§æ‹‰æ–¹æ³•"""
        with torch.no_grad():
            t_tensor = torch.full((x.size(0),), t, device=x.device)
            t_emb = model.time_embedding(t_tensor)
            v = model.velocity_net(x, t_emb, condition)
            return x + dt * v
    
    def heun_step(self, model, x, t, dt, condition=None):
        """äºŒé˜¶Heunæ–¹æ³• (æ”¹è¿›çš„æ¬§æ‹‰æ³•)"""
        with torch.no_grad():
            # ç¬¬ä¸€æ­¥é¢„æµ‹
            t_tensor = torch.full((x.size(0),), t, device=x.device)
            t_emb = model.time_embedding(t_tensor)
            k1 = model.velocity_net(x, t_emb, condition)
            x_temp = x + dt * k1
            
            # ç¬¬äºŒæ­¥æ ¡æ­£
            t_next_tensor = torch.full((x.size(0),), t + dt, device=x.device)
            t_next_emb = model.time_embedding(t_next_tensor)
            k2 = model.velocity_net(x_temp, t_next_emb, condition)
            
            # æœ€ç»ˆç»“æœ
            return x + dt * (k1 + k2) / 2
    
    def rk4_step(self, model, x, t, dt, condition=None):
        """å››é˜¶Runge-Kuttaæ–¹æ³•"""
        with torch.no_grad():
            # k1
            t_tensor = torch.full((x.size(0),), t, device=x.device)
            t_emb = model.time_embedding(t_tensor)
            k1 = model.velocity_net(x, t_emb, condition)
            
            # k2
            x2 = x + dt * k1 / 2
            t2_tensor = torch.full((x.size(0),), t + dt/2, device=x.device)
            t2_emb = model.time_embedding(t2_tensor)
            k2 = model.velocity_net(x2, t2_emb, condition)
            
            # k3
            x3 = x + dt * k2 / 2
            k3 = model.velocity_net(x3, t2_emb, condition)
            
            # k4
            x4 = x + dt * k3
            t4_tensor = torch.full((x.size(0),), t + dt, device=x.device)
            t4_emb = model.time_embedding(t4_tensor)
            k4 = model.velocity_net(x4, t4_emb, condition)
            
            # æœ€ç»ˆç»“æœ
            return x + dt * (k1 + 2*k2 + 2*k3 + k4) / 6
    
    def adaptive_step(self, model, x, t, dt, condition=None, tol=1e-5):
        """è‡ªé€‚åº”æ­¥é•¿æ§åˆ¶"""
        # ä½¿ç”¨å…¨æ­¥é•¿
        x1 = self.rk4_step(model, x, t, dt, condition)
        
        # ä½¿ç”¨ä¸¤ä¸ªåŠæ­¥é•¿
        x_half = self.rk4_step(model, x, t, dt/2, condition)
        x2 = self.rk4_step(model, x_half, t + dt/2, dt/2, condition)
        
        # ä¼°è®¡è¯¯å·®
        error = torch.norm(x1 - x2, dim=-1).max()
        
        if error < tol:
            return x2, dt  # æ¥å—æ­¥é•¿
        else:
            # å‡å°æ­¥é•¿é‡æ–°è®¡ç®—
            new_dt = dt * 0.8 * (tol / error) ** 0.2
            return self.adaptive_step(model, x, t, new_dt, condition, tol)
```

---

## ğŸ“ é‡è¦æ›´æ–°è¯´æ˜

### åŸºäºåé¦ˆçš„å…³é”®æ”¹è¿›

#### 1. é¿å…å†—ä½™æ˜ å°„è¡¨
**åŸæ–¹æ¡ˆé—®é¢˜**ï¼šåˆ›å»ºäº†äººå·¥çš„`DATASET_DOMAIN_MAPPING`å’Œ`SYSTEM_TYPE_MAPPING`
**æ”¹è¿›åæ–¹æ¡ˆ**ï¼š
- âœ… ç›´æ¥ä½¿ç”¨PHM-Vibenchç°æœ‰çš„`metadata[file_id]['Dataset_id']`
- âœ… ç›´æ¥ä½¿ç”¨PHM-Vibenchç°æœ‰çš„`metadata[file_id]['Domain_id']`  
- âœ… æ— éœ€ç»´æŠ¤é¢å¤–çš„æ˜ å°„å…³ç³»

#### 2. æ™ºèƒ½å¤„ç†æœªçŸ¥å€¼
**æ”¯æŒåœºæ™¯**ï¼š
- âœ… `Domain_id`æˆ–`Dataset_id`ä¸ºNaN/None
- âœ… æ–°å¢æ•°æ®é›†çš„åŠ¨æ€é€‚åº”
- âœ… metadataå­—æ®µç¼ºå¤±çš„å®¹é”™å¤„ç†

**å¤„ç†ç­–ç•¥**ï¼š
```python
# ç¼ºå¤±å€¼ç»Ÿä¸€å¤„ç†ä¸º-1ï¼Œç„¶åæ˜ å°„åˆ°padding_idx=0
domain_id = metadata_dict.get('Domain_id', -1)
if pd.isna(domain_id) or domain_id is None:
    domain_id = -1  # æ ‡è®°ä¸ºæœªçŸ¥
# åœ¨embeddingæ—¶ï¼š-1 -> 0 (padding_idx)
```

#### 3. åŠ¨æ€å®¹é‡åˆ†é…
**æ™ºèƒ½ç»Ÿè®¡**ï¼š
```python
stats = MetadataConditionExtractor.get_metadata_statistics(metadata.df)
args_m.num_domains = max(stats['num_domains'], 10) + 10  # é¢„ç•™æ‰©å±•ç©ºé—´
args_m.num_systems = max(stats['num_systems'], 10) + 10
```

#### 4. æ–‡ä»¶ç»“æ„å¯¹é½
- `components/` â†’ `layers/` (ä¸ç”¨æˆ·ç¼–è¾‘ä¸€è‡´)
- åˆ é™¤`metadata_extractor.py`(ä¸å†éœ€è¦)
- ä¿æŒä¸PHM-Vibenchç°æœ‰æ¶æ„çš„ä¸€è‡´æ€§

---

## ğŸ”§ ç®€åŒ–åçš„åˆ†é˜¶æ®µå®æ–½æ–¹æ¡ˆ

**è®¾è®¡åŸåˆ™**: é¿å…ç‚«æŠ€å¤æ‚åº¦ï¼Œä¸€ä¸ªæ–¹æ¡ˆä¼˜äºå¤šä¸ªé€‰æ‹©

### Phase 1: æœ€å°å¯è¡Œç‰ˆæœ¬ (ç¬¬1-4å¤©)

#### 1.1 ç®€åŒ–çš„é¡¹ç›®ç»“æ„

```bash
# æœ€å°åŒ–æ–‡ä»¶ç»“æ„
src/model_factory/ISFM/
â”œâ”€â”€ M_04_ISFM_Flow.py           # ä¸»é›†æˆæ¨¡å‹
â”œâ”€â”€ layers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ flow_model.py           # RectifiedFlowæ ¸å¿ƒ(åˆå¹¶åŸGM_01)
â”‚   â””â”€â”€ condition_encoder.py    # æ¡ä»¶ç¼–ç (åˆå¹¶åŸE_03)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ flow_utils.py           # å¿…è¦å·¥å…·å‡½æ•°(ç»´åº¦é€‚é…ç­‰)
â””â”€â”€ tests/
    â”œâ”€â”€ test_flow_basics.py     # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    â””â”€â”€ test_integration.py     # é›†æˆæµ‹è¯•
```

#### 1.2 å®æ–½æ­¥éª¤ (æ¸è¿›å¼å®ç°)

**Day 1-2: æ ¸å¿ƒFlowæ¨¡å‹**
- [ ] åˆ›å»º `flow_model.py` - åŸºç¡€RectifiedFlow
- [ ] ä»…å®ç°Euler ODEæ±‚è§£å™¨ (æœ€ç®€å•)
- [ ] ç›´æ¥å±•å¼€ç»´åº¦é€‚é… (B,L,C) â†’ (B,L*C)
- [ ] åŸºç¡€å‰å‘ä¼ æ’­å’Œé‡‡æ ·

**Day 3-4: æ¡ä»¶ç¼–ç ä¸é›†æˆ**
- [ ] åˆ›å»º `condition_encoder.py` - ç›´æ¥ä½¿ç”¨metadata
- [ ] æ”¯æŒDataset_idå’ŒDomain_id (æ— æ˜ å°„è¡¨)
- [ ] é›†æˆåˆ°ä¸»æ¨¡å‹ `M_04_ISFM_Flow.py`
- [ ] åŸºç¡€æµ‹è¯•éªŒè¯

#### 1.3 éªŒæ”¶æ ‡å‡†
- âœ… æ‰€æœ‰å½¢çŠ¶æµ‹è¯•é€šè¿‡ (>95%è¦†ç›–ç‡)
- âœ… æ”¯æŒå¯å˜åºåˆ—é•¿åº¦ (512-4096)
- âœ… å†…å­˜ä½¿ç”¨åˆç† (<8GB for batch_size=32)
- âœ… ä¸ç°æœ‰æ•°æ®åŠ è½½å™¨å…¼å®¹

### Phase 2: åŠŸèƒ½å®Œå–„ (ç¬¬5-8å¤©)

#### 2.1 è®­ç»ƒç³»ç»Ÿé›†æˆ

**Day 5-6: æŸå¤±å‡½æ•°ä¸è®­ç»ƒä»»åŠ¡**
- [ ] å®ç°åŸºç¡€RectifiedFlowæŸå¤±å‡½æ•°
- [ ] åˆ›å»ºé¢„è®­ç»ƒä»»åŠ¡ç±»é›†æˆTaskFactory
- [ ] åŸºç¡€é…ç½®æ–‡ä»¶æ¨¡æ¿
- [ ] ç«¯åˆ°ç«¯è®­ç»ƒæµ‹è¯•

**Day 7-8: ç¨³å®šæ€§å’Œæ€§èƒ½**
- [ ] æ·»åŠ æ¢¯åº¦è£å‰ªå’ŒNaNæ£€æµ‹
- [ ] åŸºç¡€æ€§èƒ½ä¼˜åŒ–(å†…å­˜ã€é€Ÿåº¦)
- [ ] æ”¯æŒå•æ•°æ®é›†è®­ç»ƒéªŒè¯
- [ ] å¦‚éœ€è¦å¯æ·»åŠ Heunæ±‚è§£å™¨

#### 2.2 éªŒæ”¶æ ‡å‡†(åŠ¡å®ç›®æ ‡)
- âœ… ç«¯åˆ°ç«¯è®­ç»ƒæˆåŠŸ(10+ epochs)
- âœ… æŸå¤±æ”¶æ•›ç¨³å®šæ— NaN
- âœ… ç”Ÿæˆæ ·æœ¬åŸºæœ¬åˆç†
- âœ… ä¸ç°æœ‰æ¡†æ¶æ— å†²çª

### Phase 3: ä¼˜åŒ–æå‡ (ç¬¬9-12å¤©)

#### 3.1 æµ‹è¯•ä¸éªŒè¯

**Day 9-10: å…¨é¢æµ‹è¯•è¦†ç›–**
- [ ] å®Œå–„å•å…ƒæµ‹è¯•è¦†ç›–æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½
- [ ] å¤šæ•°æ®é›†å…¼å®¹æ€§æµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•å’Œå†…å­˜åˆ†æ
- [ ] è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•

**Day 11-12: æ€§èƒ½ä¼˜åŒ–ä¸æ–‡æ¡£**
- [ ] æ ¹æ®æµ‹è¯•ç»“æœä¼˜åŒ–æ€§èƒ½ç“¶é¢ˆ
- [ ] å®Œå–„é…ç½®æ–‡ä»¶å’Œä½¿ç”¨ç¤ºä¾‹
- [ ] åˆ›å»ºç®€æ´çš„ä½¿ç”¨æ–‡æ¡£
- [ ] å‡†å¤‡é›†æˆåˆ°ä¸»åˆ†æ”¯

#### 3.2 éªŒæ”¶æ ‡å‡†(æœ€ç»ˆç›®æ ‡)
- âœ… æµ‹è¯•è¦†ç›–ç‡ >90%
- âœ… æ”¯æŒä¸»è¦PHM-Vibenchæ•°æ®é›†
- âœ… æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸ
- âœ… ä»£ç é€šè¿‡review

---

## ğŸ“Š å®æ–½é‡ç‚¹ç®€åŒ–

### 1. æ–‡ä»¶æœ€å°åŒ–
- `flow_model.py`: ä»…åŸºç¡€RectifiedFlow + Euleræ±‚è§£å™¨
- `condition_encoder.py`: ç›´æ¥ä½¿ç”¨Dataset_id/Domain_id
- `flow_utils.py`: ç»´åº¦é€‚é…ç­‰å¿…è¦å·¥å…·

### 2. åŠŸèƒ½æ¸è¿›å¼
- Phase 1: èƒ½è·‘çš„æœ€å°ç‰ˆæœ¬
- Phase 2: åŠ å…¥è®­ç»ƒå’ŒæŸå¤±
- Phase 3: æµ‹è¯•å’Œä¼˜åŒ–

### 3. é¿å…è¿‡åº¦è®¾è®¡
- åˆ é™¤å¤šæ±‚è§£å™¨é€‰æ‹©ï¼ˆå…ˆç”¨Eulerï¼‰
- åˆ é™¤å¤æ‚ç»´åº¦é€‚é…ï¼ˆç›´æ¥å±•å¼€ï¼‰
- åˆ é™¤è¿‡å¤šå·¥å…·æ–‡ä»¶

---

## ğŸ’» æ ¸å¿ƒä»£ç æ¡†æ¶

### åŸºç¡€RectifiedFlowå®ç°

```python
# src/model_factory/ISFM/layers/flow_model.py - æœ€ç®€å®ç°
class RectifiedFlow(nn.Module):
    def __init__(self, latent_dim, hidden_dim):
        super().__init__()
        self.velocity_net = nn.Sequential(
            nn.Linear(latent_dim + 64, hidden_dim),  # +64 for time embedding
            nn.SiLU(),
            nn.Linear(hidden_dim, latent_dim)
        )
        
    def forward(self, x, t):
        # ç®€åŒ–çš„å‰å‘ä¼ æ’­
        noise = torch.randn_like(x) 
        x_t = (1 - t) * noise + t * x
        v_pred = self.velocity_net(torch.cat([x_t, self.time_emb(t)], dim=-1))
        return {'v_pred': v_pred, 'v_true': x - noise}
```

---

## â±ï¸ æ—¶é—´çº¿æ€»ç»“

**12å¤©æ€»è®¡**:
- Phase 1 (Day 1-4): æœ€å°å¯è¡Œç‰ˆæœ¬
- Phase 2 (Day 5-8): è®­ç»ƒé›†æˆ
- Phase 3 (Day 9-12): æµ‹è¯•ä¼˜åŒ–

**ç®€åŒ–åŸåˆ™**: æ¯ä¸ªé˜¶æ®µéƒ½æœ‰å¯å·¥ä½œçš„ç‰ˆæœ¬ï¼Œé¿å…å¤§çˆ†ç‚¸å¼å¼€å‘

---

*ç®€åŒ–ç‰ˆå®æ–½è®¡åˆ’ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½ï¼Œé¿å…ç‚«æŠ€å¤æ‚åº¦*  
*æ›´æ–°æ—¶é—´ï¼š2025å¹´8æœˆ30æ—¥*
