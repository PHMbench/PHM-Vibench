# GM (Generative Model) Flow ä¼˜åŒ–å®æ–½è®¡åˆ’

**åˆ›å»ºæ—¥æœŸï¼š2025å¹´8æœˆ30æ—¥**  
**ç‰ˆæœ¬ï¼šV3.0 - ç”Ÿæˆæ¨¡å‹ä¸“æ³¨ç‰ˆ**  
**ä¼˜åŒ–é‡ç‚¹ï¼šç”Ÿæˆæ¨¡å‹ + è‡ªæµ‹è¯•ä»£ç  + TDDæ–¹æ³•**

---

## ğŸ¯ GM (Generative Model) å®šä½

### æ ¸å¿ƒç†å¿µ

Flowæ¨¡å‹åœ¨PHM-Vibenchä¸­çš„å®šä½ä¸º**ç”Ÿæˆæ¨¡å‹ (Generative Model, GM)**ï¼š

- **æ•°æ®å¢å¼º**ï¼šç”Ÿæˆé«˜è´¨é‡çš„å·¥ä¸šä¿¡å·æ ·æœ¬
- **å¼‚å¸¸æ£€æµ‹**ï¼šé€šè¿‡é‡å»ºè¯¯å·®æ£€æµ‹è®¾å¤‡å¼‚å¸¸
- **åŸŸé€‚åº”**ï¼šç”Ÿæˆç›®æ ‡åŸŸæ•°æ®æé«˜æ³›åŒ–æ€§
- **å°‘æ ·æœ¬å­¦ä¹ **ï¼šä¸ºç¨€ç¼ºæ•…éšœç±»åˆ«ç”Ÿæˆè®­ç»ƒæ ·æœ¬
- **ä¿¡å·å»å™ª**ï¼šå­¦ä¹ æ•°æ®åˆ†å¸ƒè¿›è¡Œä¿¡å·æ¸…ç†

---

## ğŸ“ æ¨¡å—æ¶æ„è®¾è®¡

### GMæ¨¡å—å±‚æ¬¡ç»“æ„

```
src/model_factory/GM/                    # ç”Ÿæˆæ¨¡å‹ä¸»ç›®å½•
â”œâ”€â”€ __init__.py                          # å·¥å‚æ³¨å†Œ
â”œâ”€â”€ GM_01_RectifiedFlow.py              # çŸ«æ­£æµç”Ÿæˆç½‘ç»œ
â”œâ”€â”€ GM_02_ConditionalFlow.py            # æ¡ä»¶æµç½‘ç»œ (æœªæ¥æ‰©å±•)
â”œâ”€â”€ GM_03_HierarchicalFlow.py           # å±‚æ¬¡åŒ–æµç½‘ç»œ (æœªæ¥æ‰©å±•)
â””â”€â”€ utils/                              # ç”Ÿæˆæ¨¡å‹å·¥å…·
    â”œâ”€â”€ flow_utils.py                   # æµåŒ¹é…å·¥å…·å‡½æ•°
    â”œâ”€â”€ sampling.py                     # é‡‡æ ·ç®—æ³•
    â””â”€â”€ interpolation.py                # æ’å€¼æ–¹æ³•
```

---

## ğŸ”¬ ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒGMæ¨¡å—å®ç°

### GM_01_RectifiedFlow.py - å®Œæ•´å®ç°

```python
"""
çŸ«æ­£æµç”Ÿæˆç½‘ç»œ (Rectified Flow Generative Model)
ç”¨äºå·¥ä¸šä¿¡å·çš„ç”Ÿæˆå¼å»ºæ¨¡å’Œè¡¨ç¤ºå­¦ä¹ 

ä¸»è¦åŠŸèƒ½:
1. çŸ«æ­£æµåŒ¹é… (Rectified Flow Matching)
2. æ¡ä»¶ç”Ÿæˆ (Conditional Generation)
3. å™ªå£°åˆ°æ•°æ®çš„ç›´çº¿æ’å€¼ (Linear Interpolation)
4. æ•°æ®å¢å¼º (Data Augmentation)
5. å¼‚å¸¸æ£€æµ‹ (Anomaly Detection)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Optional, Tuple, Dict, Any, List
import math


class SinusoidalPositionalEmbedding(nn.Module):
    """æ­£å¼¦ä½ç½®ç¼–ç ç”¨äºæ—¶é—´æ­¥åµŒå…¥"""
    
    def __init__(self, dim: int, max_timescale: float = 10000.0):
        super().__init__()
        self.dim = dim
        self.max_timescale = max_timescale
        
    def forward(self, t: torch.Tensor) -> torch.Tensor:
        """
        Args:
            t: æ—¶é—´æ­¥ (batch_size,) èŒƒå›´ [0, 1]
        Returns:
            pos_emb: (batch_size, dim)
        """
        half_dim = self.dim // 2
        emb = math.log(self.max_timescale) / (half_dim - 1)
        emb = torch.exp(torch.arange(half_dim, device=t.device, dtype=torch.float32) * -emb)
        emb = t.unsqueeze(-1).float() * emb.unsqueeze(0)
        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)
        return emb


class ConditionalMLP(nn.Module):
    """æ¡ä»¶å¤šå±‚æ„ŸçŸ¥æœº - æ”¯æŒæ—¶é—´å’Œæ¡ä»¶è¾“å…¥"""
    
    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int,
                 time_dim: int, condition_dim: int = 0, num_layers: int = 3,
                 activation: str = 'silu', dropout: float = 0.1):
        super().__init__()
        
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.condition_dim = condition_dim
        
        # æ—¶é—´åµŒå…¥æŠ•å½±
        self.time_proj = nn.Linear(time_dim, hidden_dim)
        
        # æ¡ä»¶æŠ•å½±ï¼ˆå¦‚æœæœ‰æ¡ä»¶ï¼‰
        if condition_dim > 0:
            self.condition_proj = nn.Linear(condition_dim, hidden_dim)
        
        # ä¸»ç½‘ç»œ
        layers = []
        total_input_dim = input_dim + hidden_dim + (hidden_dim if condition_dim > 0 else 0)
        
        for i in range(num_layers):
            if i == 0:
                layers.append(nn.Linear(total_input_dim, hidden_dim))
            elif i == num_layers - 1:
                layers.append(nn.Linear(hidden_dim, output_dim))
            else:
                layers.append(nn.Linear(hidden_dim, hidden_dim))
                
            # é™¤äº†æœ€åä¸€å±‚ï¼Œéƒ½åŠ æ¿€æ´»å‡½æ•°å’Œdropout
            if i < num_layers - 1:
                layers.append(nn.LayerNorm(hidden_dim))
                if activation.lower() == 'silu':
                    layers.append(nn.SiLU())
                elif activation.lower() == 'relu':
                    layers.append(nn.ReLU())
                elif activation.lower() == 'gelu':
                    layers.append(nn.GELU())
                    
                if dropout > 0:
                    layers.append(nn.Dropout(dropout))
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x: torch.Tensor, t_emb: torch.Tensor, 
                condition: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Args:
            x: è¾“å…¥ç‰¹å¾ (batch_size, input_dim)
            t_emb: æ—¶é—´åµŒå…¥ (batch_size, time_dim)
            condition: æ¡ä»¶ä¿¡æ¯ (batch_size, condition_dim)
        Returns:
            output: (batch_size, output_dim)
        """
        # æ—¶é—´æŠ•å½±
        t_proj = self.time_proj(t_emb)
        
        # æ„å»ºè¾“å…¥
        inputs = [x, t_proj]
        
        if condition is not None and self.condition_dim > 0:
            c_proj = self.condition_proj(condition)
            inputs.append(c_proj)
            
        # æ‹¼æ¥å¹¶å‰å‘ä¼ æ’­
        x_input = torch.cat(inputs, dim=-1)
        return self.network(x_input)


class GM_01_RectifiedFlow(nn.Module):
    """
    çŸ«æ­£æµç”Ÿæˆæ¨¡å‹ (Rectified Flow Generative Model)
    
    ç”¨äºå·¥ä¸šä¿¡å·çš„ç”Ÿæˆå¼å»ºæ¨¡ï¼Œæ”¯æŒï¼š
    - æ— æ¡ä»¶ç”Ÿæˆ
    - æ¡ä»¶ç”Ÿæˆï¼ˆåŸºäºåŸŸ/ç³»ç»Ÿ/æ•…éšœç±»å‹ï¼‰
    - æ•°æ®å¢å¼º
    - å¼‚å¸¸æ£€æµ‹
    - æ’å€¼ç”Ÿæˆ
    """
    
    def __init__(self, args_m):
        super().__init__()
        
        # æ¨¡å‹é…ç½®
        self.latent_dim = getattr(args_m, 'latent_dim', 128)
        self.condition_dim = getattr(args_m, 'condition_dim', 64)
        self.hidden_dim = getattr(args_m, 'hidden_dim', 256)
        self.time_dim = getattr(args_m, 'time_dim', 64)
        self.num_layers = getattr(args_m, 'num_layers', 4)
        self.dropout = getattr(args_m, 'dropout', 0.1)
        self.activation = getattr(args_m, 'activation', 'silu')
        
        # å™ªå£°å‚æ•°
        self.sigma_min = getattr(args_m, 'sigma_min', 0.001)
        self.sigma_max = getattr(args_m, 'sigma_max', 1.0)
        
        # æ—¶é—´åµŒå…¥
        self.time_embedding = SinusoidalPositionalEmbedding(self.time_dim)
        
        # é€Ÿåº¦é¢„æµ‹ç½‘ç»œ - çŸ«æ­£æµçš„æ ¸å¿ƒ
        self.velocity_net = ConditionalMLP(
            input_dim=self.latent_dim,
            output_dim=self.latent_dim,
            hidden_dim=self.hidden_dim,
            time_dim=self.time_dim,
            condition_dim=self.condition_dim,
            num_layers=self.num_layers,
            activation=self.activation,
            dropout=self.dropout
        )
        
        # æƒé‡åˆå§‹åŒ–
        self.apply(self._init_weights)
        
    def _init_weights(self, module):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡"""
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.LayerNorm):
            torch.nn.init.zeros_(module.bias)
            torch.nn.init.ones_(module.weight)
    
    def forward(self, x: torch.Tensor, condition: Optional[torch.Tensor] = None,
                return_intermediates: bool = False) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­ - ç”¨äºè®­ç»ƒ
        
        Args:
            x: ç›®æ ‡æ•°æ® (batch_size, latent_dim)
            condition: æ¡ä»¶ä¿¡æ¯ (batch_size, condition_dim)
            return_intermediates: æ˜¯å¦è¿”å›ä¸­é—´ç»“æœ
            
        Returns:
            dict: åŒ…å«æŸå¤±è®¡ç®—æ‰€éœ€çš„æ‰€æœ‰é¡¹
        """
        batch_size = x.size(0)
        device = x.device
        
        # 1. é‡‡æ ·æ—¶é—´æ­¥ t ~ Uniform[0, 1]
        t = torch.rand(batch_size, device=device)
        
        # 2. é‡‡æ ·å™ªå£° z ~ N(0, ÏƒÂ²I)ï¼ŒÏƒåœ¨è®­ç»ƒä¸­é€æ¸å‡å°
        sigma = self.sigma_min + (self.sigma_max - self.sigma_min) * torch.rand(batch_size, 1, device=device)
        noise = torch.randn_like(x) * sigma
        
        # 3. çŸ«æ­£æµæ’å€¼: x_t = (1-t)*noise + t*x
        t_expanded = t.view(batch_size, 1)
        x_t = (1 - t_expanded) * noise + t_expanded * x
        
        # 4. çœŸå®é€Ÿåº¦åœº: v_true = x - noise (ä»å™ªå£°æŒ‡å‘æ•°æ®çš„æ–¹å‘)
        v_true = x - noise
        
        # 5. æ—¶é—´åµŒå…¥
        t_emb = self.time_embedding(t)
        
        # 6. é¢„æµ‹é€Ÿåº¦åœº
        v_pred = self.velocity_net(x_t, t_emb, condition)
        
        # æ„å»ºè¾“å‡ºå­—å…¸
        outputs = {
            'v_pred': v_pred,
            'v_true': v_true,
            'x_t': x_t,
            'noise': noise,
            't': t,
            'sigma': sigma
        }
        
        if return_intermediates:
            outputs.update({
                't_emb': t_emb,
                'x_original': x
            })
        
        return outputs
    
    def sample(self, batch_size: int, condition: Optional[torch.Tensor] = None,
               num_steps: int = 50, device: str = 'cuda',
               return_trajectory: bool = False) -> torch.Tensor:
        """
        é‡‡æ ·ç”Ÿæˆæ–°æ•°æ®
        
        Args:
            batch_size: æ‰¹é‡å¤§å°
            condition: æ¡ä»¶ä¿¡æ¯ (batch_size, condition_dim)
            num_steps: é‡‡æ ·æ­¥æ•°
            device: è®¡ç®—è®¾å¤‡
            return_trajectory: æ˜¯å¦è¿”å›å®Œæ•´è½¨è¿¹
            
        Returns:
            samples: ç”Ÿæˆçš„æ ·æœ¬ (batch_size, latent_dim)
            æˆ– trajectory: å®Œæ•´é‡‡æ ·è½¨è¿¹ (num_steps+1, batch_size, latent_dim)
        """
        self.eval()
        
        # ä»æ ‡å‡†é«˜æ–¯å¼€å§‹
        x = torch.randn(batch_size, self.latent_dim, device=device) * self.sigma_max
        
        if return_trajectory:
            trajectory = [x.clone()]
        
        # æ—¶é—´æ­¥é•¿
        dt = 1.0 / num_steps
        
        with torch.no_grad():
            for i in range(num_steps):
                t = torch.full((batch_size,), i * dt, device=device)
                t_emb = self.time_embedding(t)
                
                # é¢„æµ‹é€Ÿåº¦
                v = self.velocity_net(x, t_emb, condition)
                
                # æ¬§æ‹‰ç§¯åˆ†æ›´æ–°
                x = x + dt * v
                
                if return_trajectory:
                    trajectory.append(x.clone())
        
        if return_trajectory:
            return torch.stack(trajectory, dim=0)
        else:
            return x
    
    def compute_loss(self, batch_outputs: Dict[str, torch.Tensor],
                     loss_type: str = 'mse') -> Dict[str, torch.Tensor]:
        """
        è®¡ç®—çŸ«æ­£æµæŸå¤±
        
        Args:
            batch_outputs: forward()çš„è¾“å‡º
            loss_type: æŸå¤±ç±»å‹ ('mse', 'huber', 'mae')
            
        Returns:
            losses: å„ç§æŸå¤±é¡¹
        """
        v_pred = batch_outputs['v_pred']
        v_true = batch_outputs['v_true']
        
        # ä¸»è¦çš„æµåŒ¹é…æŸå¤±
        if loss_type == 'mse':
            flow_loss = F.mse_loss(v_pred, v_true)
        elif loss_type == 'huber':
            flow_loss = F.huber_loss(v_pred, v_true, delta=1.0)
        elif loss_type == 'mae':
            flow_loss = F.l1_loss(v_pred, v_true)
        else:
            flow_loss = F.mse_loss(v_pred, v_true)
        
        # æ­£åˆ™åŒ–æŸå¤± - é˜²æ­¢é€Ÿåº¦åœºè¿‡å¤§
        velocity_reg = torch.mean(v_pred.pow(2))
        
        # æ—¶é—´ä¸€è‡´æ€§æŸå¤± - ç›¸é‚»æ—¶é—´æ­¥çš„é€Ÿåº¦åº”è¯¥å¹³æ»‘
        if 't' in batch_outputs:
            t = batch_outputs['t']
            # å¯¹æ—¶é—´æ¢¯åº¦è¿›è¡Œæƒ©ç½šï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
            time_reg = torch.tensor(0.0, device=v_pred.device)
        else:
            time_reg = torch.tensor(0.0, device=v_pred.device)
        
        return {
            'flow_loss': flow_loss,
            'velocity_reg': velocity_reg,
            'time_reg': time_reg,
            'total_loss': flow_loss + 0.001 * velocity_reg + 0.001 * time_reg
        }
    
    def interpolate(self, x0: torch.Tensor, x1: torch.Tensor, 
                   steps: int = 10) -> torch.Tensor:
        """
        åœ¨ä¸¤ä¸ªæ ·æœ¬ä¹‹é—´è¿›è¡Œå¹³æ»‘æ’å€¼
        
        Args:
            x0: èµ·å§‹æ ·æœ¬ (batch_size, latent_dim)
            x1: ç»“æŸæ ·æœ¬ (batch_size, latent_dim)
            steps: æ’å€¼æ­¥æ•°
            
        Returns:
            interpolated: æ’å€¼åºåˆ— (steps, batch_size, latent_dim)
        """
        device = x0.device
        batch_size = x0.size(0)
        
        # åˆ›å»ºæ—¶é—´ç½‘æ ¼
        t_values = torch.linspace(0, 1, steps, device=device)
        interpolated = []
        
        for t_val in t_values:
            t_expanded = t_val.expand(batch_size, 1)
            x_t = (1 - t_expanded) * x0 + t_expanded * x1
            interpolated.append(x_t)
        
        return torch.stack(interpolated, dim=0)
    
    def encode_to_noise(self, x: torch.Tensor, condition: Optional[torch.Tensor] = None,
                       num_steps: int = 50) -> torch.Tensor:
        """
        å°†æ•°æ®ç¼–ç ä¸ºå™ªå£°ï¼ˆåå‘è¿‡ç¨‹ï¼‰
        
        Args:
            x: æ•°æ®æ ·æœ¬ (batch_size, latent_dim)
            condition: æ¡ä»¶ä¿¡æ¯
            num_steps: ç¼–ç æ­¥æ•°
            
        Returns:
            noise: å¯¹åº”çš„å™ªå£° (batch_size, latent_dim)
        """
        self.eval()
        
        # åå‘æ—¶é—´ç§¯åˆ†
        current = x.clone()
        dt = 1.0 / num_steps
        
        with torch.no_grad():
            for i in range(num_steps):
                t = torch.full((x.size(0),), 1 - i * dt, device=x.device)
                t_emb = self.time_embedding(t)
                
                # åå‘é€Ÿåº¦
                v = self.velocity_net(current, t_emb, condition)
                current = current - dt * v
        
        return current
    
    def compute_likelihood(self, x: torch.Tensor, condition: Optional[torch.Tensor] = None,
                          num_steps: int = 50) -> torch.Tensor:
        """
        è®¡ç®—æ•°æ®çš„ä¼¼ç„¶ä¼°è®¡ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼‰
        
        Args:
            x: æ•°æ®æ ·æœ¬ (batch_size, latent_dim)
            condition: æ¡ä»¶ä¿¡æ¯
            num_steps: ä¼°è®¡æ­¥æ•°
            
        Returns:
            likelihood: ä¼¼ç„¶ä¼°è®¡ (batch_size,)
        """
        # ç¼–ç åˆ°å™ªå£°ç©ºé—´
        noise = self.encode_to_noise(x, condition, num_steps)
        
        # è®¡ç®—å™ªå£°çš„æ¦‚ç‡å¯†åº¦
        log_prob = -0.5 * torch.sum(noise.pow(2), dim=-1) - \
                   0.5 * self.latent_dim * math.log(2 * math.pi)
        
        return torch.exp(log_prob)


# è‡ªæµ‹è¯•ä»£ç 
if __name__ == '__main__':
    """GM_01_RectifiedFlow ç”Ÿæˆæ¨¡å‹æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ”¬ GM_01_RectifiedFlow ç”Ÿæˆæ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    # Mocké…ç½®
    class MockConfig:
        def __init__(self):
            self.latent_dim = 128
            self.condition_dim = 64
            self.hidden_dim = 256
            self.time_dim = 64
            self.num_layers = 4
            self.dropout = 0.1
            self.activation = 'silu'
            self.sigma_min = 0.001
            self.sigma_max = 1.0
    
    config = MockConfig()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–
    print(f"\nğŸ—ï¸  1. æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–...")
    model = GM_01_RectifiedFlow(config).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   âœ… æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"   âœ… æ½œåœ¨ç»´åº¦: {model.latent_dim}")
    print(f"   âœ… æ¡ä»¶ç»´åº¦: {model.condition_dim}")
    
    # 2. æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\nğŸ”„ 2. æµ‹è¯•å‰å‘ä¼ æ’­...")
    batch_size = 16
    x = torch.randn(batch_size, config.latent_dim, device=device)
    condition = torch.randn(batch_size, config.condition_dim, device=device)
    
    model.train()
    outputs = model(x, condition, return_intermediates=True)
    
    print(f"   âœ… è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"   âœ… æ¡ä»¶å½¢çŠ¶: {condition.shape}")
    print(f"   âœ… é¢„æµ‹é€Ÿåº¦å½¢çŠ¶: {outputs['v_pred'].shape}")
    print(f"   âœ… çœŸå®é€Ÿåº¦å½¢çŠ¶: {outputs['v_true'].shape}")
    print(f"   âœ… æ’å€¼ç‚¹å½¢çŠ¶: {outputs['x_t'].shape}")
    print(f"   âœ… æ—¶é—´åµŒå…¥å½¢çŠ¶: {outputs['t_emb'].shape}")
    
    # 3. æµ‹è¯•æŸå¤±è®¡ç®—
    print(f"\nğŸ“‰ 3. æµ‹è¯•æŸå¤±è®¡ç®—...")
    losses = model.compute_loss(outputs, loss_type='mse')
    
    print(f"   âœ… æµåŒ¹é…æŸå¤±: {losses['flow_loss'].item():.6f}")
    print(f"   âœ… é€Ÿåº¦æ­£åˆ™åŒ–æŸå¤±: {losses['velocity_reg'].item():.6f}")
    print(f"   âœ… æ€»æŸå¤±: {losses['total_loss'].item():.6f}")
    
    # æ£€æŸ¥æŸå¤±å€¼åˆç†æ€§
    assert not torch.isnan(losses['total_loss']), "âŒ æŸå¤±åŒ…å«NaN"
    assert losses['total_loss'].item() >= 0, "âŒ æŸå¤±ä¸ºè´Ÿå€¼"
    print("   âœ… æŸå¤±å€¼æ£€æŸ¥é€šè¿‡")
    
    # 4. æµ‹è¯•æ¢¯åº¦è®¡ç®—
    print(f"\nğŸ“ˆ 4. æµ‹è¯•æ¢¯åº¦è®¡ç®—...")
    losses['total_loss'].backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    grad_norms = []
    for name, param in model.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            grad_norms.append(grad_norm)
    
    avg_grad_norm = sum(grad_norms) / len(grad_norms)
    print(f"   âœ… å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.6f}")
    print(f"   âœ… æœ‰æ•ˆæ¢¯åº¦å‚æ•°: {len(grad_norms)}/{len(list(model.parameters()))}")
    
    # 5. æµ‹è¯•é‡‡æ ·ç”Ÿæˆ
    print(f"\nğŸ² 5. æµ‹è¯•é‡‡æ ·ç”Ÿæˆ...")
    model.eval()
    
    with torch.no_grad():
        # æ— æ¡ä»¶é‡‡æ ·
        samples = model.sample(
            batch_size=8, 
            num_steps=20,  # å‡å°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
            device=device
        )
        
        print(f"   âœ… ç”Ÿæˆæ ·æœ¬å½¢çŠ¶: {samples.shape}")
        print(f"   âœ… æ ·æœ¬ç»Ÿè®¡ - å‡å€¼: {samples.mean().item():.4f}, æ ‡å‡†å·®: {samples.std().item():.4f}")
        
        # æ¡ä»¶é‡‡æ ·
        test_condition = condition[:4]
        cond_samples = model.sample(
            batch_size=4,
            condition=test_condition,
            num_steps=20,
            device=device
        )
        
        print(f"   âœ… æ¡ä»¶ç”Ÿæˆæ ·æœ¬å½¢çŠ¶: {cond_samples.shape}")
        
        # è½¨è¿¹é‡‡æ ·
        trajectory = model.sample(
            batch_size=2,
            num_steps=10,
            device=device,
            return_trajectory=True
        )
        
        print(f"   âœ… é‡‡æ ·è½¨è¿¹å½¢çŠ¶: {trajectory.shape}")  # (steps+1, batch_size, latent_dim)
    
    # 6. æµ‹è¯•æ’å€¼åŠŸèƒ½
    print(f"\nğŸ”„ 6. æµ‹è¯•æ’å€¼åŠŸèƒ½...")
    x0 = torch.randn(4, config.latent_dim, device=device)
    x1 = torch.randn(4, config.latent_dim, device=device)
    
    interpolated = model.interpolate(x0, x1, steps=11)
    print(f"   âœ… æ’å€¼åºåˆ—å½¢çŠ¶: {interpolated.shape}")
    
    # éªŒè¯è¾¹ç•Œæ¡ä»¶
    start_error = torch.norm(interpolated[0] - x0).item()
    end_error = torch.norm(interpolated[-1] - x1).item()
    print(f"   âœ… èµ·å§‹ç‚¹è¯¯å·®: {start_error:.8f}")
    print(f"   âœ… ç»“æŸç‚¹è¯¯å·®: {end_error:.8f}")
    
    assert start_error < 1e-6, f"âŒ èµ·å§‹ç‚¹è¯¯å·®è¿‡å¤§: {start_error}"
    assert end_error < 1e-6, f"âŒ ç»“æŸç‚¹è¯¯å·®è¿‡å¤§: {end_error}"
    
    # 7. æµ‹è¯•ç¼–ç åˆ°å™ªå£°
    print(f"\nğŸ”„ 7. æµ‹è¯•æ•°æ®ç¼–ç ...")
    test_data = torch.randn(4, config.latent_dim, device=device)
    
    with torch.no_grad():
        encoded_noise = model.encode_to_noise(test_data, num_steps=20)
        
    print(f"   âœ… ç¼–ç å™ªå£°å½¢çŠ¶: {encoded_noise.shape}")
    print(f"   âœ… ç¼–ç å™ªå£°ç»Ÿè®¡ - å‡å€¼: {encoded_noise.mean().item():.4f}, æ ‡å‡†å·®: {encoded_noise.std().item():.4f}")
    
    # 8. æµ‹è¯•ä¼¼ç„¶è®¡ç®—
    print(f"\nğŸ“Š 8. æµ‹è¯•ä¼¼ç„¶ä¼°è®¡...")
    with torch.no_grad():
        likelihoods = model.compute_likelihood(test_data, num_steps=20)
        
    print(f"   âœ… ä¼¼ç„¶ä¼°è®¡å½¢çŠ¶: {likelihoods.shape}")
    print(f"   âœ… ä¼¼ç„¶å€¼èŒƒå›´: [{likelihoods.min().item():.6f}, {likelihoods.max().item():.6f}]")
    
    # 9. æµ‹è¯•ä¸åŒæŸå¤±ç±»å‹
    print(f"\nğŸ”§ 9. æµ‹è¯•ä¸åŒæŸå¤±ç±»å‹...")
    model.train()
    test_outputs = model(x[:4], condition[:4])
    
    for loss_type in ['mse', 'huber', 'mae']:
        losses = model.compute_loss(test_outputs, loss_type=loss_type)
        print(f"   âœ… {loss_type.upper()}æŸå¤±: {losses['flow_loss'].item():.6f}")
    
    # 10. æ€§èƒ½åŸºå‡†æµ‹è¯•
    print(f"\nâš¡ 10. æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    model.train()
    
    # è®­ç»ƒæ€§èƒ½
    import time
    start_time = time.time()
    
    for _ in range(10):
        x = torch.randn(batch_size, config.latent_dim, device=device)
        condition = torch.randn(batch_size, config.condition_dim, device=device)
        
        outputs = model(x, condition)
        losses = model.compute_loss(outputs)
        losses['total_loss'].backward()
        
        # æ¨¡æ‹Ÿä¼˜åŒ–å™¨æ­¥éª¤ï¼ˆæ¸…ç©ºæ¢¯åº¦ï¼‰
        model.zero_grad()
    
    train_time = time.time() - start_time
    print(f"   âœ… è®­ç»ƒ10æ¬¡è¿­ä»£æ—¶é—´: {train_time:.3f}ç§’ ({10/train_time:.1f} iter/s)")
    
    # é‡‡æ ·æ€§èƒ½
    model.eval()
    start_time = time.time()
    
    with torch.no_grad():
        for _ in range(5):
            samples = model.sample(batch_size, num_steps=50, device=device)
    
    sample_time = time.time() - start_time
    print(f"   âœ… é‡‡æ ·5æ¬¡æ—¶é—´: {sample_time:.3f}ç§’ ({5/sample_time:.1f} samples/s)")
    
    # 11. å†…å­˜ä½¿ç”¨æµ‹è¯•
    print(f"\nğŸ’¾ 11. å†…å­˜ä½¿ç”¨æµ‹è¯•...")
    if device == 'cuda':
        torch.cuda.empty_cache()
        initial_memory = torch.cuda.memory_allocated() / 1024**2  # MB
        
        # å¤§æ‰¹é‡æµ‹è¯•
        large_batch = 64
        x_large = torch.randn(large_batch, config.latent_dim, device=device)
        cond_large = torch.randn(large_batch, config.condition_dim, device=device)
        
        outputs_large = model(x_large, cond_large)
        losses_large = model.compute_loss(outputs_large)
        
        peak_memory = torch.cuda.memory_allocated() / 1024**2  # MB
        memory_usage = peak_memory - initial_memory
        
        print(f"   âœ… å¤§æ‰¹é‡({large_batch})å†…å­˜ä½¿ç”¨: {memory_usage:.2f} MB")
        
        torch.cuda.empty_cache()
    else:
        print("   â­ï¸  CPUæ¨¡å¼ï¼Œè·³è¿‡GPUå†…å­˜æµ‹è¯•")
    
    # 12. æ•°å€¼ç¨³å®šæ€§æµ‹è¯•
    print(f"\nğŸ” 12. æ•°å€¼ç¨³å®šæ€§æµ‹è¯•...")
    
    # æµ‹è¯•æç«¯è¾“å…¥
    extreme_x = torch.ones(4, config.latent_dim, device=device) * 100
    extreme_condition = torch.ones(4, config.condition_dim, device=device) * -100
    
    try:
        extreme_outputs = model(extreme_x, extreme_condition)
        extreme_losses = model.compute_loss(extreme_outputs)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–Inf
        has_nan = torch.isnan(extreme_losses['total_loss']).any()
        has_inf = torch.isinf(extreme_losses['total_loss']).any()
        
        if not has_nan and not has_inf:
            print("   âœ… æç«¯è¾“å…¥æ•°å€¼ç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
        else:
            print(f"   âš ï¸  æç«¯è¾“å…¥äº§ç”Ÿäº†NaN({has_nan})æˆ–Inf({has_inf})")
            
    except Exception as e:
        print(f"   âš ï¸  æç«¯è¾“å…¥æµ‹è¯•å¤±è´¥: {e}")
    
    print(f"\n" + "=" * 60)
    print("ğŸ‰ GM_01_RectifiedFlow ç”Ÿæˆæ¨¡å‹æµ‹è¯•å®Œæˆ!")
    print("âœ… æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸è¿è¡Œ")
    print("ğŸ“ˆ æ¨¡å‹å·²å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒå’Œéƒ¨ç½²")
    print("ğŸš€ å¯ä»¥å¼€å§‹é›†æˆåˆ°PHM-Vibenchæ¡†æ¶ä¸­")
    print("=" * 60)
```

---

## ğŸ“ E_03_ConditionalEncoder.py - æ¡ä»¶ç¼–ç å™¨

```python
"""
æ¡ä»¶ç¼–ç å™¨ (Conditional Encoder)
ç”¨äºå·¥ä¸šä¿¡å·çš„å±‚æ¬¡åŒ–æ¡ä»¶ç¼–ç 

ä¸»è¦åŠŸèƒ½:
1. åŸŸæ¡ä»¶ç¼–ç  (Domain Conditioning)
2. ç³»ç»Ÿæ¡ä»¶ç¼–ç  (System Conditioning)
3. å±‚æ¬¡åŒ–è¡¨ç¤ºå­¦ä¹  (Hierarchical Representation)
4. å¤šæ¨¡æ€æ¡ä»¶èåˆ (Multi-modal Fusion)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Any, List, Union


class DomainEncoder(nn.Module):
    """åŸŸç¼–ç å™¨ - ç¼–ç æ•°æ®æ¥æºåŸŸä¿¡æ¯"""
    
    def __init__(self, num_domains: int, embed_dim: int, hidden_dim: int = None):
        super().__init__()
        self.num_domains = num_domains
        self.embed_dim = embed_dim
        hidden_dim = hidden_dim or embed_dim
        
        # åŸŸåµŒå…¥
        self.domain_embedding = nn.Embedding(num_domains, embed_dim)
        
        # åŸŸç‰¹å¾å˜æ¢
        self.domain_transform = nn.Sequential(
            nn.Linear(embed_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, embed_dim)
        )
        
    def forward(self, domain_ids: torch.Tensor) -> torch.Tensor:
        """
        Args:
            domain_ids: åŸŸID (batch_size,)
        Returns:
            domain_features: åŸŸç‰¹å¾ (batch_size, embed_dim)
        """
        domain_emb = self.domain_embedding(domain_ids)
        domain_features = self.domain_transform(domain_emb)
        return domain_features


class SystemEncoder(nn.Module):
    """ç³»ç»Ÿç¼–ç å™¨ - ç¼–ç è®¾å¤‡ç³»ç»Ÿä¿¡æ¯"""
    
    def __init__(self, num_systems: int, embed_dim: int, hidden_dim: int = None):
        super().__init__()
        self.num_systems = num_systems
        self.embed_dim = embed_dim
        hidden_dim = hidden_dim or embed_dim
        
        # ç³»ç»ŸåµŒå…¥
        self.system_embedding = nn.Embedding(num_systems, embed_dim)
        
        # ç³»ç»Ÿç‰¹å¾å˜æ¢
        self.system_transform = nn.Sequential(
            nn.Linear(embed_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, embed_dim)
        )
        
    def forward(self, system_ids: torch.Tensor) -> torch.Tensor:
        """
        Args:
            system_ids: ç³»ç»ŸID (batch_size,)
        Returns:
            system_features: ç³»ç»Ÿç‰¹å¾ (batch_size, embed_dim)
        """
        system_emb = self.system_embedding(system_ids)
        system_features = self.system_transform(system_emb)
        return system_features


class InstanceEncoder(nn.Module):
    """å®ä¾‹ç¼–ç å™¨ - ç¼–ç å…·ä½“å®ä¾‹ä¿¡æ¯"""
    
    def __init__(self, input_dim: int, embed_dim: int, hidden_dim: int = None):
        super().__init__()
        self.input_dim = input_dim
        self.embed_dim = embed_dim
        hidden_dim = hidden_dim or embed_dim * 2
        
        # å®ä¾‹ç‰¹å¾æå–
        self.instance_encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, embed_dim)
        )
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Args:
            x: è¾“å…¥ç‰¹å¾ (batch_size, input_dim)
        Returns:
            instance_features: å®ä¾‹ç‰¹å¾ (batch_size, embed_dim)
        """
        return self.instance_encoder(x)


class HierarchicalFusion(nn.Module):
    """å±‚æ¬¡åŒ–èåˆæ¨¡å—"""
    
    def __init__(self, embed_dim: int, fusion_type: str = 'attention'):
        super().__init__()
        self.embed_dim = embed_dim
        self.fusion_type = fusion_type
        
        if fusion_type == 'attention':
            self.attention = nn.MultiheadAttention(embed_dim, num_heads=8, batch_first=True)
            self.norm = nn.LayerNorm(embed_dim)
        elif fusion_type == 'gating':
            self.gate = nn.Sequential(
                nn.Linear(embed_dim * 3, embed_dim),
                nn.Sigmoid()
            )
        elif fusion_type == 'concatenate':
            self.fusion_layer = nn.Sequential(
                nn.Linear(embed_dim * 3, embed_dim * 2),
                nn.ReLU(),
                nn.Linear(embed_dim * 2, embed_dim)
            )
    
    def forward(self, domain_feat: torch.Tensor, system_feat: torch.Tensor,
                instance_feat: torch.Tensor) -> torch.Tensor:
        """
        Args:
            domain_feat: åŸŸç‰¹å¾ (batch_size, embed_dim)
            system_feat: ç³»ç»Ÿç‰¹å¾ (batch_size, embed_dim)
            instance_feat: å®ä¾‹ç‰¹å¾ (batch_size, embed_dim)
        Returns:
            fused_features: èåˆåçš„ç‰¹å¾ (batch_size, embed_dim)
        """
        if self.fusion_type == 'attention':
            # å°†ä¸‰ä¸ªç‰¹å¾ä½œä¸ºåºåˆ—
            features = torch.stack([domain_feat, system_feat, instance_feat], dim=1)  # (B, 3, E)
            
            # è‡ªæ³¨æ„åŠ›èåˆ
            fused, _ = self.attention(features, features, features)
            fused = self.norm(fused + features)
            
            # å¹³å‡æ± åŒ–å¾—åˆ°æœ€ç»ˆç‰¹å¾
            return fused.mean(dim=1)
            
        elif self.fusion_type == 'gating':
            # é—¨æ§èåˆ
            concat_feat = torch.cat([domain_feat, system_feat, instance_feat], dim=-1)
            gate_weights = self.gate(concat_feat)
            
            weighted_sum = (gate_weights * domain_feat + 
                          gate_weights * system_feat + 
                          gate_weights * instance_feat) / 3
            return weighted_sum
            
        elif self.fusion_type == 'concatenate':
            # ç®€å•æ‹¼æ¥èåˆ
            concat_feat = torch.cat([domain_feat, system_feat, instance_feat], dim=-1)
            return self.fusion_layer(concat_feat)
        
        else:  # ç®€å•å¹³å‡
            return (domain_feat + system_feat + instance_feat) / 3


class E_03_ConditionalEncoder(nn.Module):
    """
    æ¡ä»¶ç¼–ç å™¨ - å±‚æ¬¡åŒ–æ¡ä»¶è¡¨ç¤ºå­¦ä¹ 
    
    æ”¯æŒçš„æ¡ä»¶ç±»å‹:
    - åŸŸæ¡ä»¶ (Domain): æ•°æ®é›†æ¥æº
    - ç³»ç»Ÿæ¡ä»¶ (System): è®¾å¤‡ç±»å‹  
    - å®ä¾‹æ¡ä»¶ (Instance): å…·ä½“æ ·æœ¬ç‰¹å¾
    """
    
    def __init__(self, args_m):
        super().__init__()
        
        # é…ç½®å‚æ•°
        self.embed_dim = getattr(args_m, 'condition_dim', 64)
        self.num_domains = getattr(args_m, 'num_domains', 10)
        self.num_systems = getattr(args_m, 'num_systems', 50)
        self.input_dim = getattr(args_m, 'input_dim', 128)
        self.fusion_type = getattr(args_m, 'fusion_type', 'attention')
        self.use_domain = getattr(args_m, 'use_domain', True)
        self.use_system = getattr(args_m, 'use_system', True)
        self.use_instance = getattr(args_m, 'use_instance', True)
        
        # å±‚æ¬¡ç¼–ç å™¨
        if self.use_domain:
            self.domain_encoder = DomainEncoder(
                self.num_domains, self.embed_dim
            )
            
        if self.use_system:
            self.system_encoder = SystemEncoder(
                self.num_systems, self.embed_dim
            )
            
        if self.use_instance:
            self.instance_encoder = InstanceEncoder(
                self.input_dim, self.embed_dim
            )
        
        # å±‚æ¬¡åŒ–èåˆ
        self.hierarchical_fusion = HierarchicalFusion(
            self.embed_dim, self.fusion_type
        )
        
        # æœ€ç»ˆæŠ•å½±å±‚
        self.output_proj = nn.Sequential(
            nn.Linear(self.embed_dim, self.embed_dim),
            nn.LayerNorm(self.embed_dim),
            nn.ReLU(),
            nn.Linear(self.embed_dim, self.embed_dim)
        )
    
    def forward(self, x: Optional[torch.Tensor] = None,
                domain_ids: Optional[torch.Tensor] = None,
                system_ids: Optional[torch.Tensor] = None,
                return_hierarchical: bool = False) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: å®ä¾‹ç‰¹å¾ (batch_size, input_dim)
            domain_ids: åŸŸID (batch_size,)
            system_ids: ç³»ç»ŸID (batch_size,)
            return_hierarchical: æ˜¯å¦è¿”å›å±‚æ¬¡åŒ–ç‰¹å¾
            
        Returns:
            condition_features: æ¡ä»¶ç‰¹å¾ (batch_size, embed_dim)
            æˆ– hierarchical_features: åŒ…å«æ‰€æœ‰å±‚æ¬¡ç‰¹å¾çš„å­—å…¸
        """
        batch_size = (x.size(0) if x is not None else 
                     domain_ids.size(0) if domain_ids is not None else
                     system_ids.size(0))
        device = (x.device if x is not None else
                 domain_ids.device if domain_ids is not None else
                 system_ids.device)
        
        # ç¼–ç å„ä¸ªå±‚æ¬¡çš„ç‰¹å¾
        features = {}
        
        # åŸŸç‰¹å¾
        if self.use_domain and domain_ids is not None:
            domain_feat = self.domain_encoder(domain_ids)
            features['domain'] = domain_feat
        else:
            domain_feat = torch.zeros(batch_size, self.embed_dim, device=device)
            features['domain'] = domain_feat
        
        # ç³»ç»Ÿç‰¹å¾
        if self.use_system and system_ids is not None:
            system_feat = self.system_encoder(system_ids)
            features['system'] = system_feat
        else:
            system_feat = torch.zeros(batch_size, self.embed_dim, device=device)
            features['system'] = system_feat
        
        # å®ä¾‹ç‰¹å¾
        if self.use_instance and x is not None:
            instance_feat = self.instance_encoder(x)
            features['instance'] = instance_feat
        else:
            instance_feat = torch.zeros(batch_size, self.embed_dim, device=device)
            features['instance'] = instance_feat
        
        # å±‚æ¬¡åŒ–èåˆ
        fused_features = self.hierarchical_fusion(
            domain_feat, system_feat, instance_feat
        )
        
        # æœ€ç»ˆæŠ•å½±
        condition_features = self.output_proj(fused_features)
        features['fused'] = condition_features
        
        if return_hierarchical:
            return features
        else:
            return condition_features
    
    def get_domain_prototype(self, domain_id: int) -> torch.Tensor:
        """è·å–åŸŸåŸå‹"""
        domain_tensor = torch.tensor([domain_id], device=next(self.parameters()).device)
        return self.domain_encoder(domain_tensor).squeeze(0)
    
    def get_system_prototype(self, system_id: int) -> torch.Tensor:
        """è·å–ç³»ç»ŸåŸå‹"""
        system_tensor = torch.tensor([system_id], device=next(self.parameters()).device)
        return self.system_encoder(system_tensor).squeeze(0)


# è‡ªæµ‹è¯•ä»£ç 
if __name__ == '__main__':
    """æ¡ä»¶ç¼–ç å™¨æµ‹è¯•"""
    print("=" * 60)
    print("ğŸ”¬ E_03_ConditionalEncoder æ¡ä»¶ç¼–ç å™¨æµ‹è¯•")
    print("=" * 60)
    
    # Mocké…ç½®
    class MockConfig:
        def __init__(self):
            self.condition_dim = 64
            self.num_domains = 5
            self.num_systems = 10  
            self.input_dim = 128
            self.fusion_type = 'attention'
            self.use_domain = True
            self.use_system = True
            self.use_instance = True
    
    config = MockConfig()
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # 1. æµ‹è¯•ç¼–ç å™¨åˆå§‹åŒ–
    print(f"\nğŸ—ï¸  1. æµ‹è¯•ç¼–ç å™¨åˆå§‹åŒ–...")
    encoder = E_03_ConditionalEncoder(config).to(device)
    total_params = sum(p.numel() for p in encoder.parameters())
    print(f"   âœ… ç¼–ç å™¨å‚æ•°æ€»æ•°: {total_params:,}")
    print(f"   âœ… æ¡ä»¶ç»´åº¦: {encoder.embed_dim}")
    print(f"   âœ… åŸŸæ•°é‡: {encoder.num_domains}")
    print(f"   âœ… ç³»ç»Ÿæ•°é‡: {encoder.num_systems}")
    print(f"   âœ… èåˆç±»å‹: {encoder.fusion_type}")
    
    # 2. æµ‹è¯•åŸºæœ¬å‰å‘ä¼ æ’­
    print(f"\nğŸ”„ 2. æµ‹è¯•åŸºæœ¬å‰å‘ä¼ æ’­...")
    batch_size = 16
    
    # å‡†å¤‡è¾“å…¥
    x = torch.randn(batch_size, config.input_dim, device=device)
    domain_ids = torch.randint(0, config.num_domains, (batch_size,), device=device)
    system_ids = torch.randint(0, config.num_systems, (batch_size,), device=device)
    
    # å‰å‘ä¼ æ’­
    condition_features = encoder(x, domain_ids, system_ids)
    
    print(f"   âœ… è¾“å…¥ç‰¹å¾å½¢çŠ¶: {x.shape}")
    print(f"   âœ… åŸŸIDå½¢çŠ¶: {domain_ids.shape}")
    print(f"   âœ… ç³»ç»ŸIDå½¢çŠ¶: {system_ids.shape}")
    print(f"   âœ… æ¡ä»¶ç‰¹å¾å½¢çŠ¶: {condition_features.shape}")
    
    assert condition_features.shape == (batch_size, config.condition_dim)
    print("   âœ… è¾“å‡ºå½¢çŠ¶æ£€æŸ¥é€šè¿‡")
    
    # 3. æµ‹è¯•å±‚æ¬¡åŒ–ç‰¹å¾è¿”å›
    print(f"\nğŸ—ï¸  3. æµ‹è¯•å±‚æ¬¡åŒ–ç‰¹å¾...")
    hierarchical_features = encoder(x, domain_ids, system_ids, return_hierarchical=True)
    
    print(f"   âœ… å±‚æ¬¡åŒ–ç‰¹å¾é”®: {list(hierarchical_features.keys())}")
    for key, feat in hierarchical_features.items():
        print(f"   âœ… {key}ç‰¹å¾å½¢çŠ¶: {feat.shape}")
    
    # 4. æµ‹è¯•ä¸åŒèåˆç±»å‹
    print(f"\nğŸ”§ 4. æµ‹è¯•ä¸åŒèåˆç±»å‹...")
    fusion_types = ['attention', 'gating', 'concatenate', 'average']
    
    for fusion_type in fusion_types:
        config.fusion_type = fusion_type
        encoder_test = E_03_ConditionalEncoder(config).to(device)
        
        with torch.no_grad():
            features = encoder_test(x, domain_ids, system_ids)
        
        print(f"   âœ… {fusion_type}èåˆ - è¾“å‡ºå½¢çŠ¶: {features.shape}")
        print(f"   âœ… {fusion_type}èåˆ - ç»Ÿè®¡: å‡å€¼={features.mean().item():.4f}, æ ‡å‡†å·®={features.std().item():.4f}")
    
    # æ¢å¤é»˜è®¤é…ç½®
    config.fusion_type = 'attention'
    encoder = E_03_ConditionalEncoder(config).to(device)
    
    # 5. æµ‹è¯•éƒ¨åˆ†æ¡ä»¶è¾“å…¥
    print(f"\nğŸ§© 5. æµ‹è¯•éƒ¨åˆ†æ¡ä»¶è¾“å…¥...")
    
    # åªæœ‰åŸŸID
    domain_only = encoder(domain_ids=domain_ids)
    print(f"   âœ… ä»…åŸŸæ¡ä»¶å½¢çŠ¶: {domain_only.shape}")
    
    # åªæœ‰ç³»ç»ŸID
    system_only = encoder(system_ids=system_ids)
    print(f"   âœ… ä»…ç³»ç»Ÿæ¡ä»¶å½¢çŠ¶: {system_only.shape}")
    
    # åªæœ‰å®ä¾‹ç‰¹å¾
    instance_only = encoder(x=x)
    print(f"   âœ… ä»…å®ä¾‹ç‰¹å¾å½¢çŠ¶: {instance_only.shape}")
    
    # åŸŸ+ç³»ç»Ÿ
    domain_system = encoder(domain_ids=domain_ids, system_ids=system_ids)
    print(f"   âœ… åŸŸ+ç³»ç»Ÿæ¡ä»¶å½¢çŠ¶: {domain_system.shape}")
    
    # 6. æµ‹è¯•åŸå‹è·å–
    print(f"\nğŸ¯ 6. æµ‹è¯•åŸå‹è·å–...")
    
    # è·å–åŸŸåŸå‹
    domain_prototype = encoder.get_domain_prototype(0)
    print(f"   âœ… åŸŸ0åŸå‹å½¢çŠ¶: {domain_prototype.shape}")
    
    system_prototype = encoder.get_system_prototype(0)
    print(f"   âœ… ç³»ç»Ÿ0åŸå‹å½¢çŠ¶: {system_prototype.shape}")
    
    # éªŒè¯ä¸åŒåŸŸ/ç³»ç»Ÿçš„åŸå‹ç¡®å®ä¸åŒ
    domain_proto_1 = encoder.get_domain_prototype(1)
    domain_similarity = F.cosine_similarity(domain_prototype, domain_proto_1, dim=0)
    print(f"   âœ… åŸŸ0ä¸åŸŸ1ç›¸ä¼¼åº¦: {domain_similarity.item():.4f}")
    
    # 7. æµ‹è¯•æ¢¯åº¦è®¡ç®—
    print(f"\nğŸ“ˆ 7. æµ‹è¯•æ¢¯åº¦è®¡ç®—...")
    encoder.train()
    
    # è®¡ç®—æŸå¤± (ç®€å•çš„L2æŸå¤±)
    features = encoder(x, domain_ids, system_ids)
    loss = features.pow(2).mean()
    
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    grad_norms = []
    for name, param in encoder.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            grad_norms.append(grad_norm)
    
    avg_grad_norm = sum(grad_norms) / len(grad_norms)
    print(f"   âœ… å¹³å‡æ¢¯åº¦èŒƒæ•°: {avg_grad_norm:.6f}")
    print(f"   âœ… æœ‰æ¢¯åº¦å‚æ•°æ•°: {len(grad_norms)}/{len(list(encoder.parameters()))}")
    
    # 8. æµ‹è¯•æ‰¹é‡å¤§å°å˜åŒ–
    print(f"\nğŸ“ 8. æµ‹è¯•ä¸åŒæ‰¹é‡å¤§å°...")
    
    for bs in [1, 4, 32, 64]:
        x_test = torch.randn(bs, config.input_dim, device=device)
        domain_test = torch.randint(0, config.num_domains, (bs,), device=device)
        system_test = torch.randint(0, config.num_systems, (bs,), device=device)
        
        with torch.no_grad():
            features_test = encoder(x_test, domain_test, system_test)
        
        print(f"   âœ… æ‰¹é‡å¤§å°{bs} - è¾“å‡ºå½¢çŠ¶: {features_test.shape}")
    
    # 9. æµ‹è¯•æ¡ä»¶ç‰¹å¾åŒºåˆ†åº¦
    print(f"\nğŸ” 9. æµ‹è¯•æ¡ä»¶ç‰¹å¾åŒºåˆ†åº¦...")
    
    # ç›¸åŒæ¡ä»¶åº”è¯¥äº§ç”Ÿç›¸ä¼¼ç‰¹å¾
    x_same = torch.randn(2, config.input_dim, device=device)
    domain_same = torch.tensor([0, 0], device=device)
    system_same = torch.tensor([0, 0], device=device)
    
    with torch.no_grad():
        features_same = encoder(x_same, domain_same, system_same)
        similarity_same = F.cosine_similarity(features_same[0], features_same[1], dim=0)
    
    # ä¸åŒæ¡ä»¶åº”è¯¥äº§ç”Ÿä¸åŒç‰¹å¾
    domain_diff = torch.tensor([0, 1], device=device)
    system_diff = torch.tensor([0, 1], device=device)
    
    with torch.no_grad():
        features_diff = encoder(x_same, domain_diff, system_diff)
        similarity_diff = F.cosine_similarity(features_diff[0], features_diff[1], dim=0)
    
    print(f"   âœ… ç›¸åŒæ¡ä»¶ç‰¹å¾ç›¸ä¼¼åº¦: {similarity_same.item():.4f}")
    print(f"   âœ… ä¸åŒæ¡ä»¶ç‰¹å¾ç›¸ä¼¼åº¦: {similarity_diff.item():.4f}")
    
    # 10. æ€§èƒ½åŸºå‡†æµ‹è¯•
    print(f"\nâš¡ 10. æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    encoder.eval()
    
    import time
    
    # ç¼–ç æ€§èƒ½
    start_time = time.time()
    with torch.no_grad():
        for _ in range(100):
            features = encoder(x, domain_ids, system_ids)
    
    encode_time = time.time() - start_time
    print(f"   âœ… ç¼–ç 100æ¬¡æ—¶é—´: {encode_time:.3f}ç§’ ({100/encode_time:.1f} encode/s)")
    
    # å¤§æ‰¹é‡æ€§èƒ½
    large_batch = 128
    x_large = torch.randn(large_batch, config.input_dim, device=device)
    domain_large = torch.randint(0, config.num_domains, (large_batch,), device=device)
    system_large = torch.randint(0, config.num_systems, (large_batch,), device=device)
    
    start_time = time.time()
    with torch.no_grad():
        features_large = encoder(x_large, domain_large, system_large)
    
    large_encode_time = time.time() - start_time
    print(f"   âœ… å¤§æ‰¹é‡({large_batch})ç¼–ç æ—¶é—´: {large_encode_time:.3f}ç§’")
    
    print(f"\n" + "=" * 60)
    print("ğŸ‰ E_03_ConditionalEncoder æ¡ä»¶ç¼–ç å™¨æµ‹è¯•å®Œæˆ!")
    print("âœ… æ‰€æœ‰å±‚æ¬¡åŒ–ç¼–ç åŠŸèƒ½æ­£å¸¸")
    print("ğŸ“Š æ¡ä»¶ç‰¹å¾å…·æœ‰è‰¯å¥½çš„åŒºåˆ†åº¦")
    print("âš¡ æ€§èƒ½æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚")
    print("ğŸš€ å¯ä»¥é›†æˆåˆ°ç”Ÿæˆæ¨¡å‹ä¸­")
    print("=" * 60)
```

---

## ğŸ”„ å¼€å‘æµç¨‹è¯´æ˜

### TDD (Test-Driven Development) æ–¹æ³•

æ¯ä¸ªæ¨¡å—éƒ½åŒ…å«å®Œæ•´çš„è‡ªæµ‹è¯•ä»£ç ï¼Œéµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **å…ˆæµ‹è¯•ï¼Œåå®ç°**ï¼šæµ‹è¯•ç”¨ä¾‹å®šä¹‰äº†æœŸæœ›çš„è¡Œä¸º
2. **å…¨é¢è¦†ç›–**ï¼šæµ‹è¯•è¦†ç›–æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½å’Œè¾¹ç•Œæƒ…å†µ
3. **è‡ªåŒ…å«**ï¼šæ¯ä¸ªæ¨¡å—å¯ç‹¬ç«‹è¿è¡Œæµ‹è¯•
4. **æ€§èƒ½éªŒè¯**ï¼šåŒ…å«æ€§èƒ½åŸºå‡†å’Œç¨³å®šæ€§æµ‹è¯•
5. **æ–‡æ¡£åŒ–**ï¼šæµ‹è¯•æœ¬èº«å°±æ˜¯æœ€å¥½çš„ä½¿ç”¨æ–‡æ¡£

### æ¨¡å—é—´é›†æˆç­–ç•¥

```python
# GM_01_RectifiedFlow ä¸ E_03_ConditionalEncoder é›†æˆç¤ºä¾‹
encoder = E_03_ConditionalEncoder(config)
flow_model = GM_01_RectifiedFlow(config)

# 1. ç¼–ç æ¡ä»¶
condition = encoder(x, domain_ids, system_ids)

# 2. ç”Ÿæˆæ ·æœ¬
samples = flow_model.sample(
    batch_size=32,
    condition=condition,
    num_steps=50
)

# 3. è®­ç»ƒå¾ªç¯
for batch in dataloader:
    x, domain_ids, system_ids = batch
    
    # ç¼–ç æ¡ä»¶
    condition = encoder(x, domain_ids, system_ids)
    
    # å‰å‘ä¼ æ’­
    outputs = flow_model(x, condition)
    
    # æŸå¤±è®¡ç®—
    losses = flow_model.compute_loss(outputs)
    
    # åå‘ä¼ æ’­
    losses['total_loss'].backward()
```

---

## ğŸ“ˆ ä¸‹ä¸€æ­¥å®æ–½

### ç¬¬äºŒå‘¨è®¡åˆ’

1. **M_04_ISFM_GM.py** - ä¸»ç”Ÿæˆæ¨¡å‹æ•´åˆ
2. **flow_loss.py** - æŸå¤±å‡½æ•°å®ç°
3. **pretrain_flow_task.py** - è®­ç»ƒä»»åŠ¡å°è£…

### é›†æˆè¦ç‚¹

- **ä¿æŒå·¥å‚æ¨¡å¼å…¼å®¹æ€§**ï¼šæ‰€æœ‰æ–°æ¨¡å—éƒ½è¦æ³¨å†Œåˆ°ç›¸åº”å·¥å‚
- **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡YAMLé…ç½®æ–‡ä»¶æ§åˆ¶æ‰€æœ‰è¶…å‚æ•°
- **æµ‹è¯•ä¼˜å…ˆ**ï¼šæ¯ä¸ªæ–°åŠŸèƒ½éƒ½è¦æœ‰å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹
- **æ€§èƒ½ç›‘æ§**ï¼šè·Ÿè¸ªè®­ç»ƒå’Œæ¨ç†æ€§èƒ½æŒ‡æ ‡

---

è¿™ä¸ªä¼˜åŒ–è®¡åˆ’ä¸“æ³¨äºç”Ÿæˆæ¨¡å‹çš„æŠ€æœ¯å®ç°ï¼Œæ¯ä¸ªæ¨¡å—éƒ½åŒ…å«å®Œæ•´çš„è‡ªæµ‹è¯•ä»£ç ï¼Œä¸ºå¿«é€Ÿè¿­ä»£å’Œå¯é éƒ¨ç½²å¥ å®šäº†åŸºç¡€ã€‚