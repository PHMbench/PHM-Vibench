# Multi-Task PHM Foundation Model Configuration - Quick Test (1 Epoch)
# Based on B_04_Dlinear (fastest model) for validation testing
# Author: PHM-Vibench Team
# Date: 2025-09-09

environment:
  VBENCH_HOME: "/home/lq/LQcode/2_project/PHMBench/Vbench"
  PYTHONPATH: "/home/lq/.conda/envs/lq"
  PHMBench: "/home/lq/LQcode/2_project/PHMBench"
  project: "MultiTask_Foundation_Model"
  seed: 42
  output_dir: "results/multitask_test_1epoch"
  iterations: 1  # Test mode: single iteration
  wandb: dryrun  # Test mode: dryrun (no upload)
  swanlab: False  # Test mode: disabled
  notes: 'Multi-task foundation model - QUICK TEST (1 epoch validation)'
  workspace: 'PHMbench'

# Data Configuration
data:
  data_dir: "/gpfs/gibbs/project/lu_lu/ql334/PHM-Vibench/data"
  metadata_file: "metadata_6_11.xlsx"
  batch_size: 16     # Small batch for quick test
  num_workers: 8     # Reduced workers for test
  window_size: 4096
  stride: 4
  truncate_length: 200
  num_window: 4      # Minimal windows for test
  normalization: 'standardization'
  dtype: float32
  window_sampling_strategy: 'evenly_spaced'
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  
  # RUL-specific dataset configuration
  rul_dataset_id: 2  # XJTU bearing dataset for RUL

# Model Configuration
model:
  name: "M_01_ISFM"
  type: "ISFM"
  input_dim: 2
  
  # Architecture components
  embedding: E_01_HSE
  backbone: B_04_Dlinear  # Dlinear backbone - fastest for testing
  task_head: MultiTaskHead  # Enhanced multi-task head with signal prediction
  
  # Model dimensions - MINIMAL for fast testing
  num_patches: 32    # Reduced from 128 to 32
  patch_size_L: 64   # Reduced from 256 to 64
  patch_size_C: 1
  output_dim: 128    # Reduced from 1024 to 128
  num_heads: 2       # Reduced from 8 to 2
  num_layers: 1      # Reduced from 3 to 1
  d_ff: 256          # Reduced from 2048 to 256
  dropout: 0.1
  
  # Multi-task head configuration
  classification_head: H_02_distance_cla
  prediction_head: H_03_Linear_pred
  hidden_dim: 32     # Minimal hidden dimension
  activation: "gelu"
  rul_max_value: 2000.0
  use_batch_norm: true
  
  # H_03_Linear_pred parameters for signal prediction - MINIMAL
  max_len: 4096
  max_out: 2         # Reduced from 3 to 2 for memory
  act: "gelu"

# Task Configuration
task:
  name: "multi_task_phm"
  type: "In_distribution"
  
  # Enabled tasks
  enabled_tasks: 
    - 'classification'       # Fault diagnosis
    - 'anomaly_detection'   # Anomaly detection  
    - 'signal_prediction'   # Signal prediction
    - 'rul_prediction'      # RUL prediction
  
  # Task weights for loss balancing
  task_weights:
    classification: 1.0
    anomaly_detection: 0.6
    signal_prediction: 0.7
    rul_prediction: 0.8
  
  # Task-specific configurations
  classification:
    loss: "CE"  # Cross-entropy loss
    num_classes: auto  # Auto-determined from dataset
    label_smoothing: 0.1
    loss_weight: 1.0
  
  anomaly_detection:
    loss: "BCE"  # Binary cross-entropy loss
    threshold: 0.5
    class_weights: [1.0, 2.0]  # [normal, anomaly]
    loss_weight: 0.6
  
  signal_prediction:
    loss: "MSE"  # Mean squared error loss
    pred_len: 96  # Predict 96 timesteps
    use_mean_pooling: false  # Key: don't use mean pooling
    loss_weight: 0.7
  
  rul_prediction:
    loss: "MSE"  # Mean squared error loss
    max_rul_value: 2000.0
    normalize_targets: true
    dataset_id: 2  # XJTU dataset
    loss_weight: 0.8
  
  # Target systems for evaluation - SINGLE SYSTEM for quick test
  target_system_id: [2]  # Only test system 2
  
  # Optimization parameters
  optimizer: "adamw"
  lr: 0.001          # Slightly higher LR for faster test
  weight_decay: 0.01
  momentum: 0.9  # For SGD if needed
  
  # Learning rate scheduling
  scheduler:
    name: "cosine"
    options:
      T_max: 1         # Only 1 epoch
      eta_min: 1e-6

# Trainer Configuration
trainer:
  name: "Default_trainer"
  num_epochs: 1        # QUICK TEST: Only 1 epoch
  gpus: 1
  precision: 16        # Mixed precision for speed
  accumulate_grad_batches: 1  # No accumulation for test
  gradient_clip_val: 1.0
  
  # Early stopping (disabled for test mode)
  early_stopping: false  # Test mode: disabled
  patience: 25
  monitor: "val_loss"
  
  # Model checkpointing
  save_top_k: 1        # Only save best
  save_last: false     # Don't save last for test
  
  # Logging
  log_every_n_steps: 10  # More frequent logging for test
  
  # Device configuration
  device: 'cuda'
  
  # Validation
  val_check_interval: 1.0
  check_val_every_n_epoch: 1

# Evaluation Configuration
evaluation:
  # Metrics to compute during evaluation
  compute_metrics:
    - "accuracy"      # For classification
    - "f1_score"      # For classification & anomaly detection
    - "precision"     # For classification & anomaly detection  
    - "recall"        # For classification & anomaly detection
    - "roc_auc"       # For anomaly detection
    - "mse"           # For RUL & signal prediction
    - "mae"           # For RUL & signal prediction
    - "r2_score"      # For RUL & signal prediction
  
  # Test after training
  test_after_training: true

# Reproducibility
reproducibility:
  deterministic: true
  benchmark: false
  seed_everything: true

# Advanced Configuration (Test Mode)
advanced:
  effective_batch_size: 64   # Small for testing
  use_amp: true              # Mixed precision
  compile_model: false
  memory_efficient: true
  profiler: null             # No profiling in test mode