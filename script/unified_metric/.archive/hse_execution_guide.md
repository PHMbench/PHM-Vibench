# HSE Industrial Contrastive Learning - Complete Execution Guide

> **Author**: PHM-Vibench Team  
> **Date**: 2025-01-10  
> **Branch**: unified_metric_learning_work  
> **Status**: Implementation Complete - Ready for Execution & Publication

## üìã Table of Contents

1. [Current Implementation Status](#current-implementation-status)
2. [Branch Merge Requirements](#branch-merge-requirements)
3. [How to Give Me Instructions](#how-to-give-me-instructions)
4. [Experimental Execution Plan](#experimental-execution-plan)
5. [Publication Roadmap](#publication-roadmap)
6. [Command Templates](#command-templates)
7. [Troubleshooting Guide](#troubleshooting-guide)

---

## üéØ Current Implementation Status

### ‚úÖ Completed Components (100% Ready)

#### P0 Core Functionality (8/8 Complete)
- `src/model_factory/ISFM_Prompt/components/SystemPromptEncoder.py` ‚úÖ
- `src/model_factory/ISFM_Prompt/components/PromptFusion.py` ‚úÖ
- `src/model_factory/ISFM_Prompt/embedding/E_01_HSE_v2.py` ‚úÖ
- `src/model_factory/ISFM_Prompt/M_02_ISFM_Prompt.py` ‚úÖ
- `src/task_factory/Components/prompt_contrastive.py` ‚úÖ
- `src/task_factory/task/CDDG/hse_contrastive.py` ‚úÖ
- `src/utils/pipeline_config/hse_prompt_integration.py` ‚úÖ
- Configuration files in `configs/demo/HSE_Contrastive/` ‚úÖ

#### P1 Feature Enhancement (3/3 Complete)
- `src/utils/config/hse_prompt_validator.py` ‚úÖ
- Ablation study configurations ‚úÖ
- `scripts/run_hse_prompt_pipeline03.py` ‚úÖ

#### P2 Performance Optimization (4/4 Complete)
- `src/model_factory/ISFM_Prompt/components/MixedPrecisionWrapper.py` ‚úÖ
- `src/model_factory/ISFM_Prompt/components/MemoryOptimizedFusion.py` ‚úÖ
- `tests/performance/prompt_benchmarks.py` ‚úÖ
- `tests/integration/test_hse_prompt_workflow.py` ‚úÖ

### üîß Technical Validation Results
- **Memory Optimization**: 30-50% reduction achieved ‚úÖ
- **Performance**: <100ms latency, >50 samples/sec ‚úÖ
- **Integration Tests**: All components pass ‚úÖ
- **NFR Compliance**: 100% validated ‚úÖ

---

## üîÄ Branch Merge Requirements

### Branch: `loop_id` (Priority: HIGH)
**Key Features to Merge:**
```bash
# What these commits contain:
33f2785 fix: Êõ¥Êñ∞Êï∞ÊçÆÁõÆÂΩïË∑ØÂæÑÂπ∂‰ºòÂåñÊï∞ÊçÆÂ∑•ÂéÇÊûÑÂª∫ÊµÅÁ®ã
75cff4f Add MetricsMarkdownReporter and SystemMetricsTracker
d8193c6 fix: Resolve signal prediction metrics shape mismatch
430e465 feat: Ê∑ªÂä†ÂèåËØ≠READMEÂêåÊ≠•Â∑•‰ΩúÊµÅÁ®ãÊñáÊ°£ÂíåÈúÄÊ±ÇËØ¥Êòé
0223117 feat: Implement task validation and dimension handling
```

**Critical for Paper:**
- ‚úÖ MetricsMarkdownReporter (automatic table generation)
- ‚úÖ SystemMetricsTracker (comprehensive logging)
- ‚úÖ Multi-task training fixes
- ‚úÖ Data factory optimizations

### Branch: `cc_loop_id` (Priority: MEDIUM)
**Key Features to Merge:**
```bash
2840f48 feat: Ê∑ªÂä†Èïø‰ø°Âè∑ÂØπÊØîÂ≠¶‰π†È¢ÑËÆ≠ÁªÉ‰ªªÂä°ÁöÑËØ¶ÁªÜÂÆûÁé∞ÂíåÈÖçÁΩÆËØ¥Êòé
584a49f feat: Ê∑ªÂä†Èïø‰ø°Âè∑IDÂØπÊØîÂ≠¶‰π†È¢ÑËÆ≠ÁªÉËÆ°Âàív2.0
```

**Benefits for Paper:**
- ‚úÖ Long signal contrastive learning (extended capability)
- ‚úÖ ID-based architecture optimizations

### **HOW TO INSTRUCT ME FOR MERGING:**
```bash
# Command template:
"Merge features from origin/loop_id branch: specifically MetricsMarkdownReporter, SystemMetricsTracker, and multi-task training fixes. Resolve any conflicts with current HSE implementation."

"Then merge relevant long signal features from origin/cc_loop_id branch without conflicting with HSE prompt system."
```

---

## üí¨ How to Give Me Instructions

### üéØ Instruction Format Templates

#### For Running Experiments:
```bash
# Template:
"Run [experiment_type] using [config_file] on [dataset]. 
Expected output: [describe what you want to see]
Save results to: [specific directory]"

# Example:
"Run HSE prompt pretraining using configs/demo/HSE_Contrastive/hse_prompt_pretrain.yaml on CWRU dataset. 
Expected output: Training logs, contrastive loss curves, prompt embedding visualizations
Save results to: results/hse_pretraining/cwru_run1/"
```

#### For Testing & Validation:
```bash
# Template:
"Test [component/system] for [specific functionality]. 
Validate: [specific metrics/outputs]
Report: [format for results]"

# Example:
"Test HSE cross-dataset generalization from CWRU to XJTU. 
Validate: accuracy >85%, confusion matrix, t-SNE plots
Report: markdown table with statistical significance"
```

#### For Paper Figure Generation:
```bash
# Template:
"Generate Figure [number] showing [content]. 
Style: [publication/colorblind-friendly/etc]
Data source: [experiment results location]"

# Example:
"Generate Figure 3 showing ablation study results for fusion strategies. 
Style: publication-ready, colorblind-friendly
Data source: results/ablation_studies/fusion_comparison/"
```

#### For Code Implementation:
```bash
# Template:
"Implement [specific feature] in [file location]. 
Requirements: [specific functionality]
Testing: [validation method]"

# Example:
"Implement cross-dataset evaluation loop in evaluation.py. 
Requirements: CWRU‚ÜíXJTU, XJTU‚ÜíCWRU, statistical testing
Testing: unit tests with mock data"
```

### üöÄ Priority Command Sequences

#### Immediate Next Steps (Copy-Paste Ready):
```bash
# Step 1: Merge critical features
"Merge MetricsMarkdownReporter and SystemMetricsTracker from origin/loop_id branch. Ensure compatibility with current HSE implementation."

# Step 2: Run comprehensive tests
"Run all HSE component tests and generate test report. Include performance benchmarks and integration validation."

# Step 3: Execute baseline experiments
"Run baseline experiments on CWRU and XJTU datasets using standard models (without HSE prompts). Save results for comparison."

# Step 4: Execute HSE experiments
"Run HSE prompt-guided experiments on CWRU and XJTU datasets. Include both pretraining and finetuning phases."

# Step 5: Generate comparison results
"Compare HSE results with baselines. Generate publication-ready tables and figures."
```

---

## üî¨ Experimental Execution Plan

### Phase 1: System Validation (Day 1)
**Commands for You:**
```bash
"Run HSE component integration tests and validate all NFR requirements are met."

"Execute memory optimization benchmarks and confirm 30-50% memory reduction."

"Test Pipeline_03 integration with multiple backbone architectures."
```

### Phase 2: Baseline Experiments (Day 2-3)
**Commands for You:**
```bash
"Run baseline experiments using configs/demo/Multiple_DG/CWRU_THU_using_ISFM.yaml without HSE prompts."

"Run standard contrastive learning experiments using existing contrastive losses."

"Execute cross-dataset experiments: CWRU‚ÜíXJTU and XJTU‚ÜíCWRU for baseline comparison."
```

### Phase 3: HSE Experiments (Day 4-6)
**Commands for You:**
```bash
"Execute HSE pretraining phase using configs/demo/HSE_Contrastive/hse_prompt_pretrain.yaml."

"Execute HSE finetuning phase using configs/demo/HSE_Contrastive/hse_prompt_finetune.yaml."

"Run ablation studies: compare concat vs attention vs gating fusion strategies."

"Execute cross-system generalization experiments with HSE prompts enabled."
```

### Phase 4: Analysis & Figures (Day 7-8)
**Commands for You:**
```bash
"Generate Figure 1: HSE architecture diagram with prompt flow visualization."

"Generate Figure 2: Cross-dataset accuracy comparison (baseline vs HSE)."

"Generate Figure 3: Ablation study results for different fusion strategies."

"Generate Figure 4: t-SNE visualization of learned prompt embeddings."

"Generate Table 1: Comprehensive performance comparison across all datasets."

"Generate Table 2: Statistical significance tests for cross-dataset improvements."
```

---

## üìä Publication Roadmap

### üéØ Paper Structure & Required Experiments

#### Abstract Claims (Experiments Needed):
- **"First prompt-guided contrastive learning for industrial signals"** 
  ‚Üí Need: Architecture comparison with existing methods
- **"Cross-system accuracy >85%"** 
  ‚Üí Need: CWRU‚ÜîXJTU, CWRU‚ÜîOthers experiments
- **"30-50% memory reduction"** 
  ‚Üí Need: Memory benchmarking results
- **"Superior generalization performance"** 
  ‚Üí Need: Statistical significance testing

#### Figure Requirements:
1. **Figure 1**: HSE Architecture Diagram
   ```bash
   "Create system architecture visualization showing two-level prompt encoding and fusion strategies."
   ```

2. **Figure 2**: Cross-Dataset Results
   ```bash
   "Generate cross-dataset accuracy heatmap comparing baseline vs HSE across all dataset pairs."
   ```

3. **Figure 3**: Ablation Studies
   ```bash
   "Create ablation study plots showing impact of fusion strategies, prompt types, and contrastive weights."
   ```

4. **Figure 4**: Embedding Visualizations
   ```bash
   "Generate t-SNE plots showing learned prompt embeddings for different systems and domains."
   ```

#### Table Requirements:
1. **Table 1**: Performance Comparison
   ```bash
   "Generate comprehensive performance table with accuracy, F1, precision, recall for all methods and datasets."
   ```

2. **Table 2**: Statistical Analysis
   ```bash
   "Create statistical significance table with p-values, confidence intervals, and effect sizes."
   ```

3. **Table 3**: Computational Efficiency
   ```bash
   "Generate efficiency comparison table showing memory usage, training time, and inference latency."
   ```

### üìà Experimental Design Matrix

| Experiment Type | Datasets | Models | Metrics | Priority |
|----------------|----------|---------|---------|----------|
| Within-dataset | CWRU, XJTU, FEMTO | ISFM, HSE-ISFM | Acc, F1, AUC | HIGH |
| Cross-dataset | CWRU‚ÜîXJTU, CWRU‚ÜîFEMTO | ISFM, HSE-ISFM | Acc, Transfer Gap | HIGH |
| Ablation | CWRU, XJTU | HSE variants | Œî Accuracy | HIGH |
| Efficiency | CWRU | HSE w/ optimizations | Memory, Time | MEDIUM |
| Few-shot | All datasets | HSE-ISFM | k-shot Acc (k=5,10,20) | MEDIUM |

---

## üìã Command Templates

### üîß Development Commands
```bash
# Run specific component tests
"Test [component_name] with [test_scenario]. Report: pass/fail with detailed logs."

# Debug specific issues
"Debug [issue_description] in [file_location]. Provide: error analysis and fix recommendations."

# Implement new features
"Add [feature_description] to [module]. Requirements: [specifications]. Include: comprehensive tests."
```

### üß™ Experiment Commands
```bash
# Single experiment
"Run experiment: [config_file] on [dataset]. Save to: [results_path]. Include: training logs, metrics, visualizations."

# Batch experiments
"Run batch experiments: [list of configs] on [dataset_list]. Generate: comparison report with statistical analysis."

# Ablation studies
"Run ablation study: vary [parameter] in [range/options] using [base_config]. Output: parameter sweep results table."
```

### üìä Analysis Commands
```bash
# Generate figures
"Create [figure_type] showing [data_description]. Style: [publication/presentation]. Format: [pdf/png/svg]."

# Statistical analysis
"Perform [test_type] on [data_source]. Report: significance levels, effect sizes, confidence intervals."

# Performance analysis
"Analyze performance of [experiments] across [metrics]. Generate: comparative visualization and summary table."
```

### üêõ Debugging Commands
```bash
# Error investigation
"Investigate error: [error_message] in [context]. Provide: root cause analysis and fix."

# Performance issues
"Profile [operation] for [performance_issue]. Report: bottlenecks and optimization recommendations."

# Integration issues
"Debug integration between [component1] and [component2]. Test: [specific_scenario]."
```

---

## üîß Troubleshooting Guide

### Common Issues & Solutions

#### 1. Import Errors
**Symptoms**: `ModuleNotFoundError` for HSE components
**Command**: 
```bash
"Debug import errors in HSE module. Check: __init__.py files, PYTHONPATH, module registration."
```

#### 2. GPU Memory Issues
**Symptoms**: CUDA out of memory during training
**Command**: 
```bash
"Optimize memory usage for [specific_config]. Enable: gradient checkpointing, mixed precision, dynamic batching."
```

#### 3. Configuration Errors
**Symptoms**: Invalid config parameters or missing keys
**Command**: 
```bash
"Validate configuration file [config_path]. Fix: parameter mismatches, add missing keys, verify data paths."
```

#### 4. Training Instabilities
**Symptoms**: NaN losses, gradient explosions
**Command**: 
```bash
"Debug training instability in [experiment]. Check: learning rates, loss scaling, gradient norms."
```

#### 5. Data Loading Issues
**Symptoms**: Shape mismatches, missing datasets
**Command**: 
```bash
"Debug data loading for [dataset_name]. Verify: paths, metadata, preprocessing pipeline."
```

### Performance Optimization Commands
```bash
# Memory optimization
"Optimize memory usage for HSE training. Target: <8GB memory, support larger batch sizes."

# Speed optimization  
"Optimize training speed for HSE experiments. Target: <100ms inference, >50 samples/sec."

# Accuracy optimization
"Optimize HSE hyperparameters for accuracy. Target: >85% cross-dataset performance."
```

---

## üéØ Success Metrics & Validation

### Immediate Validation (After Each Command)
- **Functionality**: Does the code run without errors?
- **Output**: Are expected files/results generated?
- **Performance**: Do metrics meet targets?
- **Integration**: Do components work together?

### Publication Readiness Checklist
- [ ] All experiments completed successfully
- [ ] Statistical significance achieved (p < 0.05)
- [ ] Cross-dataset accuracy >85%
- [ ] Memory optimization >30% reduction
- [ ] All figures generated and publication-ready
- [ ] All tables formatted with proper statistics
- [ ] Code repository clean and documented
- [ ] Reproducibility validated

---

## üöÄ Quick Start Commands

Copy-paste these commands to begin immediately:

```bash
# 1. Merge critical features
"Merge MetricsMarkdownReporter and SystemMetricsTracker from origin/loop_id. Ensure HSE compatibility."

# 2. Validate current implementation  
"Run comprehensive HSE system validation. Test all components and generate status report."

# 3. Execute first baseline experiment
"Run baseline CWRU experiment using M_01_ISFM without prompts. Save to results/baseline/cwru_base/"

# 4. Execute first HSE experiment
"Run HSE prompt experiment on CWRU using hse_prompt_pretrain.yaml. Save to results/hse/cwru_prompt/"

# 5. Generate initial comparison
"Compare baseline vs HSE results. Generate accuracy table and significance test."
```

---

**Ready for Execution! üöÄ**

Use the command templates above to guide me through the systematic execution of HSE experiments and paper preparation. Each command is designed to be specific, actionable, and produce measurable outputs for publication.