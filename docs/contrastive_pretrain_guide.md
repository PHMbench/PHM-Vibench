# ContrastiveID Pretraining Guide

PHM-Vibenchå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒä»»åŠ¡å®Œæ•´ä½¿ç”¨æŒ‡å—ã€‚åŸºäºé•¿ä¿¡å·IDå¯¹æ¯”å­¦ä¹ ï¼Œé€‚ç”¨äºå·¥ä¸šè®¾å¤‡æŒ¯åŠ¨ä¿¡å·åˆ†æçš„è‡ªç›‘ç£é¢„è®­ç»ƒã€‚

## ç›®å½•
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [é…ç½®å‚æ•°è¯¦è§£](#é…ç½®å‚æ•°è¯¦è§£)
- [å®éªŒå·¥ä½œæµ](#å®éªŒå·¥ä½œæµ)
- [é›†æˆæŒ‡å—](#é›†æˆæŒ‡å—)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [é«˜çº§ç”¨æ³•](#é«˜çº§ç”¨æ³•)
- [APIå‚è€ƒ](#apiå‚è€ƒ)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬æ¦‚å¿µ

ContrastiveIDTaskæ˜¯åŸºäºInfoNCEæŸå¤±çš„å¯¹æ¯”å­¦ä¹ ä»»åŠ¡ï¼Œé€šè¿‡å¤šçª—å£é‡‡æ ·æœºåˆ¶ä»åŒä¸€IDä¿¡å·ä¸­ç”Ÿæˆæ­£æ ·æœ¬å¯¹ï¼Œå­¦ä¹ å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„ä¿¡å·è¡¨å¾ã€‚

æ ¸å¿ƒæ€æƒ³ï¼š
- **æ­£æ ·æœ¬å¯¹**: åŒä¸€IDä¿¡å·çš„ä¸åŒçª—å£
- **è´Ÿæ ·æœ¬**: æ‰¹æ¬¡ä¸­å…¶ä»–æ ·æœ¬çš„çª—å£
- **å­¦ä¹ ç›®æ ‡**: æœ€å¤§åŒ–æ­£æ ·æœ¬å¯¹ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦

### 1. è°ƒè¯•æ¨¡å¼ - å¿«é€ŸéªŒè¯

å¼€å‘å’Œè°ƒè¯•æ—¶ä½¿ç”¨å°è§„æ¨¡é…ç½®ï¼Œæœ€å°èµ„æºå ç”¨ï¼š

```bash
# CPUè°ƒè¯•æ¨¡å¼ - å•epochå¿«é€ŸéªŒè¯
python main.py --config configs/id_contrastive/debug.yaml
```

**è°ƒè¯•é…ç½®ç‰¹ç‚¹**:
- ä½¿ç”¨CPUï¼Œå•çº¿ç¨‹æ•°æ®åŠ è½½
- å°æ‰¹é‡(4)å’Œå°çª—å£(256)
- å•epochè®­ç»ƒï¼Œè¯¦ç»†æ—¥å¿—
- æœ€å°æ¨¡å‹ç»´åº¦(64)

### 2. ç”Ÿäº§ç¯å¢ƒ - å®Œæ•´è®­ç»ƒ

æ­£å¼å®éªŒä½¿ç”¨GPUä¼˜åŒ–é…ç½®ï¼š

```bash
# GPUç”Ÿäº§æ¨¡å¼ - å®Œæ•´è®­ç»ƒ
python main.py --config configs/id_contrastive/production.yaml
```

**ç”Ÿäº§é…ç½®ç‰¹ç‚¹**:
- GPU + æ··åˆç²¾åº¦è®­ç»ƒ
- å¤§æ‰¹é‡(64)å’Œå¤§çª—å£(2048)
- 100ä¸ªepochï¼Œä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
- æ—©åœå’Œæ£€æŸ¥ç‚¹ä¿å­˜

### 3. æ¶ˆèå®éªŒ - å‚æ•°ç ”ç©¶

ç³»ç»Ÿæ€§ç ”ç©¶ä¸åŒå‚æ•°çš„å½±å“ï¼š

```bash
# æ¶ˆèå®éªŒåŸºç¡€é…ç½®
python main.py --config configs/id_contrastive/ablation.yaml

# æ¸©åº¦å‚æ•°æ¶ˆè
python main.py --config configs/id_contrastive/ablation.yaml \
    --override task.temperature=0.05

# æ‰¹é‡å¤§å°æ¶ˆè  
python main.py --config configs/id_contrastive/ablation.yaml \
    --override data.batch_size=64
```

### 4. è·¨æ•°æ®é›†æ³›åŒ– - åŸŸé€‚åº”

è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼š

```bash
# è·¨æ•°æ®é›†åŸŸæ³›åŒ–
python main.py --config configs/id_contrastive/cross_dataset.yaml \
    --override data.source_datasets='["CWRU","XJTU"]' \
    --override data.target_datasets='["PU","MFPT"]'
```

## é…ç½®å‚æ•°è¯¦è§£

### æ•°æ®é…ç½® (data)

æ§åˆ¶æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œçª—å£åŒ–çš„å…³é”®å‚æ•°ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | è°ƒä¼˜å»ºè®® |
|------|------|--------|------|---------|
| `factory_name` | str | "id" | æ•°æ®å·¥å‚åç§°ï¼Œä½¿ç”¨IDæ•°æ®æ¶æ„ | å›ºå®šå€¼ï¼Œæ— éœ€ä¿®æ”¹ |
| `dataset_name` | str | "ID_dataset" | æ•°æ®é›†ç±»åï¼Œå…¼å®¹æ‰€æœ‰IDæ ¼å¼æ•°æ® | å›ºå®šå€¼ï¼Œæ— éœ€ä¿®æ”¹ |
| `batch_size` | int | 32 | æ‰¹å¤§å°ï¼Œå½±å“å†…å­˜å’Œè®­ç»ƒç¨³å®šæ€§ | è°ƒè¯•:4, ç”Ÿäº§:64, æ ¹æ®GPUå†…å­˜è°ƒæ•´ |
| `num_workers` | int | 4 | æ•°æ®åŠ è½½è¿›ç¨‹æ•°ï¼Œå½±å“I/Oæ•ˆç‡ | è°ƒè¯•:1, ç”Ÿäº§:8, ä¸è¶…è¿‡CPUæ ¸æ•° |
| `window_size` | int | 1024 | çª—å£å¤§å°ï¼Œå†³å®šè¾“å…¥åºåˆ—é•¿åº¦ | è¶Šå¤§æ•è·æ›´å¤šä¿¡æ¯ï¼Œä½†å¢åŠ å†…å­˜æ¶ˆè€— |
| `stride` | int | 512 | çª—å£æ­¥é•¿ï¼Œæ§åˆ¶çª—å£é‡å åº¦ | é€šå¸¸ä¸ºwindow_sizeçš„1/2 |
| `num_window` | int | 2 | æ¯ä¸ªIDç”Ÿæˆçš„çª—å£æ•°é‡ | å¯¹æ¯”å­¦ä¹ å›ºå®šä¸º2ï¼Œç”Ÿæˆæ­£æ ·æœ¬å¯¹ |
| `window_sampling_strategy` | str | "random" | çª—å£é‡‡æ ·ç­–ç•¥ | random(æ¨è)/sequential/evenly_spaced |
| `normalization` | bool | true | æ˜¯å¦è¿›è¡ŒZ-scoreæ ‡å‡†åŒ– | å¼ºçƒˆæ¨èå¼€å¯ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ |
| `truncate_length` | int | 16384 | åŸå§‹ä¿¡å·æˆªæ–­é•¿åº¦ | æ ¹æ®æ•°æ®é›†ç‰¹å¾è°ƒæ•´ |

**è·¨æ•°æ®é›†ä¸“ç”¨å‚æ•°** (ä»…cross_dataset.yaml):
| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
|------|------|--------|------|
| `source_datasets` | list | ["CWRU", "XJTU"] | æºåŸŸæ•°æ®é›†åˆ—è¡¨ |
| `target_datasets` | list | ["PU", "MFPT"] | ç›®æ ‡åŸŸæ•°æ®é›†åˆ—è¡¨ |
| `dataset_balancing` | str | "weighted" | æ•°æ®é›†å¹³è¡¡ç­–ç•¥ |

### æ¨¡å‹é…ç½® (model)

å®šä¹‰æ¨¡å‹æ¶æ„å’Œå®¹é‡ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | å¯é€‰å€¼ |
|------|------|--------|------|-------|
| `name` | str | "M_01_ISFM" | ISFMæ¨¡å‹å˜ä½“ | M_01_ISFM/M_02_ISFM/M_03_ISFM |
| `backbone` | str | "B_08_PatchTST" | ä¸»å¹²ç½‘ç»œæ¶æ„ | B_08_PatchTST/B_04_Dlinear/B_06_TimesNet |
| `d_model` | int | 256 | æ¨¡å‹éšè—ç»´åº¦ | è°ƒè¯•:64, æ ‡å‡†:256, å¤§æ¨¡å‹:512 |

**ä¸»å¹²ç½‘ç»œç‰¹ç‚¹**:
- **B_08_PatchTST**: Patch-based Transformerï¼Œé€‚åˆé•¿åºåˆ—
- **B_04_Dlinear**: è½»é‡çº§çº¿æ€§ç½‘ç»œï¼Œè®¡ç®—æ•ˆç‡é«˜
- **B_06_TimesNet**: æ—¶åŸŸç‰¹å¾æå–ç½‘ç»œï¼Œé€‚åˆæ—¶åºåˆ†æ

### ä»»åŠ¡é…ç½® (task)

æ§åˆ¶å¯¹æ¯”å­¦ä¹ çš„æ ¸å¿ƒå‚æ•°ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | è°ƒä¼˜å»ºè®® |
|------|------|--------|------|---------|
| `type` | str | "pretrain" | ä»»åŠ¡ç±»å‹æ ‡è¯† | å›ºå®šå€¼ |
| `name` | str | "contrastive_id" | ä»»åŠ¡åç§°æ ‡è¯† | å›ºå®šå€¼ |
| `lr` | float | 1e-3 | å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¢¯åº¦æ›´æ–°æ­¥é•¿ | å°æ‰¹é‡ç”¨1e-3ï¼Œå¤§æ‰¹é‡ç”¨5e-4 |
| `weight_decay` | float | 1e-4 | L2æ­£åˆ™åŒ–æƒé‡è¡°å‡ | é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé€šå¸¸1e-4~1e-5 |
| `temperature` | float | 0.07 | InfoNCEæ¸©åº¦å‚æ•° | å…³é”®å‚æ•°ï¼0.05-0.1ï¼Œè¶Šå°è¶Šä¸¥æ ¼ |

**æ¸©åº¦å‚æ•°è¯¦è§£**:
- `temperature < 0.05`: éå¸¸ä¸¥æ ¼çš„å¯¹æ¯”å­¦ä¹ ï¼Œå¯èƒ½éš¾ä»¥æ”¶æ•›
- `temperature = 0.07`: æ¨èå€¼ï¼Œå¹³è¡¡å­¦ä¹ éš¾åº¦å’Œæ”¶æ•›æ€§
- `temperature > 0.1`: è¾ƒå®½æ¾çš„å¯¹æ¯”å­¦ä¹ ï¼Œå¯èƒ½å­¦ä¹ åˆ°ç²—ç²’åº¦ç‰¹å¾

### è®­ç»ƒé…ç½® (trainer)

æ§åˆ¶è®­ç»ƒè¿‡ç¨‹å’Œä¼˜åŒ–ç­–ç•¥ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° | åœºæ™¯å»ºè®® |
|------|------|--------|------|---------|
| `epochs` | int | 50 | æœ€å¤§è®­ç»ƒè½®æ•° | è°ƒè¯•:1, æ ‡å‡†:50, ç”Ÿäº§:100 |
| `accelerator` | str | "gpu" | è®¡ç®—è®¾å¤‡ç±»å‹ | gpu(æ¨è)/cpu |
| `devices` | int/list | 1 | ä½¿ç”¨çš„è®¾å¤‡æ•°é‡æˆ–åˆ—è¡¨ | å•å¡:1, å¤šå¡:[0,1] |
| `precision` | int | 16 | æ•°å€¼ç²¾åº¦ | 16(æ··åˆç²¾åº¦ï¼Œçœå†…å­˜)/32(å•ç²¾åº¦ï¼Œç¨³å®š) |
| `gradient_clip_val` | float | 1.0 | æ¢¯åº¦è£å‰ªé˜ˆå€¼ | é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼Œ0.5-1.0 |
| `check_val_every_n_epoch` | int | 5 | éªŒè¯é¢‘ç‡ | è°ƒè¯•:1, ç”Ÿäº§:10 |
| `log_every_n_steps` | int | 50 | æ—¥å¿—è®°å½•æ­¥é•¿ | è°ƒè¯•:1, ç”Ÿäº§:100 |

**ç”Ÿäº§ç¯å¢ƒä¸“ç”¨å‚æ•°** (ä»…production.yaml):
| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
|------|------|--------|------|
| `enable_early_stopping` | bool | true | å¯ç”¨æ—©åœæœºåˆ¶ |
| `patience` | int | 15 | æ—©åœè€å¿ƒå€¼ |
| `lr_scheduler` | str | "cosine" | å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥ |
| `save_top_k` | int | 3 | ä¿å­˜æœ€ä½³kä¸ªæ£€æŸ¥ç‚¹ |

### ç¯å¢ƒé…ç½® (environment)

æ§åˆ¶å®éªŒç¯å¢ƒå’Œç»“æœä¿å­˜ï¼š

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
|------|------|--------|------|
| `save_dir` | str | "save/" | ç»“æœä¿å­˜æ ¹ç›®å½• |
| `experiment_name` | str | "contrastive_*" | å®éªŒåç§°ï¼Œå½±å“ä¿å­˜è·¯å¾„ |

## å®éªŒå·¥ä½œæµ

### å·¥ä½œæµ1: è°ƒè¯•å¼€å‘æµç¨‹

æ–°åŠŸèƒ½å¼€å‘å’Œé—®é¢˜è°ƒè¯•çš„æ¨èæµç¨‹ï¼š

```bash
# 1. å¿«é€ŸéªŒè¯ - ä½¿ç”¨æœ€å°é…ç½®
python main.py --config configs/id_contrastive/debug.yaml

# 2. æ£€æŸ¥è¾“å‡ºæ—¥å¿—
tail -f debug/contrastive_debug/log.txt

# 3. å‚æ•°å¾®è°ƒ - è¦†ç›–ç‰¹å®šå‚æ•°
python main.py --config configs/id_contrastive/debug.yaml \
    --override task.temperature=0.05 data.window_size=512

# 4. ä»£ç è°ƒè¯•æ¨¡å¼ï¼ˆå¦‚éœ€è¦ï¼‰
python -m pdb main.py --config configs/id_contrastive/debug.yaml
```

**è°ƒè¯•æ£€æŸ¥æ¸…å•**:
- [ ] æ•°æ®åŠ è½½æ­£å¸¸ï¼Œæ— æŠ¥é”™
- [ ] æŸå¤±å‡½æ•°ä¸‹é™è¶‹åŠ¿
- [ ] å‡†ç¡®ç‡æœ‰æ„ä¹‰æå‡
- [ ] å†…å­˜ä½¿ç”¨å¯æ§

### å·¥ä½œæµ2: æ¶ˆèå®éªŒæµç¨‹

ç³»ç»Ÿæ€§å‚æ•°ç ”ç©¶çš„æ ‡å‡†æµç¨‹ï¼š

```bash
# 1. åŸºçº¿å®éªŒ - ä½¿ç”¨é»˜è®¤å‚æ•°
python main.py --config configs/id_contrastive/ablation.yaml \
    --override environment.experiment_name=baseline_temp_0.07

# 2. æ¸©åº¦å‚æ•°æ¶ˆè
for temp in 0.01 0.05 0.07 0.1 0.5; do
    python main.py --config configs/id_contrastive/ablation.yaml \
        --override task.temperature=$temp \
        --override environment.experiment_name=temp_${temp}
done

# 3. æ‰¹é‡å¤§å°æ¶ˆè
for batch in 16 32 64 128; do
    python main.py --config configs/id_contrastive/ablation.yaml \
        --override data.batch_size=$batch \
        --override environment.experiment_name=batch_${batch}
done

# 4. çª—å£å¤§å°æ¶ˆè
for window in 512 1024 2048 4096; do
    python main.py --config configs/id_contrastive/ablation.yaml \
        --override data.window_size=$window \
        --override data.stride=$((window/2)) \
        --override environment.experiment_name=window_${window}
done
```

**æ¶ˆèå®éªŒåˆ†æ**:
```python
# åˆ†æè„šæœ¬ç¤ºä¾‹
import pandas as pd
import matplotlib.pyplot as plt

# æ”¶é›†å®éªŒç»“æœ
results = []
for exp_name in experiment_names:
    metrics = load_experiment_metrics(f"save/ablation/{exp_name}")
    results.append({
        'experiment': exp_name,
        'final_loss': metrics['val_contrastive_loss'][-1],
        'final_acc': metrics['val_contrastive_acc'][-1],
        'parameter': parse_parameter_from_name(exp_name)
    })

# å¯è§†åŒ–åˆ†æ
df = pd.DataFrame(results)
plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.plot(df['parameter'], df['final_loss'], 'bo-')
plt.title('Parameter vs Loss')
plt.subplot(1, 2, 2)
plt.plot(df['parameter'], df['final_acc'], 'ro-')
plt.title('Parameter vs Accuracy')
plt.show()
```

### å·¥ä½œæµ3: ç”Ÿäº§è®­ç»ƒæµç¨‹

æ­£å¼å®éªŒçš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼š

```bash
# 1. é¢„æ£€æŸ¥ - ç¡®è®¤ç¯å¢ƒå’Œæ•°æ®
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
python -c "from src.configs import load_config; print('Config loading OK')"

# 2. å¯åŠ¨è®­ç»ƒ - åå°è¿è¡Œ
nohup python main.py --config configs/id_contrastive/production.yaml > train.log 2>&1 &

# 3. ç›‘æ§è®­ç»ƒ - å®æ—¶æ—¥å¿—
tail -f train.log
# æˆ–ä½¿ç”¨TensorBoard
tensorboard --logdir=save/production/contrastive_production/lightning_logs

# 4. æ£€æŸ¥ç‚¹ç®¡ç†
ls save/production/contrastive_production/checkpoints/
# best.ckpt - éªŒè¯æ€§èƒ½æœ€ä½³æ¨¡å‹
# last.ckpt - æœ€ç»ˆè®­ç»ƒçŠ¶æ€
# epoch=N.ckpt - å®šæœŸä¿å­˜ç‚¹

# 5. ç»“æœè¯„ä¼°
python scripts/evaluate_pretrain.py \
    --checkpoint save/production/contrastive_production/checkpoints/best.ckpt \
    --config configs/id_contrastive/production.yaml
```

### å·¥ä½œæµ4: è·¨æ•°æ®é›†æ³›åŒ–æµç¨‹

åŸŸé€‚åº”å®éªŒçš„ç³»ç»ŸåŒ–æµç¨‹ï¼š

```bash
# 1. å•åŸŸåŸºçº¿ - åœ¨å„æ•°æ®é›†ä¸Šç‹¬ç«‹è®­ç»ƒ
datasets=("CWRU" "XJTU" "PU" "MFPT")
for dataset in "${datasets[@]}"; do
    python main.py --config configs/id_contrastive/cross_dataset.yaml \
        --override data.source_datasets="[\"$dataset\"]" \
        --override data.target_datasets="[\"$dataset\"]" \
        --override environment.experiment_name=single_domain_$dataset
done

# 2. è·¨åŸŸæ³›åŒ– - æºåŸŸåˆ°ç›®æ ‡åŸŸ
python main.py --config configs/id_contrastive/cross_dataset.yaml \
    --override data.source_datasets='["CWRU","XJTU"]' \
    --override data.target_datasets='["PU","MFPT"]' \
    --override environment.experiment_name=cross_domain_bearing

# 3. å¤šåŸŸè”åˆ - ä½¿ç”¨æ‰€æœ‰æºåŸŸ
python main.py --config configs/id_contrastive/cross_dataset.yaml \
    --override data.source_datasets='["CWRU","XJTU","PU"]' \
    --override data.target_datasets='["MFPT"]' \
    --override environment.experiment_name=multi_source_to_mfpt

# 4. åŸŸåˆ†æ
python scripts/domain_analysis.py \
    --experiments single_domain_* cross_domain_* multi_source_*
```

**åŸŸæ³›åŒ–è¯„ä¼°æŒ‡æ ‡**:
- **æºåŸŸæ€§èƒ½**: è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¡¨ç°
- **ç›®æ ‡åŸŸæ€§èƒ½**: æµ‹è¯•æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬è¡¨ç°  
- **åŸŸå·®è·**: æºåŸŸä¸ç›®æ ‡åŸŸæ€§èƒ½çš„å·®å¼‚
- **æ³›åŒ–æ¯”ç‡**: ç›®æ ‡åŸŸæ€§èƒ½/æºåŸŸæ€§èƒ½

## é›†æˆæŒ‡å—

### ä¸PHM-Vibenchå·¥å‚ç³»ç»Ÿé›†æˆ

ContrastiveIDTaskå®Œå…¨é›†æˆåˆ°PHM-Vibenchçš„å·¥å‚è®¾è®¡æ¨¡å¼ä¸­ï¼š

#### 1. ä»»åŠ¡æ³¨å†Œæœºåˆ¶

```python
# è‡ªåŠ¨æ³¨å†Œåˆ°task_factory
@register_task("contrastive_id", "pretrain")
class ContrastiveIDTask(BaseIDTask):
    """å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒä»»åŠ¡"""
    pass

# ä½¿ç”¨ä»»åŠ¡å·¥å‚åˆ›å»º
from src.task_factory import TaskFactory
task_factory = TaskFactory()
task = task_factory.create_task(
    task_type="pretrain",
    task_name="contrastive_id",
    # ... å…¶ä»–å‚æ•°
)
```

#### 2. æ•°æ®å·¥å‚é›†æˆ

ä¸IDæ•°æ®æ¶æ„æ— ç¼é›†æˆï¼š

```python
# ä½¿ç”¨id_data_factory
data_factory = DataFactory()
dataloader = data_factory.create_data_loader(
    factory_name="id",
    dataset_name="ID_dataset",
    # ... æ•°æ®é…ç½®
)

# æ”¯æŒæ‰€æœ‰IDæ ¼å¼æ•°æ®é›†
supported_datasets = [
    "CWRU", "XJTU", "PU", "MFPT", "JNU", 
    "PHM2009", "FEMTO", "IMS", "PRONOSTIA"
]
```

#### 3. æ¨¡å‹å·¥å‚é›†æˆ

æ”¯æŒæ‰€æœ‰ISFMæ¨¡å‹æ¶æ„ï¼š

```python
# æ¨¡å‹å·¥å‚åˆ›å»º
model_factory = ModelFactory()
network = model_factory.create_model(
    model_type="ISFM",
    model_name="M_01_ISFM",
    backbone="B_08_PatchTST",
    # ... æ¨¡å‹é…ç½®
)

# æ”¯æŒçš„æ¨¡å‹æ¶æ„
isfm_models = ["M_01_ISFM", "M_02_ISFM", "M_03_ISFM"]
backbones = ["B_08_PatchTST", "B_04_Dlinear", "B_06_TimesNet", "B_09_FNO"]
```

### ä¸Pipeline_IDé›†æˆ

ä¸“é—¨ç”¨äºIDæ•°æ®å¤„ç†çš„ç®¡é“ï¼š

```python
# Pipeline_IDä½¿ç”¨ç¤ºä¾‹
from src.pipeline import Pipeline_ID

# åˆ›å»ºç®¡é“å®ä¾‹
pipeline = Pipeline_ID()

# è¿è¡Œå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ
results = pipeline.run_pretraining(
    config_path="configs/id_contrastive/production.yaml",
    checkpoint_callback=True,
    early_stopping=True
)

# ç®¡é“æ”¯æŒçš„æ“ä½œ
pipeline_ops = [
    "data_loading",      # IDæ•°æ®åŠ è½½
    "preprocessing",     # ä¿¡å·é¢„å¤„ç†
    "windowing",        # å¤šçª—å£é‡‡æ ·
    "training",         # å¯¹æ¯”å­¦ä¹ è®­ç»ƒ
    "evaluation",       # æ€§èƒ½è¯„ä¼°
    "visualization"     # ç»“æœå¯è§†åŒ–
]
```

### ä¸ä¸‹æ¸¸ä»»åŠ¡é›†æˆ

é¢„è®­ç»ƒæ¨¡å‹ç”¨äºä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒï¼š

```python
# 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
pretrain_checkpoint = "save/production/checkpoints/best.ckpt"
pretrained_task = ContrastiveIDTask.load_from_checkpoint(pretrain_checkpoint)

# 2. æå–ç‰¹å¾ç¼–ç å™¨
encoder = pretrained_task.network

# 3. åˆ›å»ºä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»ï¼‰
from src.task_factory.task.classification import ClassificationTask
downstream_task = ClassificationTask(
    network=encoder,
    num_classes=10,
    freeze_encoder=False,  # æˆ–Trueè¿›è¡Œå†»ç»“å¾®è°ƒ
    # ... å…¶ä»–å‚æ•°
)

# 4. å¾®è°ƒè®­ç»ƒ
trainer = pl.Trainer(max_epochs=20)
trainer.fit(downstream_task, downstream_dataloader)
```

### é…ç½®ç³»ç»Ÿé›†æˆ

åˆ©ç”¨PHM-Vibench v5.0ç»Ÿä¸€é…ç½®ç³»ç»Ÿï¼š

```python
from src.configs import load_config

# 1. åŸºç¡€é…ç½®åŠ è½½
config = load_config("configs/id_contrastive/production.yaml")

# 2. é¢„è®¾é…ç½®ä½¿ç”¨
config = load_config("contrastive_id_preset", {
    "data.batch_size": 64,
    "task.temperature": 0.05
})

# 3. åŠ¨æ€é…ç½®æ„å»º
config = load_config("debug_preset").copy().update({
    "trainer.epochs": 10,
    "model.d_model": 512
})

# 4. é“¾å¼é…ç½®è¦†ç›–
config = (load_config("base_config")
          .update_from_dict(user_overrides)
          .update_from_file("experiment_specific.yaml"))
```

## æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### é”™è¯¯1: CUDAå†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# æ–¹æ¡ˆ1: å‡å°‘æ‰¹é‡å¤§å°
data:
  batch_size: 16  # ä»32å‡å°‘åˆ°16

# æ–¹æ¡ˆ2: å‡å°‘æ¨¡å‹ç»´åº¦  
model:
  d_model: 128    # ä»256å‡å°‘åˆ°128

# æ–¹æ¡ˆ3: å¯ç”¨æ¢¯åº¦ç´¯ç§¯
trainer:
  accumulate_grad_batches: 4  # æ¨¡æ‹Ÿå¤§æ‰¹é‡

# æ–¹æ¡ˆ4: ä½¿ç”¨æ··åˆç²¾åº¦
trainer:
  precision: 16   # å‡å°‘50%å†…å­˜ä½¿ç”¨
```

#### é”™è¯¯2: æ•°æ®åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `FileNotFoundError: metadata file not found`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„
ls -la data/
# åº”è¯¥åŒ…å«: metadata_*.xlsx æ–‡ä»¶

# 2. æ£€æŸ¥metadataæ–‡ä»¶è·¯å¾„
python -c "
import os
data_dir = 'data'
metadata_file = 'metadata_6_1.xlsx' 
full_path = os.path.join(data_dir, metadata_file)
print(f'Checking: {full_path}')
print(f'Exists: {os.path.exists(full_path)}')
"

# 3. éªŒè¯æ•°æ®é›†ID
python -c "
from src.data_factory.dataset.ID_dataset import ID_dataset
dataset = ID_dataset('data', 'metadata_6_1.xlsx')
print(f'Dataset length: {len(dataset)}')
print(f'Available IDs: {dataset.get_available_ids()[:5]}')  # æ˜¾ç¤ºå‰5ä¸ªID
"
```

#### é”™è¯¯3: è®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**: æŸå¤±ä¸ä¸‹é™æˆ–å‡†ç¡®ç‡åœæ»

**è¯Šæ–­å’Œè§£å†³**:
```python
# è¯Šæ–­è„šæœ¬
import torch
import matplotlib.pyplot as plt

# 1. æ£€æŸ¥æ¢¯åº¦
def check_gradients(model):
    total_norm = 0
    param_count = 0
    for p in model.parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
            param_count += 1
    total_norm = total_norm ** (1. / 2)
    print(f"Gradient norm: {total_norm:.6f}, Params with grad: {param_count}")
    return total_norm

# 2. æ£€æŸ¥æƒé‡æ›´æ–°
def check_weight_updates(model_before, model_after):
    updates = []
    for (name, p_before), (_, p_after) in zip(
        model_before.named_parameters(), 
        model_after.named_parameters()
    ):
        update = torch.norm(p_after - p_before).item()
        updates.append((name, update))
        print(f"{name}: {update:.8f}")
    return updates

# è§£å†³æ–¹æ¡ˆ
solutions = {
    "å­¦ä¹ ç‡è¿‡å¤§": "å‡å°lråˆ°5e-4æˆ–1e-4",
    "æ¸©åº¦è¿‡ä½": "å¢å¤§temperatureåˆ°0.1",
    "æ¢¯åº¦æ¶ˆå¤±": "æ£€æŸ¥ç½‘ç»œæ·±åº¦ï¼Œè€ƒè™‘æ®‹å·®è¿æ¥",
    "æ¢¯åº¦çˆ†ç‚¸": "å‡å°gradient_clip_valåˆ°0.5",
    "æ•°æ®æ ‡å‡†åŒ–é—®é¢˜": "ç¡®ä¿normalization=true"
}
```

#### é”™è¯¯4: éªŒè¯æ€§èƒ½å¼‚å¸¸

**ç—‡çŠ¶**: éªŒè¯å‡†ç¡®ç‡è¿œä½äºéšæœºæ°´å¹³

**è§£å†³æ­¥éª¤**:
```python
# 1. æ£€æŸ¥æ­£è´Ÿæ ·æœ¬åˆ†å¸ƒ
def analyze_batch_distribution(dataloader):
    for batch in dataloader:
        anchor = batch['anchor']
        positive = batch['positive'] 
        print(f"Batch size: {len(batch['ids'])}")
        print(f"Anchor shape: {anchor.shape}")
        print(f"Positive shape: {positive.shape}")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºåŒä¸€IDçš„ä¸åŒçª—å£
        for i, sample_id in enumerate(batch['ids']):
            print(f"Sample {i}: ID={sample_id}")
        break

# 2. æ£€æŸ¥InfoNCEå®ç°
def validate_infonce_implementation():
    # åˆ›å»ºç®€å•æµ‹è¯•ç”¨ä¾‹
    batch_size = 4
    d_model = 256
    
    anchor = torch.randn(batch_size, d_model)
    positive = torch.randn(batch_size, d_model)
    
    # æ‰‹åŠ¨è®¡ç®—InfoNCE
    task = ContrastiveIDTask(...)
    loss = task.infonce_loss(anchor, positive)
    print(f"InfoNCE loss: {loss.item()}")
    
    # æ£€æŸ¥ç›¸ä¼¼åº¦çŸ©é˜µ
    anchor_norm = F.normalize(anchor, dim=1)
    positive_norm = F.normalize(positive, dim=1)
    sim_matrix = torch.mm(anchor_norm, positive_norm.t()) / task.temperature
    print(f"Similarity matrix diagonal: {torch.diag(sim_matrix)}")
```

### æ€§èƒ½è¯Šæ–­å·¥å…·

#### GPUä½¿ç”¨ç›‘æ§

```bash
# å®æ—¶GPUç›‘æ§
nvidia-smi -l 1

# GPUå†…å­˜ä½¿ç”¨åˆ†æ
python -c "
import torch
print(f'Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')
print(f'Current allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB')
print(f'Current reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB')
"
```

#### è®­ç»ƒé€Ÿåº¦åˆ†æ

```python
# æ€§èƒ½åˆ†æè„šæœ¬
import time
import torch.profiler as profiler

def profile_training_step(model, batch):
    with profiler.profile(
        schedule=profiler.schedule(wait=1, warmup=1, active=3, repeat=2),
        on_trace_ready=profiler.tensorboard_trace_handler('./profiler_logs'),
        record_shapes=True,
        profile_memory=True,
        with_stack=True
    ) as prof:
        for step in range(10):
            # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
            model.training_step(batch, step)
            prof.step()
    
    # åˆ†æç»“æœ
    print(prof.key_averages().table(sort_by="cuda_time_total", row_limit=10))
```

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰é…ç½®è¦†ç›–

#### 1. ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export CONTRASTIVE_TEMPERATURE=0.05
export CONTRASTIVE_BATCH_SIZE=128
export CONTRASTIVE_EPOCHS=200

# åœ¨é…ç½®ä¸­ä½¿ç”¨
python -c "
import os
from src.configs import load_config

config = load_config('configs/id_contrastive/production.yaml', {
    'task.temperature': float(os.getenv('CONTRASTIVE_TEMPERATURE', 0.07)),
    'data.batch_size': int(os.getenv('CONTRASTIVE_BATCH_SIZE', 32)),
    'trainer.epochs': int(os.getenv('CONTRASTIVE_EPOCHS', 50))
})
"
```

#### 2. æ¡ä»¶é…ç½®

```python
# æ ¹æ®æ¡ä»¶åŠ¨æ€è°ƒæ•´é…ç½®
import torch
from src.configs import load_config

def create_adaptive_config():
    # æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒ
    gpu_count = torch.cuda.device_count()
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9 if gpu_count > 0 else 0
    
    # åŸºç¡€é…ç½®
    config = load_config("configs/id_contrastive/production.yaml")
    
    # æ ¹æ®GPUå†…å­˜è°ƒæ•´æ‰¹é‡å¤§å°
    if gpu_memory > 24:  # > 24GB
        config.update({"data.batch_size": 128, "model.d_model": 512})
    elif gpu_memory > 12:  # 12-24GB
        config.update({"data.batch_size": 64, "model.d_model": 256})
    else:  # < 12GB
        config.update({"data.batch_size": 32, "model.d_model": 128})
    
    # å¤šGPUé…ç½®
    if gpu_count > 1:
        config.update({
            "trainer.devices": list(range(gpu_count)),
            "trainer.strategy": "ddp",
            "data.batch_size": config.data.batch_size * gpu_count
        })
    
    return config
```

### æ‰¹é‡å®éªŒç®¡ç†

#### å®éªŒçŸ©é˜µç”Ÿæˆ

```python
# scripts/generate_experiment_matrix.py
import itertools
import json
from pathlib import Path

def generate_ablation_experiments():
    """ç”Ÿæˆå®Œæ•´æ¶ˆèå®éªŒçŸ©é˜µ"""
    
    # å®éªŒå˜é‡å®šä¹‰
    variables = {
        "temperature": [0.01, 0.05, 0.07, 0.1, 0.5],
        "batch_size": [16, 32, 64, 128],
        "window_size": [512, 1024, 2048, 4096],
        "d_model": [128, 256, 512],
        "lr": [1e-4, 5e-4, 1e-3, 5e-3]
    }
    
    # ç”Ÿæˆæ‰€æœ‰ç»„åˆï¼ˆè­¦å‘Šï¼šå¯èƒ½å¾ˆå¤šï¼ï¼‰
    experiments = []
    for values in itertools.product(*variables.values()):
        experiment = dict(zip(variables.keys(), values))
        
        # æ·»åŠ åˆç†æ€§æ£€æŸ¥
        if experiment["batch_size"] * experiment["window_size"] > 200000:
            continue  # è·³è¿‡å†…å­˜éœ€æ±‚è¿‡é«˜çš„ç»„åˆ
            
        experiments.append(experiment)
    
    print(f"Generated {len(experiments)} experiments")
    
    # ä¿å­˜å®éªŒçŸ©é˜µ
    output_file = "experiments/ablation_matrix.json"
    Path(output_file).parent.mkdir(exist_ok=True)
    with open(output_file, 'w') as f:
        json.dump(experiments, f, indent=2)
    
    return experiments

def run_experiment_batch(experiments_file, max_parallel=4):
    """å¹¶è¡Œè¿è¡Œå®éªŒæ‰¹æ¬¡"""
    import subprocess
    import concurrent.futures
    
    with open(experiments_file, 'r') as f:
        experiments = json.load(f)
    
    def run_single_experiment(exp_id, params):
        cmd = [
            "python", "main.py",
            "--config", "configs/id_contrastive/ablation.yaml"
        ]
        
        # æ·»åŠ å‚æ•°è¦†ç›–
        for key, value in params.items():
            cmd.extend(["--override", f"task.{key}={value}" if key in ["temperature", "lr"] 
                       else f"data.{key}={value}" if key in ["batch_size", "window_size"]
                       else f"model.{key}={value}"])
        
        # æ·»åŠ å®éªŒåç§°
        exp_name = f"exp_{exp_id}_" + "_".join(f"{k}_{v}" for k, v in params.items())
        cmd.extend(["--override", f"environment.experiment_name={exp_name}"])
        
        print(f"Running experiment {exp_id}: {exp_name}")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        return exp_id, result.returncode, result.stdout, result.stderr
    
    # å¹¶è¡Œæ‰§è¡Œ
    with concurrent.futures.ProcessPoolExecutor(max_workers=max_parallel) as executor:
        futures = [
            executor.submit(run_single_experiment, i, exp) 
            for i, exp in enumerate(experiments)
        ]
        
        for future in concurrent.futures.as_completed(futures):
            exp_id, returncode, stdout, stderr = future.result()
            if returncode == 0:
                print(f"âœ“ Experiment {exp_id} completed successfully")
            else:
                print(f"âœ— Experiment {exp_id} failed: {stderr}")
```

### å‚æ•°è°ƒä¼˜ç­–ç•¥

#### 1. è´å¶æ–¯ä¼˜åŒ–

```python
# ä½¿ç”¨Optunaè¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–
import optuna
from src.configs import load_config

def objective(trial):
    # å®šä¹‰æœç´¢ç©ºé—´
    temperature = trial.suggest_float("temperature", 0.01, 0.5, log=True)
    batch_size = trial.suggest_categorical("batch_size", [16, 32, 64, 128])
    lr = trial.suggest_float("lr", 1e-5, 1e-2, log=True)
    d_model = trial.suggest_categorical("d_model", [128, 256, 512])
    
    # åˆ›å»ºé…ç½®
    config = load_config("configs/id_contrastive/ablation.yaml", {
        "task.temperature": temperature,
        "data.batch_size": batch_size,
        "task.lr": lr,
        "model.d_model": d_model,
        "trainer.epochs": 10,  # å¿«é€Ÿè¯„ä¼°
        "environment.experiment_name": f"optuna_trial_{trial.number}"
    })
    
    # è¿è¡Œå®éªŒï¼ˆç®€åŒ–ç‰ˆï¼‰
    try:
        result = run_experiment(config)
        return result['val_contrastive_acc']  # ä¼˜åŒ–ç›®æ ‡
    except Exception as e:
        return 0.0  # å¤±è´¥æ¡ˆä¾‹è¿”å›æœ€ä½åˆ†

# è¿è¡Œä¼˜åŒ–
study = optuna.create_study(direction="maximize")
study.optimize(objective, n_trials=100)

print("Best parameters:", study.best_params)
print("Best value:", study.best_value)
```

#### 2. å­¦ä¹ ç‡è°ƒåº¦

```python
# è‡ªå®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨
class ContrastiveLRScheduler:
    def __init__(self, optimizer, warmup_steps=1000, max_lr=1e-3, min_lr=1e-5):
        self.optimizer = optimizer
        self.warmup_steps = warmup_steps
        self.max_lr = max_lr
        self.min_lr = min_lr
        self.step_count = 0
    
    def step(self, val_acc=None):
        self.step_count += 1
        
        if self.step_count <= self.warmup_steps:
            # çº¿æ€§é¢„çƒ­
            lr = self.max_lr * (self.step_count / self.warmup_steps)
        else:
            # ä½™å¼¦é€€ç«
            progress = (self.step_count - self.warmup_steps) / (10000 - self.warmup_steps)
            lr = self.min_lr + (self.max_lr - self.min_lr) * 0.5 * (1 + cos(pi * progress))
        
        # åº”ç”¨å­¦ä¹ ç‡
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
        
        return lr

# é›†æˆåˆ°è®­ç»ƒä¸­
scheduler = ContrastiveLRScheduler(optimizer)
for epoch in range(epochs):
    for batch in dataloader:
        # è®­ç»ƒæ­¥éª¤
        loss = model.training_step(batch)
        optimizer.step()
        scheduler.step()
```

### ç‰¹å¾åˆ†æä¸å¯è§†åŒ–

#### 1. ç‰¹å¾è´¨é‡è¯„ä¼°

```python
# scripts/feature_analysis.py
import torch
import numpy as np
from sklearn.metrics import silhouette_score
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_feature_quality(model, dataloader):
    """è¯„ä¼°å­¦åˆ°çš„ç‰¹å¾è´¨é‡"""
    model.eval()
    
    features = []
    labels = []
    ids = []
    
    with torch.no_grad():
        for batch in dataloader:
            # æå–ç‰¹å¾
            anchor_feat = model.network(batch['anchor'])
            positive_feat = model.network(batch['positive'])
            
            features.extend([anchor_feat, positive_feat])
            labels.extend([batch['labels'], batch['labels']])  # å‡è®¾æœ‰æ ‡ç­¾
            ids.extend([batch['ids'], batch['ids']])
    
    features = torch.cat(features).cpu().numpy()
    labels = torch.cat(labels).cpu().numpy()
    
    # 1. è½®å»“ç³»æ•° - è¡¡é‡èšç±»è´¨é‡
    silhouette = silhouette_score(features, labels)
    print(f"Silhouette Score: {silhouette:.4f}")
    
    # 2. åŒç±»æ ·æœ¬ç›¸ä¼¼åº¦ vs å¼‚ç±»æ ·æœ¬ç›¸ä¼¼åº¦
    intra_class_sim = []
    inter_class_sim = []
    
    for i in range(len(features)):
        for j in range(i+1, len(features)):
            sim = np.dot(features[i], features[j]) / (
                np.linalg.norm(features[i]) * np.linalg.norm(features[j])
            )
            if labels[i] == labels[j]:
                intra_class_sim.append(sim)
            else:
                inter_class_sim.append(sim)
    
    print(f"Intra-class similarity: {np.mean(intra_class_sim):.4f} Â± {np.std(intra_class_sim):.4f}")
    print(f"Inter-class similarity: {np.mean(inter_class_sim):.4f} Â± {np.std(inter_class_sim):.4f}")
    
    return {
        'silhouette_score': silhouette,
        'intra_class_similarity': np.mean(intra_class_sim),
        'inter_class_similarity': np.mean(inter_class_sim),
        'features': features,
        'labels': labels
    }

def visualize_feature_space(features, labels, method='tsne', save_path=None):
    """å¯è§†åŒ–ç‰¹å¾ç©ºé—´åˆ†å¸ƒ"""
    
    if method == 'tsne':
        # t-SNEé™ç»´
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        features_2d = tsne.fit_transform(features)
    elif method == 'pca':
        # PCAé™ç»´
        from sklearn.decomposition import PCA
        pca = PCA(n_components=2)
        features_2d = pca.fit_transform(features)
    
    # ç»˜åˆ¶æ•£ç‚¹å›¾
    plt.figure(figsize=(12, 8))
    unique_labels = np.unique(labels)
    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
    
    for label, color in zip(unique_labels, colors):
        mask = labels == label
        plt.scatter(
            features_2d[mask, 0], 
            features_2d[mask, 1], 
            c=[color], 
            label=f'Class {label}',
            alpha=0.6,
            s=50
        )
    
    plt.xlabel(f'{method.upper()} Component 1')
    plt.ylabel(f'{method.upper()} Component 2')
    plt.title(f'Feature Space Visualization ({method.upper()})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def analyze_feature_evolution(checkpoints, dataloader):
    """åˆ†æç‰¹å¾åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¼”åŒ–"""
    
    evolution_data = []
    
    for epoch, checkpoint_path in enumerate(checkpoints):
        model = ContrastiveIDTask.load_from_checkpoint(checkpoint_path)
        metrics = evaluate_feature_quality(model, dataloader)
        
        evolution_data.append({
            'epoch': epoch,
            'silhouette_score': metrics['silhouette_score'],
            'intra_class_sim': metrics['intra_class_similarity'],
            'inter_class_sim': metrics['inter_class_similarity']
        })
    
    # å¯è§†åŒ–æ¼”åŒ–è¿‡ç¨‹
    df = pd.DataFrame(evolution_data)
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    axes[0].plot(df['epoch'], df['silhouette_score'], 'b-o')
    axes[0].set_title('Silhouette Score Evolution')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Silhouette Score')
    
    axes[1].plot(df['epoch'], df['intra_class_sim'], 'g-o', label='Intra-class')
    axes[1].plot(df['epoch'], df['inter_class_sim'], 'r-o', label='Inter-class')
    axes[1].set_title('Similarity Evolution')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Cosine Similarity')
    axes[1].legend()
    
    axes[2].plot(df['epoch'], df['intra_class_sim'] - df['inter_class_sim'], 'purple', marker='o')
    axes[2].set_title('Similarity Gap Evolution')
    axes[2].set_xlabel('Epoch')
    axes[2].set_ylabel('Intra - Inter Similarity')
    
    plt.tight_layout()
    plt.show()
    
    return evolution_data
```

## APIå‚è€ƒ

### ContrastiveIDTaskç±»

```python
from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask

# åˆ›å»ºä»»åŠ¡å®ä¾‹
task = ContrastiveIDTask(
    network=network,
    args_data=data_config,
    args_model=model_config,
    args_task=task_config,
    args_trainer=trainer_config,
    args_environment=env_config,
    metadata=metadata
)
```

#### æ ¸å¿ƒæ–¹æ³•

**`prepare_batch(batch_data: List[Tuple]) -> Dict[str, torch.Tensor]`**

å‡†å¤‡å¯¹æ¯”å­¦ä¹ çš„æ‰¹å¤„ç†æ•°æ®ï¼Œç”Ÿæˆæ­£æ ·æœ¬å¯¹ï¼š

```python
# è¾“å…¥: åŸå§‹æ‰¹æ¬¡æ•°æ®
batch_data = [
    ("ID_001", signal_array_1, metadata_1),
    ("ID_002", signal_array_2, metadata_2),
    # ...
]

# è¾“å‡º: å¯¹æ¯”å­¦ä¹ æ•°æ®å­—å…¸
batch = {
    'anchor': torch.tensor([...]),    # é”šç‚¹çª—å£ [B, L, 1]
    'positive': torch.tensor([...]),  # æ­£æ ·æœ¬çª—å£ [B, L, 1] 
    'ids': ["ID_001", "ID_002", ...]  # æ ·æœ¬IDåˆ—è¡¨
}
```

**`infonce_loss(z_anchor: torch.Tensor, z_positive: torch.Tensor) -> torch.Tensor`**

è®¡ç®—InfoNCEå¯¹æ¯”æŸå¤±ï¼š

```python
# æ•°å­¦å…¬å¼
# InfoNCE = -log(exp(sim(anchor, positive)/Ï„) / Î£exp(sim(anchor, all)/Ï„))

loss = task.infonce_loss(anchor_features, positive_features)
# è¿”å›æ ‡é‡æŸå¤±å€¼
```

**`compute_accuracy(z_anchor: torch.Tensor, z_positive: torch.Tensor) -> torch.Tensor`**

è®¡ç®—å¯¹æ¯”å­¦ä¹ Top-1å‡†ç¡®ç‡ï¼š

```python
accuracy = task.compute_accuracy(anchor_features, positive_features)
# è¿”å›0-1ä¹‹é—´çš„å‡†ç¡®ç‡å€¼
```

#### ç»§æ‰¿çš„æ–¹æ³•ï¼ˆæ¥è‡ªBaseIDTaskï¼‰

**`process_sample(data_array: np.ndarray, metadata: Dict) -> np.ndarray`**
- ä¿¡å·é¢„å¤„ç†ï¼ˆæ ‡å‡†åŒ–ã€æˆªæ–­ç­‰ï¼‰

**`create_windows(data: np.ndarray, strategy: str, num_window: int) -> List[np.ndarray]`**
- çª—å£åŒ–é‡‡æ ·ï¼ˆæ”¯æŒrandom/sequential/evenly_spacedç­–ç•¥ï¼‰

### é…ç½®ç³»ç»ŸAPI

```python
from src.configs import load_config

# 1. åŸºç¡€é…ç½®åŠ è½½
config = load_config("configs/id_contrastive/production.yaml")

# 2. é¢„è®¾é…ç½® + å‚æ•°è¦†ç›–
config = load_config("contrastive_id_preset", {
    "task.temperature": 0.05,
    "trainer.epochs": 100
})

# 3. é“¾å¼é…ç½®æ„å»º
config = (load_config("base_config")
          .copy()
          .update({"data.batch_size": 64})
          .update_from_file("overrides.yaml"))

# 4. æ¡ä»¶é…ç½®
if torch.cuda.is_available():
    config.update({"trainer.accelerator": "gpu", "trainer.precision": 16})
else:
    config.update({"trainer.accelerator": "cpu", "trainer.precision": 32})
```

### å·¥å‚ç³»ç»ŸAPI

```python
# ä»»åŠ¡å·¥å‚
from src.task_factory import create_task
task = create_task("pretrain", "contrastive_id", 
                   network, data_config, model_config, 
                   task_config, trainer_config, env_config, metadata)

# æ•°æ®å·¥å‚  
from src.data_factory import create_data_loader
dataloader = create_data_loader("id", "ID_dataset", data_config, metadata)

# æ¨¡å‹å·¥å‚
from src.model_factory import create_model
network = create_model("ISFM", "M_01_ISFM", model_config)
```

## æ€§èƒ½ä¼˜åŒ–

### è®¡ç®—èµ„æºä¼˜åŒ–

#### GPUå†…å­˜ç®¡ç†

```python
# åŠ¨æ€å†…å­˜åˆ†é…ç­–ç•¥
def optimize_memory_config(available_memory_gb):
    """æ ¹æ®å¯ç”¨GPUå†…å­˜åŠ¨æ€è°ƒæ•´é…ç½®"""
    
    if available_memory_gb >= 24:  # RTX 4090, A100ç­‰
        return {
            "data.batch_size": 128,
            "model.d_model": 512,
            "trainer.precision": 16,
            "trainer.accumulate_grad_batches": 1
        }
    elif available_memory_gb >= 12:  # RTX 3080Ti, RTX 4080ç­‰
        return {
            "data.batch_size": 64,
            "model.d_model": 256,
            "trainer.precision": 16,
            "trainer.accumulate_grad_batches": 2
        }
    elif available_memory_gb >= 8:  # RTX 3070, RTX 4060Tiç­‰
        return {
            "data.batch_size": 32,
            "model.d_model": 256,
            "trainer.precision": 16,
            "trainer.accumulate_grad_batches": 4
        }
    else:  # < 8GB
        return {
            "data.batch_size": 16,
            "model.d_model": 128,
            "trainer.precision": 16,
            "trainer.accumulate_grad_batches": 8
        }

# ä½¿ç”¨ç¤ºä¾‹
import torch
gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
memory_config = optimize_memory_config(gpu_memory)
config.update(memory_config)
```

#### CPUä¼˜åŒ–

```python
# CPUèµ„æºé…ç½®ä¼˜åŒ–
import os
import psutil

def optimize_cpu_config():
    """ä¼˜åŒ–CPUç›¸å…³é…ç½®"""
    cpu_count = os.cpu_count()
    memory_gb = psutil.virtual_memory().total / (1024**3)
    
    return {
        "data.num_workers": min(cpu_count, 8),  # é¿å…è¿‡å¤šè¿›ç¨‹
        "data.pin_memory": True,                 # åŠ é€ŸGPUä¼ è¾“
        "data.persistent_workers": True,        # ä¿æŒworkerè¿›ç¨‹
        "trainer.enable_checkpointing": memory_gb > 16  # å¤§å†…å­˜æ—¶å¯ç”¨
    }
```

#### å¤šGPUæ‰©å±•

```python
# å¤šGPUè®­ç»ƒé…ç½®
def setup_multi_gpu_config():
    """é…ç½®å¤šGPUè®­ç»ƒ"""
    gpu_count = torch.cuda.device_count()
    
    if gpu_count > 1:
        return {
            "trainer.devices": list(range(gpu_count)),
            "trainer.strategy": "ddp",           # åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
            "trainer.sync_batchnorm": True,      # æ‰¹å½’ä¸€åŒ–åŒæ­¥
            "data.batch_size": 32 * gpu_count,   # æŒ‰GPUæ•°é‡ç¼©æ”¾æ‰¹é‡
            "task.lr": 1e-3 * gpu_count,        # çº¿æ€§ç¼©æ”¾å­¦ä¹ ç‡
        }
    else:
        return {"trainer.devices": 1}

# åº”ç”¨å¤šGPUé…ç½®
multi_gpu_config = setup_multi_gpu_config()
config.update(multi_gpu_config)
```

### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–

#### æ•°æ®I/Oä¼˜åŒ–

```python
# æ•°æ®åŠ è½½æ€§èƒ½è°ƒä¼˜
def optimize_dataloader_config(dataset_size, signal_length):
    """æ ¹æ®æ•°æ®ç‰¹å¾ä¼˜åŒ–æ•°æ®åŠ è½½"""
    
    # åŸºäºæ•°æ®é›†å¤§å°è°ƒæ•´ç¼“å­˜ç­–ç•¥
    if dataset_size < 10000:  # å°æ•°æ®é›†
        prefetch_factor = 4
        num_workers = 2
    elif dataset_size < 100000:  # ä¸­ç­‰æ•°æ®é›†  
        prefetch_factor = 8
        num_workers = 4
    else:  # å¤§æ•°æ®é›†
        prefetch_factor = 16
        num_workers = 8
    
    # åŸºäºä¿¡å·é•¿åº¦è°ƒæ•´é¢„å¤„ç†å¹¶è¡Œåº¦
    if signal_length > 50000:  # é•¿ä¿¡å·
        persistent_workers = True
        pin_memory = True
    else:  # çŸ­ä¿¡å·
        persistent_workers = False
        pin_memory = False
        
    return {
        "data.num_workers": num_workers,
        "data.prefetch_factor": prefetch_factor,
        "data.persistent_workers": persistent_workers,
        "data.pin_memory": pin_memory
    }
```

#### æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–

```python
# PyTorch 2.0+ ç¼–è¯‘ä¼˜åŒ–
def enable_torch_compile(model, mode="default"):
    """å¯ç”¨PyTorchç¼–è¯‘ä¼˜åŒ–"""
    
    # ç¼–è¯‘æ¨¡å¼é€‰æ‹©
    compile_modes = {
        "default": {"mode": "default"},      # å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜
        "reduce-overhead": {"mode": "reduce-overhead"},  # å‡å°‘å¼€é”€
        "max-autotune": {"mode": "max-autotune"}         # æœ€å¤§ä¼˜åŒ–
    }
    
    if hasattr(torch, 'compile') and torch.cuda.is_available():
        compiled_model = torch.compile(model, **compile_modes[mode])
        return compiled_model
    else:
        return model

# åœ¨è®­ç»ƒä¸­ä½¿ç”¨
task.network = enable_torch_compile(task.network, mode="reduce-overhead")
```

### æ”¶æ•›æ€§ä¼˜åŒ–

#### å­¦ä¹ ç‡è°ƒåº¦ç­–ç•¥

```python
# è‡ªé€‚åº”å­¦ä¹ ç‡è°ƒåº¦
class ContrastiveOptimizer:
    def __init__(self, model_parameters, config):
        self.config = config
        
        # ä¼˜åŒ–å™¨é€‰æ‹©
        if config.task.optimizer == "adamw":
            self.optimizer = torch.optim.AdamW(
                model_parameters,
                lr=config.task.lr,
                weight_decay=config.task.weight_decay,
                betas=(0.9, 0.999),
                eps=1e-8
            )
        elif config.task.optimizer == "lion":  # æ–°å…´ä¼˜åŒ–å™¨
            from lion_pytorch import Lion
            self.optimizer = Lion(
                model_parameters,
                lr=config.task.lr,
                weight_decay=config.task.weight_decay
            )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = self._create_scheduler()
    
    def _create_scheduler(self):
        if self.config.task.lr_scheduler == "cosine":
            return torch.optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=self.config.trainer.epochs,
                eta_min=self.config.task.lr * 0.01
            )
        elif self.config.task.lr_scheduler == "onecycle":
            return torch.optim.lr_scheduler.OneCycleLR(
                self.optimizer,
                max_lr=self.config.task.lr,
                total_steps=self.config.trainer.epochs,
                pct_start=0.1,  # 10%æ—¶é—´é¢„çƒ­
                anneal_strategy='cos'
            )
        else:
            return None
```

#### æŸå¤±å‡½æ•°æ”¹è¿›

```python
# æ”¹è¿›çš„InfoNCEå®ç°
class ImprovedInfoNCE(nn.Module):
    def __init__(self, temperature=0.07, use_cosine_sim=True, 
                 hard_negative_weight=0.0):
        super().__init__()
        self.temperature = temperature
        self.use_cosine_sim = use_cosine_sim
        self.hard_negative_weight = hard_negative_weight
    
    def forward(self, anchor, positive, negatives=None):
        batch_size = anchor.size(0)
        
        if self.use_cosine_sim:
            # ä½™å¼¦ç›¸ä¼¼åº¦
            anchor = F.normalize(anchor, dim=1)
            positive = F.normalize(positive, dim=1)
            
            # æ­£æ ·æœ¬ç›¸ä¼¼åº¦
            pos_sim = torch.sum(anchor * positive, dim=1, keepdim=True)
            
            # è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦ï¼ˆæ‰¹æ¬¡å†…å…¶ä»–æ ·æœ¬ï¼‰
            neg_sim = torch.mm(anchor, positive.t())
            # ç§»é™¤å¯¹è§’çº¿ï¼ˆæ­£æ ·æœ¬ï¼‰
            neg_sim = neg_sim.masked_fill(
                torch.eye(batch_size, device=anchor.device).bool(), 
                float('-inf')
            )
            
            # åˆå¹¶æ­£è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦
            all_sim = torch.cat([pos_sim, neg_sim], dim=1) / self.temperature
            
        # InfoNCEæŸå¤±
        labels = torch.zeros(batch_size, device=anchor.device, dtype=torch.long)
        loss = F.cross_entropy(all_sim, labels)
        
        # å›°éš¾è´Ÿæ ·æœ¬åŠ æƒï¼ˆå¯é€‰ï¼‰
        if self.hard_negative_weight > 0 and negatives is not None:
            hard_neg_loss = self._compute_hard_negative_loss(anchor, negatives)
            loss = loss + self.hard_negative_weight * hard_neg_loss
            
        return loss
```

### è´¨é‡ç›‘æ§ä¸åˆ†æ

#### å®æ—¶è´¨é‡ç›‘æ§

```python
# è®­ç»ƒè´¨é‡ç›‘æ§å›è°ƒ
class ContrastiveQualityMonitor(pl.Callback):
    def __init__(self, monitor_frequency=100):
        super().__init__()
        self.monitor_frequency = monitor_frequency
        self.step_count = 0
        
    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        self.step_count += 1
        
        if self.step_count % self.monitor_frequency == 0:
            # ç›‘æ§ç‰¹å¾è´¨é‡
            self._monitor_feature_quality(pl_module, batch)
            
            # ç›‘æ§æ¢¯åº¦å¥åº·åº¦
            self._monitor_gradient_health(pl_module)
            
            # ç›‘æ§ç›¸ä¼¼åº¦åˆ†å¸ƒ
            self._monitor_similarity_distribution(pl_module, batch)
    
    def _monitor_feature_quality(self, model, batch):
        """ç›‘æ§ç‰¹å¾è¡¨ç¤ºè´¨é‡"""
        with torch.no_grad():
            anchor_feat = model.network(batch['anchor'])
            positive_feat = model.network(batch['positive'])
            
            # ç‰¹å¾èŒƒæ•°
            anchor_norm = torch.norm(anchor_feat, dim=1).mean()
            positive_norm = torch.norm(positive_feat, dim=1).mean()
            
            model.log("monitor/anchor_feat_norm", anchor_norm)
            model.log("monitor/positive_feat_norm", positive_norm)
            
            # ç‰¹å¾ç›¸ä¼¼åº¦ç»Ÿè®¡
            cosine_sim = F.cosine_similarity(anchor_feat, positive_feat)
            model.log("monitor/positive_pair_similarity", cosine_sim.mean())
            model.log("monitor/positive_pair_similarity_std", cosine_sim.std())
    
    def _monitor_gradient_health(self, model):
        """ç›‘æ§æ¢¯åº¦å¥åº·åº¦"""
        total_norm = 0.0
        param_count = 0
        
        for p in model.parameters():
            if p.grad is not None:
                param_norm = p.grad.data.norm(2)
                total_norm += param_norm.item() ** 2
                param_count += 1
        
        if param_count > 0:
            total_norm = total_norm ** (1. / 2)
            model.log("monitor/gradient_norm", total_norm)
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†PHM-Vibench ContrastiveIDé¢„è®­ç»ƒä»»åŠ¡çš„å®Œæ•´ä½¿ç”¨æŒ‡å—ï¼Œæ¶µç›–äº†ï¼š

**ğŸš€ å¿«é€Ÿå¼€å§‹**
- 4ç§é…ç½®åœºæ™¯ï¼šè°ƒè¯•ã€ç”Ÿäº§ã€æ¶ˆèã€è·¨æ•°æ®é›†
- å³å¼€å³ç”¨çš„å‘½ä»¤è¡Œç¤ºä¾‹
- æ ¸å¿ƒæ¦‚å¿µæ¸…æ™°è¯´æ˜

**âš™ï¸ é…ç½®è¯¦è§£** 
- å®Œæ•´å‚æ•°è¡¨æ ¼ï¼ŒåŒ…å«è°ƒä¼˜å»ºè®®
- ä¸åŒåœºæ™¯çš„æœ€ä½³å®è·µé…ç½®
- ç¡¬ä»¶èµ„æºé€‚é…ç­–ç•¥

**ğŸ”„ å®éªŒå·¥ä½œæµ**
- æ ‡å‡†åŒ–çš„å®éªŒæµç¨‹
- æ¶ˆèå®éªŒè‡ªåŠ¨åŒ–è„šæœ¬
- è·¨æ•°æ®é›†æ³›åŒ–è¯„ä¼°

**ğŸ”§ é›†æˆæŒ‡å—**
- ä¸PHM-Vibenchå·¥å‚ç³»ç»Ÿé›†æˆ
- Pipeline_IDæ— ç¼å¯¹æ¥
- ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæµç¨‹

**ğŸ” æ•…éšœæ’é™¤**
- å¸¸è§é”™è¯¯è¯Šæ–­ä¸è§£å†³
- æ€§èƒ½ç›‘æ§å·¥å…·
- æ”¶æ•›æ€§åˆ†ææ–¹æ³•

**ğŸ¯ é«˜çº§ç”¨æ³•**
- æ‰¹é‡å®éªŒç®¡ç†
- è¶…å‚æ•°è‡ªåŠ¨è°ƒä¼˜
- ç‰¹å¾è´¨é‡åˆ†æ

**ğŸ“Š æ€§èƒ½ä¼˜åŒ–**
- å†…å­˜ã€è®¡ç®—ã€I/Oå…¨æ–¹ä½ä¼˜åŒ–
- å¤šGPUæ‰©å±•ç­–ç•¥
- å®æ—¶è´¨é‡ç›‘æ§

è¯¥æ¡†æ¶ä¸ºå·¥ä¸šè®¾å¤‡æŒ¯åŠ¨ä¿¡å·åˆ†ææä¾›äº†å¼ºå¤§çš„å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒèƒ½åŠ›ï¼Œæ”¯æŒä»ç ”ç©¶æ¢ç´¢åˆ°ç”Ÿäº§éƒ¨ç½²çš„å…¨æµç¨‹éœ€æ±‚ã€‚é€šè¿‡æœ¬æŒ‡å—ï¼Œç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆå¯ä»¥é«˜æ•ˆåœ°å¼€å±•ç›¸å…³å·¥ä½œï¼Œè·å¾—é«˜è´¨é‡çš„ä¿¡å·è¡¨å¾ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚

**æŠ€æœ¯ç‰¹è‰²**:
- âœ… **å³æ’å³ç”¨**: é…ç½®é©±åŠ¨ï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
- âœ… **é«˜åº¦å¯æ‰©å±•**: æ”¯æŒ30+å·¥ä¸šæ•°æ®é›†
- âœ… **æ€§èƒ½ä¼˜åŒ–**: GPUå†…å­˜è‡ªé€‚åº”ï¼Œå¤šGPUå¹¶è¡Œ
- âœ… **è´¨é‡ä¿è¯**: å®æ—¶ç›‘æ§ï¼Œè‡ªåŠ¨è¯Šæ–­
- âœ… **æ ‡å‡†æ¥å£**: å…¼å®¹PHM-Vibenchç”Ÿæ€ç³»ç»Ÿ

å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦æŠ€æœ¯æ”¯æŒï¼Œè¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£æˆ–æäº¤Issueã€‚