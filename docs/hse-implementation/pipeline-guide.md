# HSE Pipelineä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•ä½¿ç”¨HSE Industrial Contrastive Learning pipelineè¿›è¡Œå·¥ä¸šæŒ¯åŠ¨ä¿¡å·åˆ†æã€‚æ¶µç›–ä»ç¯å¢ƒè®¾ç½®åˆ°ç”Ÿäº§å®éªŒçš„å®Œæ•´æµç¨‹ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# 1. æ¿€æ´»condaç¯å¢ƒ
conda activate P

# 2. éªŒè¯å…³é”®ä¾èµ–
python -c "import wandb, swanlab; print('âœ… wandbå’Œswanlabå·²å®‰è£…')"

# 3. éªŒè¯æ•°æ®ç›®å½•
ls data/  # ç¡®ä¿åŒ…å«metadataæ–‡ä»¶å’ŒH5æ•°æ®æ–‡ä»¶
```

### 2. åŸºç¡€éªŒè¯

```bash
# è¿è¡Œåˆæˆæ•°æ®æ¼”ç¤ºï¼ˆæ¨èé¦–æ¬¡ä½¿ç”¨ï¼‰
python scripts/hse_synthetic_demo.py

# é¢„æœŸè¾“å‡ºï¼š
# âœ… ç³»ç»Ÿæç¤ºç¼–ç : æˆåŠŸ
# âœ… æ ·æœ¬æç¤ºç¼–ç : æˆåŠŸ
# âœ… æç¤ºèåˆ: æˆåŠŸ
# âœ… å¯¹æ¯”å­¦ä¹ : æˆåŠŸ (å‡†ç¡®åº¦æå‡: 14.3%)
# âœ… éªŒè¯æµ‹è¯•: æˆåŠŸ (å†…å­˜: <0.1GB, é€Ÿåº¦: >1400 samples/sec)
```

### 3. Pipelineé›†æˆæµ‹è¯•

```bash
# è¿è¡ŒPipeline_03é›†æˆæµ‹è¯•
python scripts/test_pipeline03_integration.py

# é¢„æœŸè¾“å‡ºï¼š
# âœ… é…ç½®åŠ è½½æµ‹è¯•: é€šè¿‡
# âœ… ç»„ä»¶é›†æˆæµ‹è¯•: é€šè¿‡
# âœ… æ£€æŸ¥ç‚¹å¤„ç†æµ‹è¯•: é€šè¿‡
# æµ‹è¯•æˆåŠŸç‡: 55.6% (5/9 tests passing)
```

## ğŸ›ï¸ Pipelineé€‰æ‹©

### Pipeline_03: å¤šä»»åŠ¡é¢„è®­ç»ƒå¾®è°ƒ

**é€‚ç”¨åœºæ™¯**:
- è·¨åŸŸå·¥ä¸šä¿¡å·åˆ†æ
- å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡
- éœ€è¦å¼ºæ³›åŒ–èƒ½åŠ›çš„åº”ç”¨

**æ ¸å¿ƒç‰¹æ€§**:
- ä¸¤é˜¶æ®µè®­ç»ƒ: é¢„è®­ç»ƒ â†’ å¾®è°ƒ
- æç¤ºå¼•å¯¼çš„ç‰¹å¾å­¦ä¹ 
- å¤šä»»åŠ¡è”åˆè®­ç»ƒ

```bash
# ä½¿ç”¨Pipeline_03è¿è¡ŒHSEå®éªŒ
python scripts/run_hse_prompt_pipeline03.py

# æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶æ–¹å¼
python main.py --pipeline Pipeline_03 \
  --config configs/pipeline_03/hse_prompt_multitask_config.yaml
```

### Pipeline_01: æ ‡å‡†è®­ç»ƒ

**é€‚ç”¨åœºæ™¯**:
- å•åŸŸä»»åŠ¡
- åŸºçº¿å¯¹æ¯”å®éªŒ
- å¿«é€ŸéªŒè¯

```bash
# åŸºçº¿å®éªŒç¤ºä¾‹
python main.py --config configs/baseline/cwru_baseline.yaml
```

## ğŸ“Š å®éªŒé…ç½®

### ä¸»é…ç½®æ–‡ä»¶

#### 1. HSEå¤šä»»åŠ¡é…ç½®
**æ–‡ä»¶**: `configs/pipeline_03/hse_prompt_multitask_config.yaml`

```yaml
# æ ¸å¿ƒé…ç½®é¡¹
pipeline: "Pipeline_03_multitask_pretrain_finetune"

data:
  dataset_names: ["CWRU", "XJTU", "THU", "Ottawa", "JNU"]  # 5ä¸ªæ•°æ®é›†è”åˆè®­ç»ƒ
  unified_loading: true

model:
  backbone:
    name: "B_11_MomentumEncoder"
    base_encoder: "E_01_HSE_v2"
  task_head:
    name: "H_10_ProjectionHead"

task:
  task_type: "hse_contrastive"
  loss_type: "infonce"

trainer:
  max_epochs: 50
  batch_size: 32
  learning_rate: 1e-4
```

#### 2. æ¶ˆèç ”ç©¶é…ç½®

**ç›®å½•**: `configs/pipeline_03/ablation/`

```bash
# æ— æç¤ºåŸºçº¿
configs/pipeline_03/ablation/hse_no_prompt_baseline.yaml

# ä»…ç³»ç»Ÿæç¤º
configs/pipeline_03/ablation/hse_system_prompt_only.yaml

# ä»…æ ·æœ¬æç¤º
configs/pipeline_03/ablation/hse_sample_prompt_only.yaml
```

#### 3. HSEå¯¹æ¯”å­¦ä¹ æ¼”ç¤º

**ç›®å½•**: `configs/demo/HSE_Contrastive/`

```bash
# é«˜å¯¹æ¯”åº¦å®éªŒ
configs/demo/HSE_Contrastive/high_contrast.yaml

# è·¨æ•°æ®é›†åŸŸæ³›åŒ–
configs/demo/HSE_Contrastive/hse_cddg.yaml

# æç¤ºèåˆæ¶ˆè
configs/demo/HSE_Contrastive/hse_prompt_ablation_fusion.yaml
```

## ğŸ¯ ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹

### é˜¶æ®µ1: å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ

```bash
# 1. é…ç½®é¢„è®­ç»ƒå‚æ•°
vim configs/demo/HSE_Contrastive/hse_prompt_pretrain.yaml

# å…³é”®é…ç½®
stage1:
  epochs: 100
  learning_rate: 1e-3
  task_type: "contrastive"
  datasets: ["CWRU", "XJTU", "THU", "Ottawa", "JNU"]

# 2. å¯åŠ¨é¢„è®­ç»ƒ
python scripts/run_hse_prompt_pipeline03.py \
  --stage pretrain \
  --config configs/demo/HSE_Contrastive/hse_prompt_pretrain.yaml
```

### é˜¶æ®µ2: ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ

```bash
# 1. é…ç½®å¾®è°ƒå‚æ•°
vim configs/demo/HSE_Contrastive/hse_prompt_finetune.yaml

# å…³é”®é…ç½®
stage2:
  epochs: 20
  learning_rate: 1e-4
  task_type: "classification"
  freeze_backbone: false
  pretrained_path: "save/stage1_checkpoint.pth"

# 2. å¯åŠ¨å¾®è°ƒ
python scripts/run_hse_prompt_pipeline03.py \
  --stage finetune \
  --config configs/demo/HSE_Contrastive/hse_prompt_finetune.yaml
```

## ğŸ” æç¤ºç³»ç»Ÿé…ç½®

### 1. ç³»ç»Ÿçº§æç¤º

```yaml
system_prompt:
  # æ•°æ®é›†æç¤º
  dataset_embedding:
    vocab: ["CWRU", "XJTU", "THU", "Ottawa", "JNU"]
    embedding_dim: 32

  # åŸŸæç¤º
  domain_embedding:
    vocab: ["bearing", "gearbox", "motor", "pump"]
    embedding_dim: 32

  # å·¥å†µæç¤º
  condition_embedding:
    vocab: ["normal", "fault", "degraded"]
    embedding_dim: 16
```

### 2. æ ·æœ¬çº§æç¤º

```yaml
sample_prompt:
  # é‡‡æ ·ç‡æç¤º
  sample_rate_embedding:
    min_rate: 1000
    max_rate: 50000
    embedding_dim: 16

  # åºåˆ—é•¿åº¦æç¤º
  sequence_length_embedding:
    min_length: 512
    max_length: 4096
    embedding_dim: 16

  # å™ªå£°æ°´å¹³æç¤º
  noise_level_embedding:
    levels: [0.0, 0.1, 0.2, 0.5]
    embedding_dim: 8
```

### 3. æç¤ºèåˆç­–ç•¥

```yaml
prompt_fusion:
  strategy: "attention"  # attention/concat/gate

  attention_config:
    num_heads: 8
    hidden_dim: 128
    dropout: 0.1

  output_dim: 64
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### 1. å®éªŒè·Ÿè¸ª

```python
# WandBé›†æˆ
wandb.init(
    project="hse-industrial-contrastive",
    name=f"hse-{dataset}-{timestamp}",
    config=config
)

# SwanLabé›†æˆ
swanlab.init(
    project="HSE-Prompt-Learning",
    experiment_name=f"multi-task-{timestamp}"
)
```

### 2. æŒ‡æ ‡ç›‘æ§

å…³é”®ç›‘æ§æŒ‡æ ‡:
- **è®­ç»ƒæŸå¤±**: å¯¹æ¯”å­¦ä¹ æŸå¤±è¶‹åŠ¿
- **éªŒè¯å‡†ç¡®åº¦**: å„æ•°æ®é›†ä¸Šçš„åˆ†ç±»å‡†ç¡®åº¦
- **å†…å­˜ä½¿ç”¨**: å³°å€¼GPUå†…å­˜å ç”¨
- **è®­ç»ƒé€Ÿåº¦**: samples/second
- **æ¢¯åº¦èŒƒæ•°**: è®­ç»ƒç¨³å®šæ€§æŒ‡æ ‡

### 3. è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ

```bash
# ç”Ÿæˆå®éªŒæŠ¥å‘Š
python script/unified_metric/collect_results.py \
  --experiment_dir save/hse_experiment_20250915 \
  --output_format markdown

# è¾“å‡ºä½ç½®
# reports/hse_experiment_report_20250915.md
```

## ğŸ› ï¸ é«˜çº§é…ç½®

### 1. å†…å­˜ä¼˜åŒ–

```yaml
# æ··åˆç²¾åº¦è®­ç»ƒ
trainer:
  precision: 16

# æ¢¯åº¦æ£€æŸ¥ç‚¹
model:
  gradient_checkpointing: true

# æ•°æ®åŠ è½½ä¼˜åŒ–
data:
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2
```

### 2. åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# å¤šGPUè®­ç»ƒ
python -m torch.distributed.launch \
  --nproc_per_node=4 \
  scripts/run_hse_prompt_pipeline03.py \
  --config configs/pipeline_03/hse_prompt_multitask_config.yaml
```

### 3. è¶…å‚æ•°è°ƒä¼˜

```yaml
# Grid Searché…ç½®
hyperparameter_search:
  learning_rate: [1e-5, 1e-4, 1e-3]
  batch_size: [16, 32, 64]
  temperature: [0.05, 0.1, 0.2]
  momentum: [0.9, 0.99, 0.999]
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. ConfigWrapperå…¼å®¹æ€§é—®é¢˜
```bash
# ç—‡çŠ¶: TypeError: 'ConfigWrapper' object is not iterable
# è§£å†³: ç¡®ä¿é…ç½®æ›´æ–°ä½¿ç”¨ConfigWrapper.update()æ–¹æ³•
config = load_config('base_config')
config.update({'model.backbone.name': 'new_value'})
```

#### 2. H5æ•°æ®åŠ è½½å¤±è´¥
```bash
# ç—‡çŠ¶: No such file or directory: '*.h5'
# è§£å†³: æ£€æŸ¥æ•°æ®ç›®å½•é…ç½®
export DATA_DIR=/path/to/your/data
python scripts/check_data_paths.py
```

#### 3. å†…å­˜ä¸è¶³
```bash
# ç—‡çŠ¶: RuntimeError: CUDA out of memory
# è§£å†³: è°ƒæ•´batch_sizeæˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
trainer:
  batch_size: 16  # å‡å°batch size
  accumulate_grad_batches: 2  # æ¢¯åº¦ç´¯ç§¯
```

#### 4. seabornå¯¼å…¥é”™è¯¯
```bash
# ç—‡çŠ¶: ModuleNotFoundError: No module named 'seaborn'
# è§£å†³: å®‰è£…å¯é€‰ä¾èµ–æˆ–ç¦ç”¨å¯è§†åŒ–
pip install seaborn
# æˆ–åœ¨ä»£ç ä¸­å·²åšå®¹é”™å¤„ç†ï¼Œå¯å¿½ç•¥æ­¤è­¦å‘Š
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æœŸæœ›æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | å½“å‰çŠ¶æ€ |
|------|--------|----------|
| å†…å­˜ä½¿ç”¨ | < 1GB | âœ… < 0.1GB |
| è®­ç»ƒé€Ÿåº¦ | > 1000 samples/sec | âœ… > 1400 samples/sec |
| éªŒè¯æˆåŠŸç‡ | > 80% | âš ï¸ 55.6% |
| å‡†ç¡®åº¦æå‡ | > 10% | âœ… 14.3% |

### åŸºå‡†æµ‹è¯•å‘½ä»¤

```bash
# è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•
python tests/performance/prompt_benchmarks.py

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
python scripts/generate_benchmark_report.py \
  --results benchmark_results/ \
  --output benchmark_report.md
```

## ğŸ“ å®éªŒè®°å½•

### å®éªŒå‘½åè§„èŒƒ

```
å®éªŒåç§°æ ¼å¼: hse_{dataset}_{task}_{timestamp}
ç¤ºä¾‹: hse_cwru_classification_20250915_1430
```

### ç»“æœä¿å­˜ç»“æ„

```
save/
â”œâ”€â”€ hse_cwru_classification_20250915_1430/
â”‚   â”œâ”€â”€ checkpoints/           # æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ logs/                  # è®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ metrics.json           # æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€â”€ config.yaml           # å®éªŒé…ç½®
â”‚   â””â”€â”€ figures/              # å¯è§†åŒ–å›¾è¡¨
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å®éªŒè®¾è®¡
- å§‹ç»ˆå…ˆè¿è¡Œåˆæˆæ•°æ®éªŒè¯
- ä½¿ç”¨OneEpochValidatorå¿«é€Ÿæ£€æŸ¥é…ç½®
- å¯¹æ¯”åŸºçº¿å’ŒHSEæ–¹æ³•çš„æ€§èƒ½

### 2. é…ç½®ç®¡ç†
- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†é…ç½®æ–‡ä»¶
- ä¸ºæ¯ä¸ªå®éªŒåˆ›å»ºç‹¬ç«‹çš„é…ç½®æ–‡ä»¶
- è®°å½•å…³é”®è¶…å‚æ•°çš„é€‰æ‹©ç†ç”±

### 3. ç»“æœåˆ†æ
- å…³æ³¨è·¨åŸŸæ³›åŒ–æ€§èƒ½
- åˆ†æä¸åŒæç¤ºç­–ç•¥çš„å½±å“
- å®šæœŸç”Ÿæˆæ€§èƒ½å¯¹æ¯”æŠ¥å‘Š

---

*æœ¬æŒ‡å—æ¶µç›–äº†HSE pipelineçš„å®Œæ•´ä½¿ç”¨æµç¨‹ã€‚å¦‚é‡é—®é¢˜ï¼Œè¯·å‚è€ƒ [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤) éƒ¨åˆ†æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚*