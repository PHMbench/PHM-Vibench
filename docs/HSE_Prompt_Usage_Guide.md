# HSE Promptå¼•å¯¼å¯¹æ¯”å­¦ä¹ ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

E_01_HSE_Prompt æ˜¯å¯¹åŽŸå§‹ E_01_HSE çš„é‡å¤§å‡çº§ï¼Œå®žçŽ°äº†**Prompt Feature + å¯¹æ¯”å­¦ä¹ **çš„åˆ›æ–°ç»“åˆã€‚é€šè¿‡å°†ç³»ç»Ÿmetadataä¿¡æ¯ç¼–ç ä¸ºå¯å­¦ä¹ çš„promptç‰¹å¾ï¼ŒæŒ‡å¯¼å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼Œå®žçŽ°æ›´å¥½çš„è·¨ç³»ç»Ÿæ³›åŒ–èƒ½åŠ›ã€‚

## æ ¸å¿ƒç‰¹æ€§

### ðŸš€ æ–¹æ³•åˆ›æ–°
- **ç³»ç»Ÿä¿¡æ¯PromptåŒ–**: å°†Dataset_idã€Domain_idã€Sample_rateç­‰è½¬åŒ–ä¸ºå¯å­¦ä¹ å‘é‡
- **å¤šå±‚çº§Promptè®¾è®¡**: ç³»ç»Ÿçº§ + æ ·æœ¬çº§ + æ•…éšœçº§ ä¸‰å±‚æ¬¡ç‰¹å¾èžåˆ
- **é€šç”¨å¯¹æ¯”å­¦ä¹ æ¡†æž¶**: æ”¯æŒä¸Žæ‰€æœ‰SOTAå¯¹æ¯”å­¦ä¹ ç®—æ³•ç»“åˆ
- **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**: é¢„è®­ç»ƒå­¦ä¹ é€šç”¨ç‰¹å¾ï¼Œå¾®è°ƒé€‚é…ä¸‹æ¸¸ä»»åŠ¡

### ðŸŽ¯ æŠ€æœ¯äº®ç‚¹
- **ä¸‰ç§èžåˆç­–ç•¥**: concatenation, cross-attention, adaptive gating
- **Promptå†»ç»“æœºåˆ¶**: é˜¶æ®µäºŒå¯å†»ç»“promptå®žçŽ°å¿«é€Ÿé€‚é…
- **å®Œå…¨å‘åŽå…¼å®¹**: ä¿ç•™åŽŸå§‹E_01_HSEæ‰€æœ‰åŠŸèƒ½
- **è‡ªé€‚åº”å¤„ç†**: æ”¯æŒæœ‰/æ— metadataçš„æ··åˆä½¿ç”¨åœºæ™¯

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬é…ç½®

```yaml
# åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨æ–°çš„Promptå¼•å¯¼HSE
model:
  embedding: "E_01_HSE_Prompt"  # ä½¿ç”¨æ–°çš„Promptç‰ˆæœ¬
  
  # Promptç‰¹å¾é…ç½®
  prompt_dim: 128
  fusion_type: "attention"      # æˆ– "concat" / "gating"
  use_system_prompt: true       # Dataset_id, Domain_id
  use_sample_prompt: true       # Sample_rate, Channel  
  use_fault_prompt: true        # Label, Fault_level
  
  # è®­ç»ƒé˜¶æ®µæŽ§åˆ¶
  training_stage: "pretrain"    # æˆ– "finetune"
  freeze_prompt: false          # æ˜¯å¦å†»ç»“promptç‰¹å¾
```

### 2. ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹

#### é˜¶æ®µä¸€ï¼šå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ
```bash
# ä½¿ç”¨å¤šç³»ç»Ÿæ•°æ®è¿›è¡Œå¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒ
python main.py --config configs/demo/HSE_Contrastive/hse_prompt_pretrain.yaml
```

**é…ç½®è¦ç‚¹**:
- `training_stage: "pretrain"`
- `freeze_prompt: false` 
- ä½¿ç”¨å¤šæºåŸŸï¼š`source_domain_id: [1, 13, 19]`
- å¯ç”¨å¯¹æ¯”å­¦ä¹ ï¼š`contrast_weight: 0.15`

#### é˜¶æ®µäºŒï¼šä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒ
```bash
# å†»ç»“promptï¼Œå¾®è°ƒä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡
python main.py --config configs/demo/HSE_Contrastive/hse_prompt_finetune.yaml
```

**é…ç½®è¦ç‚¹**:
- `training_stage: "finetune"`
- `freeze_prompt: true`
- ç¦ç”¨å¯¹æ¯”å­¦ä¹ ï¼š`contrast_weight: 0.0`
- è¾ƒå°å­¦ä¹ çŽ‡ï¼š`lr: 1e-4`

## èžåˆç­–ç•¥è¯¦è§£

### 1. Concatenation (concat)
```python
# ç®€å•æ‹¼æŽ¥promptå’Œsignalç‰¹å¾
fused_feature = concat([signal_emb, expanded_prompt], dim=-1)
```
**ä¼˜ç‚¹**: è®¡ç®—ç®€å•ï¼Œå‚æ•°é‡å°‘  
**ç¼ºç‚¹**: å¯èƒ½å­˜åœ¨ç‰¹å¾å†²çª

### 2. Cross-Attention (attention) 
```python
# Signalç‰¹å¾attendåˆ°Promptç‰¹å¾
attended_signal = CrossAttention(signal_emb, prompt_emb)
fused_feature = signal_emb + attended_signal  # æ®‹å·®è¿žæŽ¥
```
**ä¼˜ç‚¹**: åŠ¨æ€èžåˆï¼Œæ•ˆæžœæœ€ä½³  
**ç¼ºç‚¹**: è®¡ç®—å¤æ‚åº¦è¾ƒé«˜

### 3. Adaptive Gating (gating)
```python
# è‡ªé€‚åº”é—¨æŽ§æœºåˆ¶
gate = sigmoid(gate_proj(prompt_emb))
fused_feature = gate * signal_emb + (1-gate) * transform_proj(prompt_emb)
```
**ä¼˜ç‚¹**: å¹³è¡¡äº†æ•ˆæžœå’Œæ•ˆçŽ‡  
**ç¼ºç‚¹**: éœ€è¦é¢å¤–çš„gateå‚æ•°

## æ¶ˆèžå®žéªŒæŒ‡å—

### è¿è¡Œæ¶ˆèžå®žéªŒ
```bash
# è¿è¡Œèžåˆç­–ç•¥æ¶ˆèžå®žéªŒ
python main.py --config configs/demo/HSE_Contrastive/hse_prompt_ablation_fusion.yaml
```

### å®žéªŒç»´åº¦

1. **èžåˆç­–ç•¥æ¶ˆèž**: concat vs attention vs gating
2. **Promptç»„ä»¶æ¶ˆèž**: ç³»ç»Ÿçº§ vs æ ·æœ¬çº§ vs æ•…éšœçº§
3. **Promptç»´åº¦æ¶ˆèž**: 64 vs 128 vs 256 vs 512
4. **è®­ç»ƒç­–ç•¥æ¶ˆèž**: é¢„è®­ç»ƒ vs ç«¯åˆ°ç«¯ vs å¾®è°ƒ

## APIä½¿ç”¨ç¤ºä¾‹

### Pythonä»£ç ç¤ºä¾‹

```python
import torch
from src.model_factory.ISFM.embedding.E_01_HSE import E_01_HSE_Prompt

# é…ç½®å‚æ•°
class Config:
    patch_size_L = 256
    patch_size_C = 1
    num_patches = 128
    output_dim = 1024
    prompt_dim = 128
    fusion_type = "attention"
    use_system_prompt = True
    use_sample_prompt = True
    use_fault_prompt = True
    training_stage = "pretrain"
    freeze_prompt = False

# åˆå§‹åŒ–æ¨¡åž‹
model = E_01_HSE_Prompt(Config())

# å‡†å¤‡è¾“å…¥æ•°æ®
batch_size, seq_len, channels = 4, 1024, 2
x = torch.randn(batch_size, seq_len, channels)
fs = 1000.0  # é‡‡æ ·é¢‘çŽ‡

# å‡†å¤‡ç³»ç»Ÿmetadata
metadata = [
    {'Dataset_id': 1, 'Domain_id': 5, 'Sample_rate': 1000.0, 'Label': 2},
    {'Dataset_id': 2, 'Domain_id': 3, 'Sample_rate': 2000.0, 'Label': 1},
    {'Dataset_id': 1, 'Domain_id': 7, 'Sample_rate': 1500.0, 'Label': 0},
    {'Dataset_id': 3, 'Domain_id': 2, 'Sample_rate': 1200.0, 'Label': 2}
]

# å‰å‘ä¼ æ’­
output, prompt = model(x, fs, metadata)

print(f"Signal embedding: {output.shape}")  # [4, 128, 1024]
print(f"Prompt embedding: {prompt.shape}")  # [4, 128]

# åˆ‡æ¢åˆ°å¾®è°ƒæ¨¡å¼
model.set_training_stage('finetune')
output_ft, prompt_ft = model(x, fs, metadata)
print(f"Finetune mode - Prompt gradients: {prompt_ft.requires_grad}")  # False
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å†…å­˜ä¼˜åŒ–
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼š`precision: 16`
- é€‚å½“å‡å°‘batch_sizeæˆ–num_patches
- åœ¨å¾®è°ƒé˜¶æ®µç¦ç”¨ä¸å¿…è¦çš„ç»„ä»¶

### 2. è®¡ç®—ä¼˜åŒ–
- attentionèžåˆç­–ç•¥è®¡ç®—é‡æœ€å¤§ï¼Œå¯è€ƒè™‘gatingç­–ç•¥
- é¢„è®­ç»ƒé˜¶æ®µå¯ä½¿ç”¨è¾ƒå¤§å­¦ä¹ çŽ‡ï¼Œå¾®è°ƒé˜¶æ®µä½¿ç”¨å°å­¦ä¹ çŽ‡
- å¯ç”¨gradient checkpointingèŠ‚çœæ˜¾å­˜

### 3. è¶…å‚æ•°å»ºè®®
```yaml
# æŽ¨èè¶…å‚æ•°é…ç½®
model:
  prompt_dim: 128              # å¹³è¡¡æ•ˆæžœå’Œæ•ˆçŽ‡
  fusion_type: "attention"     # æœ€ä½³æ•ˆæžœ
  
task:
  contrast_weight: 0.1-0.2     # å¯¹æ¯”æŸå¤±æƒé‡
  temperature: 0.07            # InfoNCEæ¸©åº¦
  lr: 5e-4 (pretrain)         # é¢„è®­ç»ƒå­¦ä¹ çŽ‡
  lr: 1e-4 (finetune)         # å¾®è°ƒå­¦ä¹ çŽ‡
```

## æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

1. **æ˜¾å­˜ä¸è¶³**
   ```bash
   # å‡å°‘batch_sizeæˆ–ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
   batch_size: 16
   accumulate_grad_batches: 2
   ```

2. **è®­ç»ƒä¸æ”¶æ•›**
   ```bash
   # æ£€æŸ¥å­¦ä¹ çŽ‡å’Œæƒé‡è¡°å‡
   lr: 1e-4
   weight_decay: 1e-4
   ```

3. **Promptç‰¹å¾æ²¡æœ‰å­¦åˆ°æœ‰æ•ˆä¿¡æ¯**
   ```bash
   # å¢žåŠ å¯¹æ¯”æŸå¤±æƒé‡æˆ–è°ƒæ•´æ¸©åº¦å‚æ•°
   contrast_weight: 0.2
   temperature: 0.05
   ```

4. **è·¨ç³»ç»Ÿæ³›åŒ–æ•ˆæžœä¸ä½³**
   ```bash
   # å¢žåŠ é¢„è®­ç»ƒè½®æ•°æˆ–ä½¿ç”¨æ›´å¤šæºåŸŸ
   epochs: 100
   source_domain_id: [1, 5, 6, 13, 19]
   ```

## å®žéªŒç»“æžœåˆ†æž

### å…³é”®æŒ‡æ ‡
- **è·¨ç³»ç»Ÿå‡†ç¡®çŽ‡**: ç›®æ ‡ > 85%
- **Promptç›¸ä¼¼åº¦**: åŒæ•…éšœä¸åŒç³»ç»Ÿ > 0.8ï¼Œå¼‚æ•…éšœ < 0.3
- **è®­ç»ƒæ•ˆçŽ‡**: å¾®è°ƒé˜¶æ®µæ”¶æ•› < 20 epochs
- **å†…å­˜ä½¿ç”¨**: å•GPU < 8GB

### å¯è§†åŒ–åˆ†æž
```python
# åˆ†æžpromptç‰¹å¾è´¨é‡
def analyze_prompt_quality(model, dataloader):
    prompts = []
    labels = []
    
    with torch.no_grad():
        for batch in dataloader:
            _, prompt = model(batch['signal'], batch['fs'], batch['metadata'])
            prompts.append(prompt)
            labels.append(batch['labels'])
    
    # t-SNEå¯è§†åŒ–
    import matplotlib.pyplot as plt
    from sklearn.manifold import TSNE
    
    tsne = TSNE(n_components=2)
    prompt_2d = tsne.fit_transform(torch.cat(prompts).cpu())
    
    plt.scatter(prompt_2d[:, 0], prompt_2d[:, 1], c=torch.cat(labels))
    plt.title('Prompt Feature Visualization')
    plt.show()
```

## è®ºæ–‡å®žéªŒæ”¯æŒ

### ICML/NeurIPS å®žéªŒè®¾ç½®
1. **åŸºçº¿å¯¹æ¯”**: ä¸Žä¼ ç»Ÿå¯¹æ¯”å­¦ä¹ æ–¹æ³•å¯¹æ¯”
2. **æ¶ˆèžç ”ç©¶**: ç³»ç»ŸåŒ–åˆ†æžå„ç»„ä»¶è´¡çŒ®
3. **è·¨æ•°æ®é›†éªŒè¯**: åœ¨5ä¸ªä¸åŒå·¥ä¸šæ•°æ®é›†ä¸ŠéªŒè¯é€šç”¨æ€§
4. **è®¡ç®—æ•ˆçŽ‡åˆ†æž**: FLOPsã€å‚æ•°é‡ã€è®­ç»ƒæ—¶é—´å¯¹æ¯”
5. **ç»Ÿè®¡æ˜¾è‘—æ€§**: på€¼ã€ç½®ä¿¡åŒºé—´ã€æ•ˆåº”é‡åˆ†æž

### å¯é‡çŽ°æ€§ä¿è¯
- å›ºå®šéšæœºç§å­ï¼š`seed: 42`
- ç‰ˆæœ¬é”å®šï¼šrequirements.txt
- å®Œæ•´é…ç½®ä¿å­˜ï¼šæ¯ä¸ªå®žéªŒè‡ªåŠ¨å¤‡ä»½config
- çŽ¯å¢ƒé…ç½®è®°å½•ï¼šcondaçŽ¯å¢ƒå¯¼å‡º

## åŽç»­å¼€å‘è®¡åˆ’

### v2.0 è§„åˆ’åŠŸèƒ½
- [ ] æ”¯æŒæ›´å¤šPromptç‰¹å¾ç±»åž‹ï¼ˆé¢‘åŸŸã€æ—¶é¢‘åŸŸï¼‰
- [ ] è‡ªé€‚åº”Promptç»´åº¦é€‰æ‹©
- [ ] å¤šæ¨¡æ€Promptèžåˆï¼ˆæŒ¯åŠ¨+å£°å­¦+æ¸©åº¦ï¼‰
- [ ] åœ¨çº¿Promptæ›´æ–°æœºåˆ¶
- [ ] åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–

---

**ä½œè€…**: PHM-Vibenchå›¢é˜Ÿ  
**ç‰ˆæœ¬**: v1.0  
**æ—¥æœŸ**: 2025å¹´1æœˆ  
**è”ç³»**: è¯¦è§CLAUDE.md