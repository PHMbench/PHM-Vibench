# ContrastiveIDTask æ•…éšœæ’é™¤æŒ‡å—

ContrastiveIDTaskå¸¸è§é—®é¢˜çš„è¯Šæ–­ä¸è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ å¿«é€Ÿè¯Šæ–­

### ç¯å¢ƒæ£€æŸ¥è„šæœ¬

è¿è¡Œæ­¤è„šæœ¬å¿«é€Ÿæ£€æŸ¥ç¯å¢ƒçŠ¶æ€ï¼š

```python
def diagnose_environment():
    """å®Œæ•´ç¯å¢ƒè¯Šæ–­"""
    print("ğŸ” ContrastiveIDTaskç¯å¢ƒè¯Šæ–­")
    print("="*50)

    # Pythonç¯å¢ƒ
    import sys
    print(f"Pythonç‰ˆæœ¬: {sys.version}")

    # PyTorchæ£€æŸ¥
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"   GPU {i}: {props.name}, {props.total_memory/1e9:.1f}GB")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")

    # æ ¸å¿ƒæ¨¡å—æ£€æŸ¥
    try:
        from src.configs import load_config
        print("âœ… é…ç½®ç³»ç»Ÿå¯ç”¨")
    except ImportError as e:
        print(f"âŒ é…ç½®ç³»ç»Ÿå¯¼å…¥å¤±è´¥: {e}")

    try:
        from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask
        print("âœ… ContrastiveIDTaskå¯ç”¨")
    except ImportError as e:
        print(f"âŒ ContrastiveIDTaskå¯¼å…¥å¤±è´¥: {e}")

    # é…ç½®æ–‡ä»¶æ£€æŸ¥
    from pathlib import Path
    config_files = [
        "configs/id_contrastive/debug.yaml",
        "configs/id_contrastive/production.yaml"
    ]

    for config_file in config_files:
        if Path(config_file).exists():
            print(f"âœ… {config_file}")
        else:
            print(f"âŒ {config_file} ä¸å­˜åœ¨")

if __name__ == "__main__":
    diagnose_environment()
```

## ğŸš¨ å¸¸è§é”™è¯¯è§£å†³

### 1. å†…å­˜ç›¸å…³é”™è¯¯

#### é”™è¯¯ï¼šCUDA out of memory

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**åŸå› **: GPUå†…å­˜ä¸è¶³ï¼Œé€šå¸¸ç”±æ‰¹é‡å¤§å°è¿‡å¤§æˆ–çª—å£å¤§å°è¿‡å¤§å¼•èµ·

**è§£å†³æ–¹æ¡ˆ**:

```yaml
# æ–¹æ¡ˆ1: å‡å°æ‰¹é‡å¤§å°
data:
  batch_size: 16  # ä»32æˆ–64å‡å°‘åˆ°16

# æ–¹æ¡ˆ2: å‡å°çª—å£å¤§å°
data:
  window_size: 512  # ä»1024å‡å°‘åˆ°512

# æ–¹æ¡ˆ3: ä½¿ç”¨CPUè®­ç»ƒ
trainer:
  devices: "cpu"
  precision: 32
```

**åŠ¨æ€è°ƒæ•´è„šæœ¬**:
```python
def adjust_batch_size_for_memory():
    """æ ¹æ®GPUå†…å­˜åŠ¨æ€è°ƒæ•´æ‰¹é‡å¤§å°"""
    import torch

    if torch.cuda.is_available():
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        if gpu_memory < 8:
            return 16  # å°äº8GBä½¿ç”¨å°æ‰¹é‡
        elif gpu_memory < 16:
            return 32  # 8-16GBä½¿ç”¨ä¸­ç­‰æ‰¹é‡
        else:
            return 64  # å¤§äº16GBä½¿ç”¨å¤§æ‰¹é‡
    else:
        return 8  # CPUæ¨¡å¼ä½¿ç”¨æœ€å°æ‰¹é‡
```

#### é”™è¯¯ï¼šç³»ç»Ÿå†…å­˜ä¸è¶³

**ç—‡çŠ¶**:
```
OSError: [Errno 12] Cannot allocate memory
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å‡å°‘æ•°æ®åŠ è½½è¿›ç¨‹
data:
  num_workers: 1  # ä»4å‡å°‘åˆ°1

# å¯ç”¨å»¶è¿ŸåŠ è½½
data:
  lazy_loading: true
```

### 2. æ•°æ®åŠ è½½é”™è¯¯

#### é”™è¯¯ï¼šæ–‡ä»¶æœªæ‰¾åˆ°

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'data/metadata_6_1.xlsx'
```

**è¯Šæ–­**:
```bash
# æ£€æŸ¥å½“å‰ç›®å½•
pwd

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -la data/
ls -la data/metadata_6_1.xlsx

# æ£€æŸ¥é…ç½®ä¸­çš„è·¯å¾„
python -c "
from src.configs import load_config
config = load_config('configs/id_contrastive/debug.yaml')
print(f'æ•°æ®ç›®å½•: {config.data.data_dir}')
print(f'å…ƒæ•°æ®æ–‡ä»¶: {config.data.metadata_file}')
"
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# ä¿®æ­£é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
data:
  data_dir: "/absolute/path/to/data"  # ä½¿ç”¨ç»å¯¹è·¯å¾„
  metadata_file: "metadata_6_1.xlsx"
```

#### é”™è¯¯ï¼šæ•°æ®æ ¼å¼ä¸åŒ¹é…

**ç—‡çŠ¶**:
```
ValueError: Expected tensor of shape [batch, seq_len, channels], got [batch, channels, seq_len]
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# åœ¨é…ç½®ä¸­æ·»åŠ æ•°æ®é¢„å¤„ç†
data:
  preprocessing:
    transpose_channels: true  # è½¬ç½®é€šé“ç»´åº¦
    normalize: true           # æ ‡å‡†åŒ–
```

### 3. æ¨¡å‹ç›¸å…³é”™è¯¯

#### é”™è¯¯ï¼šæ¨¡å‹ç»´åº¦ä¸åŒ¹é…

**ç—‡çŠ¶**:
```
RuntimeError: size mismatch, m1: [32 x 256], m2: [512 x 256]
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# ç¡®ä¿æ¨¡å‹è¾“å…¥ç»´åº¦ä¸æ•°æ®åŒ¹é…
model:
  input_dim: 1      # ä¸æ•°æ®é€šé“æ•°ä¸€è‡´
  d_model: 256      # ä¸é¢„æœŸç‰¹å¾ç»´åº¦ä¸€è‡´
```

#### é”™è¯¯ï¼šæ¨¡å‹æœªæ³¨å†Œ

**ç—‡çŠ¶**:
```
KeyError: 'contrastive_id' not found in task registry
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿å¯¼å…¥äº†æ¨¡å‹å®šä¹‰
from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask

# æ£€æŸ¥æ³¨å†ŒçŠ¶æ€
from src.task_factory import TASK_REGISTRY
print("å·²æ³¨å†Œä»»åŠ¡:", list(TASK_REGISTRY.keys()))
```

### 4. è®­ç»ƒç›¸å…³é”™è¯¯

#### é”™è¯¯ï¼šæŸå¤±ä¸ºNaN

**ç—‡çŠ¶**:
```
Training loss: nan
```

**åŸå› ä¸è§£å†³**:

1. **å­¦ä¹ ç‡è¿‡å¤§**:
```yaml
task:
  lr: 0.0001  # ä»0.001é™ä½åˆ°0.0001
```

2. **æ¸©åº¦å‚æ•°è¿‡å°**:
```yaml
task:
  temperature: 0.1  # ä»0.01å¢åŠ åˆ°0.1
```

3. **æ¢¯åº¦çˆ†ç‚¸**:
```yaml
trainer:
  gradient_clip_val: 1.0  # æ·»åŠ æ¢¯åº¦è£å‰ª
```

#### é”™è¯¯ï¼šè®­ç»ƒä¸æ”¶æ•›

**ç—‡çŠ¶**: æŸå¤±ä¸ä¸‹é™ï¼Œå‡†ç¡®ç‡å§‹ç»ˆå¾ˆä½

**è¯Šæ–­è„šæœ¬**:
```python
def diagnose_training_issues(model, dataloader):
    """è¯Šæ–­è®­ç»ƒé—®é¢˜"""
    model.eval()

    # æ£€æŸ¥æ•°æ®è´¨é‡
    batch = next(iter(dataloader))
    prepared_batch = model.prepare_batch(batch)

    print(f"æ‰¹é‡å½¢çŠ¶ - é”šç‚¹: {prepared_batch['anchor'].shape}")
    print(f"æ‰¹é‡å½¢çŠ¶ - æ­£æ ·æœ¬: {prepared_batch['positive'].shape}")

    # æ£€æŸ¥ç‰¹å¾åˆ†å¸ƒ
    with torch.no_grad():
        z_anchor = model.model(prepared_batch['anchor'])
        z_positive = model.model(prepared_batch['positive'])

        print(f"ç‰¹å¾å‡å€¼ - é”šç‚¹: {z_anchor.mean().item():.4f}")
        print(f"ç‰¹å¾æ ‡å‡†å·® - é”šç‚¹: {z_anchor.std().item():.4f}")
        print(f"ç‰¹å¾å‡å€¼ - æ­£æ ·æœ¬: {z_positive.mean().item():.4f}")
        print(f"ç‰¹å¾æ ‡å‡†å·® - æ­£æ ·æœ¬: {z_positive.std().item():.4f}")

        # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†å¸ƒ
        sim_matrix = torch.mm(F.normalize(z_anchor, dim=1),
                              F.normalize(z_positive, dim=1).t())
        pos_sim = torch.diag(sim_matrix).mean()
        neg_sim = (sim_matrix.sum() - torch.diag(sim_matrix).sum()) / (sim_matrix.numel() - sim_matrix.size(0))

        print(f"æ­£æ ·æœ¬å¹³å‡ç›¸ä¼¼åº¦: {pos_sim.item():.4f}")
        print(f"è´Ÿæ ·æœ¬å¹³å‡ç›¸ä¼¼åº¦: {neg_sim.item():.4f}")
```

**è§£å†³æ–¹æ¡ˆ**:

1. **è°ƒæ•´æ¸©åº¦å‚æ•°**:
```yaml
task:
  temperature: 0.07  # å°è¯•0.05, 0.1, 0.2
```

2. **å¢åŠ æ‰¹é‡å¤§å°**:
```yaml
data:
  batch_size: 64  # æ›´å¤šè´Ÿæ ·æœ¬
```

3. **æ£€æŸ¥æ•°æ®é¢„å¤„ç†**:
```yaml
data:
  normalization: true  # ç¡®ä¿æ•°æ®æ ‡å‡†åŒ–
  window_sampling_strategy: "random"  # ç¡®ä¿éšæœºæ€§
```

### 5. é…ç½®ç›¸å…³é”™è¯¯

#### é”™è¯¯ï¼šé…ç½®å‚æ•°ç¼ºå¤±

**ç—‡çŠ¶**:
```
ValueError: ç¼ºå°‘å¿…éœ€å­—æ®µ: data.data_dir
```

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# ç¡®ä¿é…ç½®åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
data:
  data_dir: "data"
  metadata_file: "metadata_6_1.xlsx"
  factory_name: "id"
  dataset_name: "ID_dataset"

model:
  type: "ISFM"
  factory_name: "ISFM"

task:
  name: "contrastive_id"
```

#### é”™è¯¯ï¼šé…ç½®åŠ è½½å¤±è´¥

**ç—‡çŠ¶**:
```
FileNotFoundError: configs/id_contrastive/debug.yaml not found
```

**æ£€æŸ¥ä¸ä¿®å¤**:
```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶å­˜åœ¨
find . -name "*.yaml" | grep contrastive

# åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶
mkdir -p configs/id_contrastive
cp configs/demo/debug.yaml configs/id_contrastive/debug.yaml
```

## ğŸ”§ è°ƒè¯•å·¥å…·

### 1. é€æ­¥è°ƒè¯•è„šæœ¬

```python
def debug_step_by_step():
    """é€æ­¥è°ƒè¯•ContrastiveIDTask"""

    # æ­¥éª¤1: é…ç½®åŠ è½½
    try:
        from src.configs import load_config
        config = load_config('configs/id_contrastive/debug.yaml')
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return

    # æ­¥éª¤2: æ•°æ®é›†åˆ›å»º
    try:
        from src.data_factory import create_dataset
        dataset = create_dataset(**config.data.to_dict())
        print(f"âœ… æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {len(dataset)}")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return

    # æ­¥éª¤3: ä»»åŠ¡åˆ›å»º
    try:
        from src.task_factory.task.pretrain.ContrastiveIDTask import ContrastiveIDTask
        task = ContrastiveIDTask(**config.to_dict())
        print("âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")
        return

    # æ­¥éª¤4: æ‰¹æ¬¡å¤„ç†æµ‹è¯•
    try:
        from torch.utils.data import DataLoader
        dataloader = DataLoader(dataset, batch_size=4, shuffle=True)
        batch = next(iter(dataloader))
        prepared_batch = task.prepare_batch(batch)
        print("âœ… æ‰¹æ¬¡å¤„ç†æˆåŠŸ")
        print(f"   é”šç‚¹å½¢çŠ¶: {prepared_batch['anchor'].shape}")
        print(f"   æ­£æ ·æœ¬å½¢çŠ¶: {prepared_batch['positive'].shape}")
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
        return

    # æ­¥éª¤5: å‰å‘ä¼ æ’­æµ‹è¯•
    try:
        z_anchor = task.model(prepared_batch['anchor'])
        z_positive = task.model(prepared_batch['positive'])
        loss = task.infonce_loss(z_anchor, z_positive)
        accuracy = task.compute_accuracy(z_anchor, z_positive)
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   æŸå¤±å€¼: {loss.item():.4f}")
        print(f"   å‡†ç¡®ç‡: {accuracy.item():.2%}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return

    print("\nğŸ‰ æ‰€æœ‰ç»„ä»¶è¿è¡Œæ­£å¸¸ï¼")

if __name__ == "__main__":
    debug_step_by_step()
```

### 2. æ€§èƒ½ç›‘æ§è„šæœ¬

```python
import psutil
import torch
import time

def monitor_training_performance(task, dataloader, num_batches=10):
    """ç›‘æ§è®­ç»ƒæ€§èƒ½æŒ‡æ ‡"""

    # GPUå†…å­˜ç›‘æ§
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
        initial_memory = torch.cuda.memory_allocated()

    # CPUå’Œç³»ç»Ÿå†…å­˜ç›‘æ§
    process = psutil.Process()
    initial_cpu_memory = process.memory_info().rss / 1024 / 1024  # MB

    task.train()
    times = []

    for i, batch in enumerate(dataloader):
        if i >= num_batches:
            break

        start_time = time.time()

        # å‰å‘ä¼ æ’­
        prepared_batch = task.prepare_batch(batch)
        z_anchor = task.model(prepared_batch['anchor'])
        z_positive = task.model(prepared_batch['positive'])
        loss = task.infonce_loss(z_anchor, z_positive)

        # åå‘ä¼ æ’­
        loss.backward()

        batch_time = time.time() - start_time
        times.append(batch_time)

        # å†…å­˜ä½¿ç”¨
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated() / 1024 / 1024  # MB
            peak_gpu_memory = torch.cuda.max_memory_allocated() / 1024 / 1024  # MB

        cpu_memory = process.memory_info().rss / 1024 / 1024  # MB

        print(f"Batch {i+1}/{num_batches}:")
        print(f"  æ—¶é—´: {batch_time:.3f}s")
        print(f"  æŸå¤±: {loss.item():.4f}")
        print(f"  CPUå†…å­˜: {cpu_memory:.1f}MB")
        if torch.cuda.is_available():
            print(f"  GPUå†…å­˜: {gpu_memory:.1f}MB")
            print(f"  å³°å€¼GPUå†…å­˜: {peak_gpu_memory:.1f}MB")
        print()

    # ç»Ÿè®¡ä¿¡æ¯
    avg_time = sum(times) / len(times)
    print(f"å¹³å‡æ‰¹æ¬¡æ—¶é—´: {avg_time:.3f}s")
    print(f"é¢„ä¼°æ¯epochæ—¶é—´: {avg_time * len(dataloader) / 60:.1f}åˆ†é’Ÿ")
```

### 3. æ•°æ®è´¨é‡æ£€æŸ¥

```python
def check_data_quality(dataset):
    """æ£€æŸ¥æ•°æ®é›†è´¨é‡"""
    print("ğŸ“Š æ•°æ®è´¨é‡æ£€æŸ¥")
    print("-" * 40)

    # é‡‡æ ·æ£€æŸ¥
    sample_ids = []
    for i in range(min(100, len(dataset))):
        sample_id, _, metadata = dataset[i]
        sample_ids.append(sample_id)

    # æ£€æŸ¥IDåˆ†å¸ƒ
    from collections import Counter
    id_counts = Counter(sample_ids)
    print(f"æ ·æœ¬æ€»æ•°: {len(sample_ids)}")
    print(f"å”¯ä¸€IDæ•°: {len(id_counts)}")
    print(f"å¹³å‡æ¯IDæ ·æœ¬æ•°: {len(sample_ids) / len(id_counts):.2f}")
    print(f"IDåˆ†å¸ƒ (å‰10): {dict(list(id_counts.most_common(10)))}")

    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    missing_data = 0
    for sample_id in list(id_counts.keys())[:10]:
        try:
            data = dataset._get_data_for_id(sample_id)
            if data is None or len(data) == 0:
                missing_data += 1
        except:
            missing_data += 1

    print(f"ç¼ºå¤±æ•°æ®IDæ•°: {missing_data}/10")

    if missing_data > 0:
        print("âš ï¸  å‘ç°æ•°æ®å®Œæ•´æ€§é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
    else:
        print("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
```

## ğŸ“‹ æ•…éšœæ’é™¤æ¸…å•

### å¯åŠ¨å‰æ£€æŸ¥

- [ ] Pythonç‰ˆæœ¬ â‰¥ 3.8
- [ ] PyTorchç‰ˆæœ¬ = 2.6.0
- [ ] CUDAç‰ˆæœ¬å…¼å®¹ (å¦‚ä½¿ç”¨GPU)
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»
- [ ] é…ç½®æ–‡ä»¶è¯­æ³•æ­£ç¡®
- [ ] å¿…éœ€å­—æ®µå®Œæ•´

### è¿è¡Œæ—¶æ£€æŸ¥

- [ ] GPUå†…å­˜å……è¶³ (è‡³å°‘2GBç©ºé—²)
- [ ] ç³»ç»Ÿå†…å­˜å……è¶³ (è‡³å°‘8GB)
- [ ] ç£ç›˜ç©ºé—´å……è¶³ (ç»“æœä¿å­˜)
- [ ] æ•°æ®åŠ è½½æ­£å¸¸
- [ ] æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ

### è®­ç»ƒè¿‡ç¨‹æ£€æŸ¥

- [ ] æŸå¤±å€¼åˆç† (0.1-10èŒƒå›´)
- [ ] å‡†ç¡®ç‡é€æ­¥æå‡
- [ ] å†…å­˜ä½¿ç”¨ç¨³å®š
- [ ] æ— è­¦å‘Šæˆ–å¼‚å¸¸

## ğŸ†˜ è·å–å¸®åŠ©

### æ—¥å¿—åˆ†æ

1. **æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯**:
```bash
python main.py --config configs/id_contrastive/debug.yaml --verbose
```

2. **ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶**:
```bash
python main.py --config configs/id_contrastive/debug.yaml 2>&1 | tee training.log
```

3. **åˆ†ææ—¥å¿—æ¨¡å¼**:
```bash
grep "ERROR\|WARNING" training.log
grep "loss\|accuracy" training.log
```

### è”ç³»æ”¯æŒ

- **GitHub Issues**: [PHM-Vibench Issues](https://github.com/your-repo/issues)
- **æ–‡æ¡£**: [technical_guide.md](technical_guide.md)
- **APIå‚è€ƒ**: [api_reference.md](api_reference.md)

---

**æ›´æ–°æ—¶é—´**: 2024å¹´9æœˆ
**é€‚ç”¨ç‰ˆæœ¬**: ContrastiveIDTask v1.0