# ContrastiveIDTask API å‚è€ƒ

PHM-Vibench ContrastiveIDTaskçš„å®Œæ•´APIæ¥å£æ–‡æ¡£ã€‚

## ğŸ“‹ å¿«é€Ÿç´¢å¼•

- [æ ¸å¿ƒç±»](#æ ¸å¿ƒç±»)
- [é…ç½®æ¥å£](#é…ç½®æ¥å£)
- [æ•°æ®æ¥å£](#æ•°æ®æ¥å£)
- [è®­ç»ƒæ¥å£](#è®­ç»ƒæ¥å£)
- [å·¥å…·å‡½æ•°](#å·¥å…·å‡½æ•°)

## ğŸ—ï¸ æ ¸å¿ƒç±»

### ContrastiveIDTask

é•¿ä¿¡å·å¯¹æ¯”å­¦ä¹ ä»»åŠ¡çš„ä¸»è¦å®ç°ç±»ã€‚

```python
@register_task("contrastive_id", "pretrain")
class ContrastiveIDTask(BaseIDTask):
    """åŸºäºIDçš„å¯¹æ¯”å­¦ä¹ é¢„è®­ç»ƒä»»åŠ¡

    ç»§æ‰¿BaseIDTaskçš„æ‰€æœ‰åŠŸèƒ½ï¼Œä¸“æ³¨äºå¯¹æ¯”å­¦ä¹ é€»è¾‘å®ç°ã€‚
    """
```

#### åˆå§‹åŒ–

```python
def __init__(self, **kwargs):
    """åˆå§‹åŒ–å¯¹æ¯”å­¦ä¹ ä»»åŠ¡

    Args:
        temperature (float, optional): InfoNCEæ¸©åº¦å‚æ•°. é»˜è®¤: 0.07
        **kwargs: ä¼ é€’ç»™BaseIDTaskçš„å…¶ä»–å‚æ•°

    Attributes:
        temperature (float): å¯¹æ¯”å­¦ä¹ æ¸©åº¦å‚æ•°
        criterion (nn.CrossEntropyLoss): æŸå¤±å‡½æ•°
    """
```

#### æ ¸å¿ƒæ–¹æ³•

##### prepare_batch()

```python
def prepare_batch(self, batch_data: List[Tuple]) -> Dict[str, torch.Tensor]:
    """ä¸ºå¯¹æ¯”å­¦ä¹ å‡†å¤‡æ‰¹æ¬¡æ•°æ®

    ä¸ºæ¯ä¸ªæ ·æœ¬IDç”Ÿæˆæ­£æ ·æœ¬å¯¹ï¼Œæ„å»ºç”¨äºInfoNCEæŸå¤±è®¡ç®—çš„å¼ é‡ã€‚

    Args:
        batch_data (List[Tuple]): æ‰¹æ¬¡æ•°æ®
            æ ¼å¼: [(sample_id, None, metadata), ...]

    Returns:
        Dict[str, torch.Tensor]: åŒ…å«ä»¥ä¸‹é”®çš„å­—å…¸
            - 'anchor': é”šç‚¹çª—å£ [batch_size, window_size, channels]
            - 'positive': æ­£æ ·æœ¬çª—å£ [batch_size, window_size, channels]

    Raises:
        ValueError: å½“æ‰¹æ¬¡ä¸ºç©ºæˆ–å¤„ç†å¤±è´¥æ—¶
        RuntimeError: å½“çª—å£ç”Ÿæˆå¤±è´¥æ—¶

    Example:
        ```python
        task = ContrastiveIDTask(temperature=0.07)
        batch = task.prepare_batch(dataloader_batch)
        print(f"é”šç‚¹å½¢çŠ¶: {batch['anchor'].shape}")
        print(f"æ­£æ ·æœ¬å½¢çŠ¶: {batch['positive'].shape}")
        ```
    """
```

##### infonce_loss()

```python
def infonce_loss(self, z_anchor: torch.Tensor, z_positive: torch.Tensor) -> torch.Tensor:
    """è®¡ç®—InfoNCEå¯¹æ¯”æŸå¤±

    å®ç°æ ‡å‡†çš„InfoNCEæŸå¤±è®¡ç®—ï¼ŒåŒ…æ‹¬ç‰¹å¾å½’ä¸€åŒ–å’Œæ¸©åº¦ç¼©æ”¾ã€‚

    Args:
        z_anchor (torch.Tensor): é”šç‚¹ç‰¹å¾å‘é‡ [batch_size, d_model]
        z_positive (torch.Tensor): æ­£æ ·æœ¬ç‰¹å¾å‘é‡ [batch_size, d_model]

    Returns:
        torch.Tensor: InfoNCEæŸå¤±å€¼ (æ ‡é‡)

    Mathematical Formula:
        L = -Î£_i log(exp(s(z_i, z_i+) / Ï„) / Î£_j exp(s(z_i, z_j) / Ï„))

        å…¶ä¸­:
        - s(Â·,Â·): ä½™å¼¦ç›¸ä¼¼åº¦å‡½æ•°
        - Ï„: æ¸©åº¦å‚æ•° (self.temperature)

    Example:
        ```python
        # å‡è®¾æ¨¡å‹è¾“å‡ºç‰¹å¾ç»´åº¦ä¸º256
        z_anchor = torch.randn(32, 256)  # æ‰¹é‡å¤§å°32
        z_positive = torch.randn(32, 256)

        loss = task.infonce_loss(z_anchor, z_positive)
        print(f"InfoNCEæŸå¤±: {loss.item():.4f}")
        ```
    """
```

##### compute_accuracy()

```python
def compute_accuracy(self, z_anchor: torch.Tensor, z_positive: torch.Tensor) -> torch.Tensor:
    """è®¡ç®—å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡

    è®¡ç®—æ­£æ ·æœ¬åœ¨ç›¸ä¼¼åº¦æ’åºä¸­ä½äºç¬¬ä¸€ä½çš„æ¯”ä¾‹ã€‚

    Args:
        z_anchor (torch.Tensor): é”šç‚¹ç‰¹å¾å‘é‡ [batch_size, d_model]
        z_positive (torch.Tensor): æ­£æ ·æœ¬ç‰¹å¾å‘é‡ [batch_size, d_model]

    Returns:
        torch.Tensor: å‡†ç¡®ç‡ (0-1ä¹‹é—´çš„æ ‡é‡)

    Example:
        ```python
        accuracy = task.compute_accuracy(z_anchor, z_positive)
        print(f"å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡: {accuracy.item():.2%}")
        ```
    """
```

##### _shared_step()

```python
def _shared_step(self, batch: Dict, stage: str) -> torch.Tensor:
    """è®­ç»ƒ/éªŒè¯/æµ‹è¯•çš„å…±äº«æ­¥éª¤

    Args:
        batch (Dict): æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å«'anchor'å’Œ'positive'
        stage (str): é˜¶æ®µæ ‡è¯† ('train', 'val', 'test')

    Returns:
        torch.Tensor: æŸå¤±å€¼
    """
```

## âš™ï¸ é…ç½®æ¥å£

### load_config()

```python
from src.configs import load_config

# åŸºç¡€ç”¨æ³•
config = load_config('contrastive')

# ä»æ–‡ä»¶åŠ è½½
config = load_config('configs/id_contrastive/debug.yaml')

# å‚æ•°è¦†ç›–
config = load_config('contrastive', {
    'task.temperature': 0.05,
    'data.batch_size': 64,
    'model.d_model': 512
})
```

### é…ç½®ç»“æ„

#### æ•°æ®é…ç½® (ConfigWrapper.data)

```python
class DataConfig:
    factory_name: str = "id"                    # æ•°æ®å·¥å‚åç§°
    dataset_name: str = "ID_dataset"            # æ•°æ®é›†ç±»å
    data_dir: str = "data"                      # æ•°æ®æ ¹ç›®å½•
    metadata_file: str = "metadata_6_1.xlsx"   # å…ƒæ•°æ®æ–‡ä»¶

    # çª—å£åŒ–å‚æ•°
    window_size: int = 1024                     # çª—å£å¤§å°
    stride: int = 512                           # çª—å£æ­¥é•¿
    num_window: int = 2                         # æ¯IDçª—å£æ•°é‡
    window_sampling_strategy: str = "random"    # é‡‡æ ·ç­–ç•¥

    # æ‰¹å¤„ç†å‚æ•°
    batch_size: int = 32                        # æ‰¹é‡å¤§å°
    num_workers: int = 4                        # æ•°æ®åŠ è½½è¿›ç¨‹

    # é¢„å¤„ç†å‚æ•°
    normalization: bool = True                  # Z-scoreæ ‡å‡†åŒ–
    truncate_length: Optional[int] = None       # æˆªæ–­é•¿åº¦
```

#### ä»»åŠ¡é…ç½® (ConfigWrapper.task)

```python
class TaskConfig:
    name: str = "contrastive_id"               # ä»»åŠ¡åç§°
    type: str = "pretrain"                     # ä»»åŠ¡ç±»å‹

    # å¯¹æ¯”å­¦ä¹ å‚æ•°
    temperature: float = 0.07                  # InfoNCEæ¸©åº¦

    # ä¼˜åŒ–å‚æ•°
    lr: float = 0.001                          # å­¦ä¹ ç‡
    weight_decay: float = 1e-4                 # æƒé‡è¡°å‡

    # è°ƒåº¦å™¨å‚æ•°
    scheduler: str = "cosine"                  # å­¦ä¹ ç‡è°ƒåº¦å™¨
    warmup_steps: int = 1000                   # é¢„çƒ­æ­¥æ•°
```

#### æ¨¡å‹é…ç½® (ConfigWrapper.model)

```python
class ModelConfig:
    factory_name: str = "ISFM"                 # æ¨¡å‹å·¥å‚
    type: str = "ISFM"                         # æ¨¡å‹ç±»å‹

    # æ¶æ„å‚æ•°
    d_model: int = 256                         # åµŒå…¥ç»´åº¦
    nhead: int = 8                             # æ³¨æ„åŠ›å¤´æ•°
    nlayers: int = 6                           # ç¼–ç å™¨å±‚æ•°

    # è¾“å…¥å‚æ•°
    input_dim: int = 1                         # è¾“å…¥é€šé“æ•°
    seq_len: int = 1024                        # åºåˆ—é•¿åº¦
```

## ğŸ“Š æ•°æ®æ¥å£

### ID_dataset

åŸºç¡€IDæ•°æ®é›†ç±»ï¼Œç”±data_factoryæä¾›ã€‚

```python
from src.data_factory import create_dataset

# åˆ›å»ºæ•°æ®é›†
dataset = create_dataset(
    factory_name="id",
    dataset_name="ID_dataset",
    data_dir="data",
    metadata_file="metadata_6_1.xlsx"
)

# æ•°æ®é›†æ¥å£
len(dataset)                    # æ•°æ®é›†å¤§å°
dataset[idx]                    # è·å–æ ·æœ¬: (sample_id, None, metadata)
dataset.get_sample_ids()        # è·å–æ‰€æœ‰æ ·æœ¬ID
```

### H5DataDict

å»¶è¿ŸåŠ è½½æ•°æ®å­—å…¸ï¼Œæä¾›å†…å­˜é«˜æ•ˆçš„æ•°æ®è®¿é—®ã€‚

```python
# é€šè¿‡BaseIDTask._get_data_for_id()è®¿é—®
data = task._get_data_for_id(sample_id)
print(f"ä¿¡å·å½¢çŠ¶: {data.shape}")         # [seq_len, channels]
print(f"æ•°æ®ç±»å‹: {data.dtype}")         # torch.float32
```

## ğŸš€ è®­ç»ƒæ¥å£

### PyTorch Lightningé›†æˆ

ContrastiveIDTaskç»§æ‰¿äº†BaseIDTaskçš„PyTorch Lightningæ¥å£ã€‚

```python
import pytorch_lightning as pl

# åˆ›å»ºä»»åŠ¡å®ä¾‹
task = ContrastiveIDTask(
    temperature=0.07,
    lr=0.001,
    # ... å…¶ä»–å‚æ•°
)

# åˆ›å»ºè®­ç»ƒå™¨
trainer = pl.Trainer(
    max_epochs=100,
    devices=1,
    precision=16
)

# å¼€å§‹è®­ç»ƒ
trainer.fit(task, train_dataloader, val_dataloader)
```

### è®­ç»ƒæ­¥éª¤æ–¹æ³•

```python
# Lightningè®­ç»ƒæ­¥éª¤
def training_step(self, batch, batch_idx) -> torch.Tensor:
    """è®­ç»ƒæ­¥éª¤ - è‡ªåŠ¨è°ƒç”¨"""
    return self._shared_step(batch, "train")

def validation_step(self, batch, batch_idx) -> torch.Tensor:
    """éªŒè¯æ­¥éª¤ - è‡ªåŠ¨è°ƒç”¨"""
    return self._shared_step(batch, "val")

def test_step(self, batch, batch_idx) -> torch.Tensor:
    """æµ‹è¯•æ­¥éª¤ - è‡ªåŠ¨è°ƒç”¨"""
    return self._shared_step(batch, "test")
```

### ä¼˜åŒ–å™¨é…ç½®

```python
def configure_optimizers(self):
    """é…ç½®ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨"""
    optimizer = torch.optim.AdamW(
        self.parameters(),
        lr=self.lr,
        weight_decay=self.weight_decay
    )

    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=100
    )

    return [optimizer], [scheduler]
```

## ğŸ› ï¸ å·¥å…·å‡½æ•°

### ç‰¹å¾æå–

```python
def extract_features(model: ContrastiveIDTask, dataset_id: str) -> torch.Tensor:
    """æå–é¢„è®­ç»ƒç‰¹å¾ç”¨äºä¸‹æ¸¸ä»»åŠ¡

    Args:
        model: é¢„è®­ç»ƒçš„ContrastiveIDTaskæ¨¡å‹
        dataset_id: æ•°æ®é›†æ ‡è¯†ç¬¦

    Returns:
        torch.Tensor: æå–çš„ç‰¹å¾ [num_samples, d_model]
    """
    model.eval()
    features = []

    with torch.no_grad():
        for batch in dataloader:
            batch_prepared = model.prepare_batch(batch)
            z_anchor = model.model(batch_prepared['anchor'])
            features.append(z_anchor)

    return torch.cat(features, dim=0)
```

### ç›¸ä¼¼åº¦è®¡ç®—

```python
def cosine_similarity(z1: torch.Tensor, z2: torch.Tensor) -> torch.Tensor:
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦

    Args:
        z1, z2: ç‰¹å¾å‘é‡ [batch_size, d_model]

    Returns:
        torch.Tensor: ç›¸ä¼¼åº¦çŸ©é˜µ [batch_size, batch_size]
    """
    z1_norm = F.normalize(z1, dim=1)
    z2_norm = F.normalize(z2, dim=1)
    return torch.mm(z1_norm, z2_norm.t())
```

### å¯è§†åŒ–å·¥å…·

```python
def visualize_embeddings(features: torch.Tensor, labels: List[int]):
    """ä½¿ç”¨t-SNEå¯è§†åŒ–ç‰¹å¾åµŒå…¥

    Args:
        features: ç‰¹å¾çŸ©é˜µ [num_samples, d_model]
        labels: æ ‡ç­¾åˆ—è¡¨
    """
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt

    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42)
    features_2d = tsne.fit_transform(features.numpy())

    # ç»˜åˆ¶æ•£ç‚¹å›¾
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='tab10')
    plt.colorbar(scatter)
    plt.title('ContrastiveIDTaskç‰¹å¾å¯è§†åŒ–')
    plt.show()
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
src/task_factory/task/pretrain/
â””â”€â”€ ContrastiveIDTask.py              # ä¸»å®ç°æ–‡ä»¶

configs/id_contrastive/
â”œâ”€â”€ debug.yaml                        # è°ƒè¯•é…ç½®
â”œâ”€â”€ production.yaml                   # ç”Ÿäº§é…ç½®
â”œâ”€â”€ ablation.yaml                     # æ¶ˆèå®éªŒé…ç½®
â””â”€â”€ cross_dataset.yaml               # è·¨æ•°æ®é›†é…ç½®

test/unit/task_factory/
â””â”€â”€ test_contrastive_id_task.py       # å•å…ƒæµ‹è¯•

test/integration/
â”œâ”€â”€ test_contrastive_full_training.py # é›†æˆæµ‹è¯•
â””â”€â”€ test_contrastive_real_data.py     # çœŸå®æ•°æ®æµ‹è¯•
```

## ğŸ”— ç›¸å…³é“¾æ¥

- **æŠ€æœ¯æŒ‡å—**: [technical_guide.md](technical_guide.md)
- **æ•…éšœæ’é™¤**: [troubleshooting.md](troubleshooting.md)
- **PHM-Vibenchæ–‡æ¡£**: [../../../docs/](../../../docs/)
- **é…ç½®ç³»ç»Ÿ**: [../../../src/configs/CLAUDE.md](../../../src/configs/CLAUDE.md)

---

**APIç‰ˆæœ¬**: v1.0
**æ›´æ–°æ—¶é—´**: 2024å¹´9æœˆ
**å…¼å®¹æ€§**: PHM-Vibench v5.0+