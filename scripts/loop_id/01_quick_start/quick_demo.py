#!/usr/bin/env python3
"""
ContrastiveIDTask 5åˆ†é’Ÿå¿«é€Ÿæ¼”ç¤º

å¿«é€ŸéªŒè¯ContrastiveIDTaskçš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå’Œé¢„å¤„ç†
- å¯¹æ¯”å­¦ä¹ ä»»åŠ¡åˆå§‹åŒ–
- InfoNCEæŸå¤±è®¡ç®—æ¼”ç¤º
- åŸºç¡€è®­ç»ƒå¾ªç¯å±•ç¤º
- ç»“æœå¯è§†åŒ–

æœ¬æ¼”ç¤ºä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œæ— éœ€çœŸå®æ•°æ®é›†ï¼Œé€‚åˆï¼š
- æ–°ç”¨æˆ·å¿«é€Ÿäº†è§£ç³»ç»ŸåŠŸèƒ½
- å¼€å‘ç¯å¢ƒéªŒè¯
- ç®—æ³•åŸç†æ¼”ç¤º

Usage:
    # æ ‡å‡†5åˆ†é’Ÿæ¼”ç¤º
    python quick_demo.py

    # ç®€åŒ–ç‰ˆæ¼”ç¤ºï¼ˆ1åˆ†é’Ÿï¼‰
    python quick_demo.py --fast

    # è¯¦ç»†æ¼”ç¤ºåŒ…å«å¯è§†åŒ–
    python quick_demo.py --verbose --plot

Author: PHM-Vibench Team
Version: 1.0 (Quick Validation Demo)
"""

import sys
import time
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from datetime import datetime
import warnings

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# æŠ‘åˆ¶è­¦å‘Šä»¥ä¿æŒæ¼”ç¤ºæ¸…æ´
warnings.filterwarnings('ignore')

class MockContrastiveIDTask(nn.Module):
    """æ¨¡æ‹Ÿçš„ContrastiveIDTaskç”¨äºæ¼”ç¤º

    å®ç°æ ¸å¿ƒçš„å¯¹æ¯”å­¦ä¹ åŠŸèƒ½ï¼š
    1. ç‰¹å¾ç¼–ç å™¨
    2. InfoNCEæŸå¤±è®¡ç®—
    3. å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡è®¡ç®—
    """

    def __init__(self, input_dim: int = 1024, d_model: int = 128, temperature: float = 0.07):
        super().__init__()
        self.temperature = temperature

        # ç®€åŒ–çš„ç¼–ç å™¨ç½‘ç»œ
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, d_model * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(d_model * 2, d_model),
            nn.ReLU(),
            nn.Linear(d_model, d_model)
        )

        # æŠ•å½±å¤´ï¼ˆå¯é€‰ï¼‰
        self.projection_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Linear(d_model // 2, d_model // 2)
        )

        print(f"âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: è¾“å…¥ç»´åº¦={input_dim}, ç‰¹å¾ç»´åº¦={d_model}, æ¸©åº¦={temperature}")

    def forward(self, anchor, positive):
        """å‰å‘ä¼ æ’­"""
        # ç‰¹å¾æå–
        z_anchor = self.encoder(anchor)
        z_positive = self.encoder(positive)

        # æŠ•å½±
        z_anchor = self.projection_head(z_anchor)
        z_positive = self.projection_head(z_positive)

        return z_anchor, z_positive

    def infonce_loss(self, z_anchor, z_positive):
        """è®¡ç®—InfoNCEå¯¹æ¯”æŸå¤±"""
        batch_size = z_anchor.size(0)

        # L2å½’ä¸€åŒ–
        z_anchor = F.normalize(z_anchor, dim=1)
        z_positive = F.normalize(z_positive, dim=1)

        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        similarity_matrix = torch.mm(z_anchor, z_positive.t()) / self.temperature

        # åˆ›å»ºæ ‡ç­¾ï¼ˆå¯¹è§’çº¿ä¸ºæ­£æ ·æœ¬ï¼‰
        labels = torch.arange(batch_size, device=z_anchor.device)

        # è®¡ç®—äº¤å‰ç†µæŸå¤±
        loss = F.cross_entropy(similarity_matrix, labels)

        return loss

    def compute_accuracy(self, z_anchor, z_positive):
        """è®¡ç®—å¯¹æ¯”å­¦ä¹ å‡†ç¡®ç‡"""
        with torch.no_grad():
            z_anchor = F.normalize(z_anchor, dim=1)
            z_positive = F.normalize(z_positive, dim=1)

            similarity_matrix = torch.mm(z_anchor, z_positive.t()) / self.temperature
            predictions = torch.argmax(similarity_matrix, dim=1)
            labels = torch.arange(len(z_anchor), device=z_anchor.device)

            accuracy = (predictions == labels).float().mean()

        return accuracy

class QuickDemo:
    """ContrastiveIDTaskå¿«é€Ÿæ¼”ç¤ºç±»"""

    def __init__(self, fast_mode: bool = False, verbose: bool = False, enable_plot: bool = False):
        self.fast_mode = fast_mode
        self.verbose = verbose
        self.enable_plot = enable_plot

        # æ¼”ç¤ºå‚æ•°
        if fast_mode:
            self.demo_params = {
                'batch_size': 16,
                'window_size': 512,
                'num_epochs': 3,
                'num_batches_per_epoch': 5,
                'd_model': 64
            }
            print("ğŸš€ å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼ï¼ˆçº¦1åˆ†é’Ÿï¼‰")
        else:
            self.demo_params = {
                'batch_size': 32,
                'window_size': 1024,
                'num_epochs': 10,
                'num_batches_per_epoch': 10,
                'd_model': 128
            }
            print("ğŸš€ æ ‡å‡†æ¼”ç¤ºæ¨¡å¼ï¼ˆçº¦5åˆ†é’Ÿï¼‰")

        # è®¾å¤‡é€‰æ‹©
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {self.device}")

        # ç»“æœè®°å½•
        self.training_history = {
            'epochs': [],
            'losses': [],
            'accuracies': [],
            'batch_times': []
        }

    def generate_mock_data(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„æŒ¯åŠ¨ä¿¡å·æ•°æ®"""
        print("\nğŸ“Š ç”Ÿæˆæ¨¡æ‹ŸæŒ¯åŠ¨ä¿¡å·æ•°æ®...")

        batch_size = self.demo_params['batch_size']
        window_size = self.demo_params['window_size']
        num_batches = self.demo_params['num_batches_per_epoch']

        # æ¨¡æ‹Ÿä¸åŒç±»å‹çš„æŒ¯åŠ¨ä¿¡å·
        def create_vibration_signal(signal_type, length):
            """åˆ›å»ºä¸åŒç±»å‹çš„æ¨¡æ‹ŸæŒ¯åŠ¨ä¿¡å·"""
            t = np.linspace(0, 1, length)

            if signal_type == 'normal':
                # æ­£å¸¸ä¿¡å·ï¼šä½å¹…åº¦å™ªå£°
                signal = 0.1 * np.random.randn(length) + 0.05 * np.sin(2 * np.pi * 10 * t)
            elif signal_type == 'bearing_fault':
                # è½´æ‰¿æ•…éšœï¼šå‘¨æœŸæ€§å†²å‡»
                signal = 0.2 * np.random.randn(length)
                impact_freq = 50  # 50Hzå†²å‡»é¢‘ç‡
                for i in range(0, length, length // impact_freq):
                    if i < length - 20:
                        signal[i:i+20] += 0.8 * np.exp(-np.arange(20) / 5)
            elif signal_type == 'gear_fault':
                # é½¿è½®æ•…éšœï¼šè°æ³¢æˆåˆ†
                signal = 0.15 * np.random.randn(length)
                signal += 0.3 * np.sin(2 * np.pi * 25 * t)  # åŸºé¢‘
                signal += 0.2 * np.sin(2 * np.pi * 50 * t)  # äºŒæ¬¡è°æ³¢
                signal += 0.1 * np.sin(2 * np.pi * 75 * t)  # ä¸‰æ¬¡è°æ³¢
            else:
                # é»˜è®¤éšæœºä¿¡å·
                signal = 0.2 * np.random.randn(length)

            return signal

        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        all_anchors = []
        all_positives = []

        signal_types = ['normal', 'bearing_fault', 'gear_fault']

        for batch_idx in range(num_batches):
            batch_anchors = []
            batch_positives = []

            for i in range(batch_size):
                # éšæœºé€‰æ‹©ä¿¡å·ç±»å‹
                signal_type = np.random.choice(signal_types)

                # ç”ŸæˆåŒä¸€IDçš„ä¸¤ä¸ªä¸åŒçª—å£ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰
                base_signal = create_vibration_signal(signal_type, window_size * 2)

                # éšæœºé€‰æ‹©ä¸¤ä¸ªä¸é‡å çš„çª—å£
                start1 = np.random.randint(0, window_size // 2)
                start2 = np.random.randint(window_size, window_size + window_size // 2)

                anchor = base_signal[start1:start1 + window_size]
                positive = base_signal[start2:start2 + window_size]

                batch_anchors.append(anchor)
                batch_positives.append(positive)

            all_anchors.append(np.array(batch_anchors))
            all_positives.append(np.array(batch_positives))

        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        anchor_data = torch.FloatTensor(np.concatenate(all_anchors, axis=0))
        positive_data = torch.FloatTensor(np.concatenate(all_positives, axis=0))

        print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ: é”šç‚¹æ•°æ® {anchor_data.shape}, æ­£æ ·æœ¬æ•°æ® {positive_data.shape}")

        return anchor_data, positive_data

    def create_dataloader(self, anchor_data, positive_data):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        dataset = TensorDataset(anchor_data, positive_data)
        dataloader = DataLoader(
            dataset,
            batch_size=self.demo_params['batch_size'],
            shuffle=True,
            num_workers=0  # æ¼”ç¤ºä¸­ä½¿ç”¨å•çº¿ç¨‹é¿å…å¤æ‚æ€§
        )

        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ: {len(dataset)}ä¸ªæ ·æœ¬, æ‰¹å¤§å°={self.demo_params['batch_size']}")
        return dataloader

    def run_training_demo(self, dataloader):
        """è¿è¡Œè®­ç»ƒæ¼”ç¤º"""
        print(f"\nğŸš€ å¼€å§‹å¯¹æ¯”å­¦ä¹ è®­ç»ƒæ¼”ç¤º...")

        # åˆå§‹åŒ–æ¨¡å‹
        model = MockContrastiveIDTask(
            input_dim=self.demo_params['window_size'],
            d_model=self.demo_params['d_model']
        ).to(self.device)

        # ä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

        model.train()
        start_time = time.time()

        for epoch in range(self.demo_params['num_epochs']):
            epoch_losses = []
            epoch_accuracies = []
            epoch_start = time.time()

            for batch_idx, (anchor, positive) in enumerate(dataloader):
                if batch_idx >= self.demo_params['num_batches_per_epoch']:
                    break

                batch_start = time.time()

                # æ•°æ®è½¬ç§»åˆ°è®¾å¤‡
                anchor = anchor.to(self.device)
                positive = positive.to(self.device)

                # å‰å‘ä¼ æ’­
                z_anchor, z_positive = model(anchor, positive)

                # è®¡ç®—æŸå¤±
                loss = model.infonce_loss(z_anchor, z_positive)

                # è®¡ç®—å‡†ç¡®ç‡
                accuracy = model.compute_accuracy(z_anchor, z_positive)

                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                # è®°å½•ç»“æœ
                epoch_losses.append(loss.item())
                epoch_accuracies.append(accuracy.item())

                batch_time = time.time() - batch_start

                if self.verbose or batch_idx % 3 == 0:
                    print(f"  Epoch {epoch+1:2d}, Batch {batch_idx+1:2d}: "
                          f"Loss={loss.item():.4f}, Acc={accuracy.item():.3f}, "
                          f"Time={batch_time*1000:.0f}ms")

            # è®°å½•æ¯ä¸ªepochçš„ç»Ÿè®¡
            epoch_time = time.time() - epoch_start
            avg_loss = np.mean(epoch_losses)
            avg_accuracy = np.mean(epoch_accuracies)

            self.training_history['epochs'].append(epoch + 1)
            self.training_history['losses'].append(avg_loss)
            self.training_history['accuracies'].append(avg_accuracy)
            self.training_history['batch_times'].append(epoch_time)

            print(f"ğŸ“Š Epoch {epoch+1:2d}: Loss={avg_loss:.4f}, "
                  f"Acc={avg_accuracy:.3f}, Time={epoch_time:.1f}s")

        total_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time:.1f}ç§’")

        return model

    def evaluate_model(self, model, dataloader):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print(f"\nğŸ“ˆ æ¨¡å‹è¯„ä¼°...")

        model.eval()
        test_losses = []
        test_accuracies = []
        feature_similarities = []

        with torch.no_grad():
            for batch_idx, (anchor, positive) in enumerate(dataloader):
                if batch_idx >= 3:  # åªè¯„ä¼°å‰3ä¸ªæ‰¹æ¬¡
                    break

                anchor = anchor.to(self.device)
                positive = positive.to(self.device)

                z_anchor, z_positive = model(anchor, positive)
                loss = model.infonce_loss(z_anchor, z_positive)
                accuracy = model.compute_accuracy(z_anchor, z_positive)

                test_losses.append(loss.item())
                test_accuracies.append(accuracy.item())

                # è®¡ç®—æ­£æ ·æœ¬å¯¹çš„ç›¸ä¼¼åº¦
                z_anchor_norm = F.normalize(z_anchor, dim=1)
                z_positive_norm = F.normalize(z_positive, dim=1)
                similarities = torch.sum(z_anchor_norm * z_positive_norm, dim=1)
                feature_similarities.extend(similarities.cpu().numpy())

        avg_test_loss = np.mean(test_losses)
        avg_test_accuracy = np.mean(test_accuracies)
        avg_similarity = np.mean(feature_similarities)

        print(f"âœ… æµ‹è¯•ç»“æœ: Loss={avg_test_loss:.4f}, "
              f"Acc={avg_test_accuracy:.3f}, "
              f"å¹³å‡æ­£æ ·æœ¬ç›¸ä¼¼åº¦={avg_similarity:.3f}")

        return {
            'test_loss': avg_test_loss,
            'test_accuracy': avg_test_accuracy,
            'average_similarity': avg_similarity,
            'similarity_distribution': feature_similarities
        }

    def visualize_results(self, evaluation_results):
        """å¯è§†åŒ–ç»“æœ"""
        if not self.enable_plot:
            return

        print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('ContrastiveIDTask Demo Results', fontsize=16)

        # 1. è®­ç»ƒæŸå¤±æ›²çº¿
        axes[0, 0].plot(self.training_history['epochs'], self.training_history['losses'], 'b-o')
        axes[0, 0].set_title('Training Loss')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].grid(True)

        # 2. è®­ç»ƒå‡†ç¡®ç‡æ›²çº¿
        axes[0, 1].plot(self.training_history['epochs'], self.training_history['accuracies'], 'g-o')
        axes[0, 1].set_title('Training Accuracy')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].grid(True)

        # 3. æ‰¹å¤„ç†æ—¶é—´
        axes[1, 0].bar(self.training_history['epochs'], self.training_history['batch_times'])
        axes[1, 0].set_title('Epoch Time')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Time (seconds)')

        # 4. ç‰¹å¾ç›¸ä¼¼åº¦åˆ†å¸ƒ
        similarities = evaluation_results['similarity_distribution']
        axes[1, 1].hist(similarities, bins=20, alpha=0.7, color='orange')
        axes[1, 1].axvline(evaluation_results['average_similarity'], color='red', linestyle='--',
                          label=f'Mean: {evaluation_results["average_similarity"]:.3f}')
        axes[1, 1].set_title('Feature Similarity Distribution')
        axes[1, 1].set_xlabel('Cosine Similarity')
        axes[1, 1].set_ylabel('Frequency')
        axes[1, 1].legend()

        plt.tight_layout()

        # ä¿å­˜å›¾åƒ
        output_dir = Path(__file__).parent
        plot_file = output_dir / f"demo_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(plot_file, dpi=150, bbox_inches='tight')
        print(f"ğŸ“ˆ å›¾è¡¨å·²ä¿å­˜: {plot_file}")

        plt.show()

    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        demo_start_time = time.time()

        print("ğŸ¯ ContrastiveIDTask å¿«é€Ÿæ¼”ç¤ºå¼€å§‹")
        print("=" * 60)

        try:
            # 1. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            anchor_data, positive_data = self.generate_mock_data()

            # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
            dataloader = self.create_dataloader(anchor_data, positive_data)

            # 3. è®­ç»ƒæ¼”ç¤º
            model = self.run_training_demo(dataloader)

            # 4. æ¨¡å‹è¯„ä¼°
            evaluation_results = self.evaluate_model(model, dataloader)

            # 5. ç»“æœå¯è§†åŒ–
            if self.enable_plot:
                self.visualize_results(evaluation_results)

            # 6. æ¼”ç¤ºæ€»ç»“
            demo_end_time = time.time()
            total_demo_time = demo_end_time - demo_start_time

            print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆæ€»ç»“")
            print("=" * 60)
            print(f"â±ï¸  æ€»æ¼”ç¤ºæ—¶é—´: {total_demo_time:.1f}ç§’")
            print(f"ğŸƒ è®­ç»ƒè½®æ•°: {self.demo_params['num_epochs']}")
            print(f"ğŸ“Š æœ€ç»ˆè®­ç»ƒæŸå¤±: {self.training_history['losses'][-1]:.4f}")
            print(f"ğŸ¯ æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {self.training_history['accuracies'][-1]:.3f}")
            print(f"âœ… æµ‹è¯•æŸå¤±: {evaluation_results['test_loss']:.4f}")
            print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡: {evaluation_results['test_accuracy']:.3f}")

            print(f"\nğŸ’¡ å…³é”®å­¦ä¹ ç‚¹:")
            print(f"   â€¢ InfoNCEæŸå¤±æœ‰æ•ˆä¼˜åŒ–äº†ç‰¹å¾è¡¨ç¤º")
            print(f"   â€¢ å¯¹æ¯”å­¦ä¹ æˆåŠŸå­¦ä¹ åˆ°äº†ä¿¡å·é—´çš„ç›¸ä¼¼æ€§")
            print(f"   â€¢ æ¨¡å‹åœ¨{self.device}ä¸Šè¿è¡Œç¨³å®š")

            if evaluation_results['test_accuracy'] > 0.5:
                print(f"   ğŸŠ æ¼”ç¤ºç»“æœè‰¯å¥½ï¼å¯¹æ¯”å­¦ä¹ æ•ˆæœæ˜¾è‘—")
            else:
                print(f"   âš ï¸  å‡†ç¡®ç‡åä½ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤šæ•°æ®å’Œè°ƒä¼˜")

            print(f"\nğŸ”— åç»­æ­¥éª¤:")
            print(f"   1. å°è¯•çœŸå®æ•°æ®é›†è®­ç»ƒ: python main.py --config configs/id_contrastive/debug.yaml")
            print(f"   2. è¿è¡Œæ¶ˆèå®éªŒ: python scripts/loop_id/03_experiments/ablation_study.py --quick")
            print(f"   3. æ€§èƒ½åŸºå‡†æµ‹è¯•: python scripts/loop_id/04_analysis/performance_benchmark.py --quick")

            return True

        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            if self.verbose:
                traceback.print_exc()
            return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ContrastiveIDTask 5åˆ†é’Ÿå¿«é€Ÿæ¼”ç¤º")

    parser.add_argument('--fast', action='store_true',
                       help='å¿«é€Ÿæ¨¡å¼ï¼ˆçº¦1åˆ†é’Ÿï¼‰')
    parser.add_argument('--verbose', action='store_true',
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')
    parser.add_argument('--plot', action='store_true',
                       help='ç”Ÿæˆç»“æœå¯è§†åŒ–å›¾è¡¨')

    args = parser.parse_args()

    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = QuickDemo(
        fast_mode=args.fast,
        verbose=args.verbose,
        enable_plot=args.plot
    )

    try:
        # è¿è¡Œå®Œæ•´æ¼”ç¤º
        success = demo.run_complete_demo()

        if success:
            return 0
        else:
            return 1

    except KeyboardInterrupt:
        print(f"\nâš ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main())