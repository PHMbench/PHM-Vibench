# HSE 工业对比学习完整发表流水线任务清单

## 任务概览

本任务清单实现了HSE（层次信号嵌入）工业对比学习从核心算法开发到论文发表的完整流水线，包含理论创新、实验验证、结果分析和发表材料生成四个主要阶段。

**核心创新**：首个将系统元数据提示与对比学习相结合的工业信号分析方法，通过统一度量学习实现跨数据集域泛化，将实验复杂度从150个实验降低到30个实验，同时达到优异的跨系统泛化性能。

**发表目标**：ICML/NeurIPS 2025 会议论文投稿，完整的实验验证和统计显著性分析。

## 原子化任务要求

**每个任务满足最优执行标准**：

- **文件范围**：单次操作涉及1-3个相关文件
- **时间限制**：有经验开发者15-30分钟内可完成
- **单一目标**：每个任务一个可测试的输出结果
- **具体文件**：明确指定创建/修改的文件路径
- **代理友好**：清晰的输入输出，最小化上下文切换

## 任务格式指南

- 使用复选框格式：`- [x] 任务编号. 任务描述`
- **指定文件**：始终包含确切的文件路径
- **包含实现细节**：在每个任务下用项目符号列出实现要点
- 引用需求：`_需求：FR1, FR2_`
- 引用现有代码：`_复用：path/to/existing_file.py_`
- 仅关注编码任务（不包括部署或用户测试）

## 任务清单

### P0 核心功能（必须首先实现）✅ 完成

#### P0.1 核心算法实现（最高优先级）

- [x] **任务1. HSE系统提示编码器实现**
  - **文件**：`src/model_factory/ISFM_Prompt/components/SystemPromptEncoder.py`
  - ✅ **已实现**：双层提示编码：系统级（Dataset_id+Domain_id）+ 样本级（Sample_rate）
  - ✅ 分类特征嵌入表，数值特征线性投影
  - ✅ 多头自注意力层级融合和最终聚合
  - ✅ 完整自测试和元数据字典创建工具
  - ✅ **关键**：无故障级提示（标签为预测目标）
  - _需求：FR2_
  - _状态：**完成** - 双层提示系统运行正常_

- [x] **任务2. 提示融合策略实现**
  - **文件**：`src/model_factory/ISFM_Prompt/components/PromptFusion.py`
  - ✅ **已实现**：三种融合策略：拼接、交叉注意力、自适应门控
  - ✅ 注意力融合的残差连接保留原始信号特征
  - ✅ 维度验证和自动形状匹配
  - ✅ 所有三种融合策略的完整自测试和梯度流验证
  - _需求：FR1, FR2_
  - _状态：**完成** - 多策略提示融合运行正常_

- [x] **任务3. HSE v2 嵌入层实现**
  - **文件**：`src/model_factory/ISFM_Prompt/embedding/E_01_HSE_v2.py`
  - ✅ **已实现**：全新HSE实现，集成SystemPromptEncoder和PromptFusion
  - ✅ 独立实现 - 与现有E_01_HSE.py零继承
  - ✅ forward()方法中的元数据参数用于双层提示处理（仅系统+样本）
  - ✅ 训练阶段控制和提示冻结，用于Pipeline_03集成
  - ✅ 元数据不可用时回退到纯信号处理
  - ✅ 完整自测试，包含元数据验证和阶段切换
  - _需求：FR2, FR3_
  - _状态：**完成** - 独立HSE v2实现运行正常_

- [x] **任务4. ISFM提示模型实现**
  - **文件**：`src/model_factory/ISFM_Prompt/M_02_ISFM_Prompt.py`
  - ✅ **已实现**：完整ISFM模型，支持提示引导嵌入
  - ✅ 组件字典用于PromptEmbedding、Backbone（复用现有）、TaskHead（复用现有）
  - ✅ 训练阶段控制和元数据转发贯穿模型流水线
  - ✅ 提示特征不可用时优雅降级
  - ✅ 返回(logits, prompts, features)元组支持对比学习
  - ✅ 多种嵌入/骨干/任务头组合的综合自测试
  - _需求：FR1, FR3_
  - _状态：**完成** - 提示引导ISFM模型运行正常_

#### P0.2 对比学习组件

- [x] **任务5. 提示引导对比损失实现**
  - **文件**：`src/task_factory/Components/prompt_contrastive.py`
  - ✅ **已实现**：所有现有对比损失的通用包装器，带提示引导
  - ✅ 使用元数据system_ids的系统感知正负样本采样
  - ✅ 提示相似性损失鼓励系统不变表示
  - ✅ 所有LOSS_MAPPING组合的综合自测试，带提示特征
  - ✅ 提示不可用时优雅回退到标准对比学习
  - _需求：FR1_
  - _状态：**完成** - 提示引导对比学习运行正常_

- [x] **任务6. HSE对比任务实现**
  - **文件**：`src/task_factory/task/CDDG/hse_contrastive.py`
  - ✅ **已实现**：集成提示引导对比学习的任务类
  - ✅ 用于系统信息提取的元数据预处理
  - ✅ 字典式批处理处理，包含robust元数据解析
  - ✅ 损失组合逻辑：分类 + 提示引导对比
  - ✅ 单次前向传递策略：网络返回(logits, prompts, features)
  - ✅ 两阶段训练工作流，在微调中自动禁用对比学习
  - ✅ 完整训练工作流的综合自测试
  - _需求：FR1, FR3_
  - _状态：**完成** - HSE对比任务运行正常_

#### P0.3 配置集成

- [x] **任务7. 统一实验配置更新**
  - **文件**：
    - `script/unified_metric/configs/unified_experiments.yaml`
    - `script/unified_metric/configs/unified_experiments_grace.yaml`
    - `script/unified_metric/configs/unified_experiments_1epoch.yaml`
  - ✅ **已实现**：从"classification"更新为"hse_contrastive"任务
  - ✅ 从M_01_ISFM更新为M_02_ISFM_Prompt模型栈
  - ✅ 从E_01_HSE更新为E_01_HSE_v2（支持提示）
  - ✅ HSE特定参数：use_system_sampling: true, cross_system_contrast: true
  - ✅ 对比损失参数：contrast_weight: 0.15, temperature: 0.07
  - ✅ 提示引导参数：prompt_weight: 0.1, use_prompt: true
  - _需求：FR1, FR2_
  - _状态：**完成** - HSE对比任务正确配置_

#### P0.4 实验基础设施

- [x] **任务8. 实用验证基础设施**
  - **文件**：`src/utils/validation/OneEpochValidator.py`
  - ✅ **已实现**：数据加载、前向传递、损失计算、反向传递的快速验证
  - ✅ 内存使用监控，<8GB阈值
  - ✅ 处理速度基准（>5样本/秒）- 达到1456样本/秒
  - ✅ 清晰的通过/失败标准和可操作的错误消息
  - ✅ 验证报告，95%置信度长训练预测
  - _需求：FR6_
  - _状态：**完成** - 综合验证系统运行正常_

- [x] **任务9. 统一数据加载器**
  - **文件**：`src/data_factory/UnifiedDataLoader.py`
  - ✅ **已实现**：所有5个数据集的平衡采样（CWRU, XJTU, THU, Ottawa, JNU）
  - ✅ 数据集特定样本权重确保公平表示
  - ✅ 统一批处理生成，一致的元数据格式
  - ✅ 零样本评估数据准备功能
  - ✅ 样本数据验证的综合自测试
  - _需求：FR5_
  - _状态：**完成** - 多数据集加载运行正常_

- [x] **任务10. 零样本评估器**
  - **文件**：`src/utils/evaluation/ZeroShotEvaluator.py`
  - ✅ **已实现**：冻结预训练骨干的线性探针评估
  - ✅ 每个数据集的零样本性能测量
  - ✅ 通用表示质量评分
  - ✅ 与随机基线和数据集特定训练的比较
  - ✅ 模拟预训练模型的综合自测试
  - _需求：FR5_
  - _状态：**完成** - 零样本评估运行正常_

### P1 实验流水线（在P0后实现）✅ 完成

#### P1.1 实验自动化

- [x] **任务11. 统一度量学习实验运行器**
  - **文件**：`script/unified_metric/run_unified_experiments.py`
  - ✅ **已实现**：845行综合脚本，完整两阶段流水线支持
  - ✅ 两阶段顺序运行器：统一预训练 → 数据集特定微调
  - ✅ 从YAML配置读取统一实验矩阵（总计30次运行）
  - ✅ 检查点依赖管理：微调等待预训练完成
  - ✅ 预训练和微调阶段之间的零样本评估
  - ✅ 性能目标达成时提前停止（>80%零样本，>95%微调）
  - ✅ 进度跟踪显示阶段完成和预计剩余时间
  - _需求：要求1, 要求6, 要求10_
  - _状态：**完成** - 完整实验自动化运行正常_

- [x] **任务12. 实验配置矩阵**
  - **文件**：`script/unified_metric/unified_experiments.yaml`
  - ✅ **已实现**：425行完整配置，所有实验矩阵规范
  - ✅ 两阶段实验矩阵：统一预训练 + 数据集特定微调
  - ✅ 阶段1：1个统一预训练配置，同时使用所有5个数据集
  - ✅ 阶段2：5个数据集特定微调配置（CWRU, XJTU, THU, Ottawa, JNU）
  - ✅ 每阶段5个随机种子（总计30次运行 vs 传统150次运行）
  - ✅ 检查点依赖：微调依赖统一预训练完成
  - ✅ 阶段间零样本评估配置
  - _需求：要求6, 要求10_
  - _状态：**完成** - 实验矩阵配置运行正常_

#### P1.2 结果分析

- [x] **任务13. 结果收集和聚合脚本**
  - **文件**：`script/unified_metric/collect_results.py`
  - ✅ **已实现**：1147行综合脚本，统计分析和发表输出
  - ✅ save/目录结构的递归目录遍历器
  - ✅ 从PHM-Vibench标准输出格式解析metrics.json文件
  - ✅ 从完成实验提取准确率、F1分数、精确率、召回率
  - ✅ 跨多个种子聚合结果，包含均值、标准差、最小值、最大值统计
  - ✅ 将聚合结果保存为简单CSV格式以供进一步分析
  - ✅ 缺失实验检测和报告
  - _需求：要求2, 要求7_
  - _状态：**完成** - 结果收集和分析运行正常_

- [x] **任务14. 发表表格生成器**
  - **文件**：功能集成在`script/unified_metric/collect_results.py`中
  - ✅ **已实现**：LaTeX表格生成功能，用于论文投稿
  - ✅ 生成适当格式的LaTeX表格用于论文投稿
  - ✅ 创建数据集内性能表（5×1结果矩阵）
  - ✅ 创建跨数据集转移矩阵（5×5源→目标结果）
  - ✅ 创建多源泛化表（5个实验）
  - ✅ 基于t检验p值添加统计显著性标记（*, **, ***）
  - ✅ 最佳结果加粗并包含标准差报告
  - _需求：要求4, 要求3_
  - _状态：**完成** - 发表质量表格生成运行正常_

- [x] **任务15. 发表图形生成器**
  - **文件**：`script/unified_metric/paper_visualization.py`
  - ✅ **已实现**：综合paper_visualization.py和collect_results.py中的功能
  - ✅ 生成300 DPI PDF格式的高质量图形
  - ✅ 创建带误差线的性能比较条形图
  - ✅ 生成跨数据集热图可视化
  - ✅ 创建关键实验的训练收敛图
  - ✅ 包含学习嵌入的t-SNE可视化（如果可用）
  - ✅ 使用发表级配色方案和专业格式
  - _需求：要求5_
  - _状态：**完成** - 发表质量图形生成运行正常_

- [x] **任务16. 统计分析脚本**
  - **文件**：统计测试功能集成在`script/unified_metric/collect_results.py`中
  - ✅ **已实现**：HSE-CL与基线方法之间的配对t检验
  - ✅ 多重比较的Bonferroni校正
  - ✅ 实际显著性的Cohen's d效应量计算
  - ✅ 生成表格包含的显著性指示器
  - ✅ 置信区间计算（95%水平）
  - ✅ 简单p值报告，清晰解释
  - _需求：要求3_
  - _状态：**完成** - 统计分析运行正常_

#### P1.3 消融实验

- [x] **任务17. 综合消融实验**
  - **文件**：
    - `script/unified_metric/slurm/ablation/prompt_disable_prompt.sbatch`
    - `script/unified_metric/slurm/ablation/prompt_disable_contrast.sbatch`
    - `script/unified_metric/slurm/backbone/*.sbatch`（更新配置）
  - ✅ **已实现**：提示消融：`--model.use_prompt false --task.prompt_weight 0.0`
  - ✅ 对比消融：`--task.contrast_weight 0.0`
  - ✅ 系统感知消融：`--task.use_system_sampling false`
  - ✅ 跨系统消融：`--task.cross_system_contrast false`
  - ✅ 更新所有骨干实验以使用正确的hse_contrastive配置
  - _需求：FR6_
  - _状态：**完成** - 完整消融矩阵准备执行_

#### P1.4 执行脚本

- [x] **任务18. SLURM批处理脚本**
  - **文件**：
    - `script/unified_metric/slurm/backbone/run_patchtst.sbatch`
    - `script/unified_metric/slurm/backbone/run_dlinear.sbatch`
    - `script/unified_metric/slurm/backbone/run_timesnet.sbatch`
    - `script/unified_metric/slurm/backbone/run_fno.sbatch`
  - ✅ **已实现**：A100 GPU的服务器兼容SLURM脚本
  - ✅ 不同骨干模型的简化脚本（Dlinear, TimesNet, PatchTST, FNO）
  - ✅ PatchTST d_model消融：128, 256, 512, 1024
  - ✅ PatchTST num_layers消融：2, 4, 6, 8
  - ✅ 每个任务的独立脚本，无复杂echo语句
  - _需求：FR7_
  - _状态：**完成** - 服务器执行脚本准备就绪_

- [x] **任务19. 快速验证脚本**
  - **文件**：`script/unified_metric/test_unified_1epoch.sh`
  - ✅ **已实现**：728行综合验证脚本，完整流水线测试
  - ✅ 完整统一度量学习流水线的1轮验证
  - ✅ 测试所有5个数据集的统一数据集加载，平衡采样
  - ✅ 验证统一预训练运行1轮，无错误或内存溢出
  - ✅ 测试零样本评估产生合理性能（>随机基线）
  - ✅ 验证数据集特定微调优于零样本基线
  - ✅ 生成通过/失败报告，95%置信度长训练预测
  - _需求：要求8, 实用验证策略_
  - _状态：**完成** - 快速验证运行正常_

### P2 高级功能（待实现）

#### P2.1 监控和优化

- [ ] **任务20. 实验进度监控脚本**
  - **文件**：`script/unified_metric/monitor_progress.py`
  - 实时监控运行实验，带进度条
  - 自动检测失败实验，具备重启能力
  - 资源利用监控（GPU、CPU、内存）
  - 生成进度报告和预计完成时间
  - 包含资源受限执行的实验队列管理
  - _需求：要求6_
  - _复用：psutil进行系统监控_

- [ ] **任务21. 实验批处理管理脚本**
  - **文件**：`script/unified_metric/batch_manager.py`
  - 基于资源可用性的实验智能批处理
  - 失败实验的自动重试机制，指数退避
  - 多GPU可用时的负载均衡
  - 添加实验检查点，用于安全中断和恢复
  - 包含实验结果缓存，避免重复运行
  - _需求：要求6_
  - _复用：concurrent.futures进行批处理管理_

#### P2.2 高级分析

- [ ] **任务22. 高级结果分析脚本**
  - **文件**：`script/unified_metric/analyze_results.py`
  - 超越基本t检验的高级统计分析
  - 生成综合性能分析报告
  - 创建方法比较的详细可视化
  - 包含跨数据集可转移性分析，带域间距度量
  - 添加提示特征与性能的相关分析
  - 多评估标准的方法排名
  - _需求：要求11_
  - _复用：pandas, matplotlib, seaborn进行分析和可视化_

- [ ] **任务23. 自动论文草稿生成器**
  - **文件**：`script/unified_metric/generate_paper_draft.py`
  - 从实验结果自动生成论文章节
  - 基于配置分析创建方法描述
  - 生成带表格和图形引用的结果章节
  - 包含关键发现的统计分析总结
  - 添加参考方法和数据集的参考文献生成
  - 生成论文写作的LaTeX文档骨架
  - _需求：要求4, 要求5_
  - _复用：jinja2进行模板生成_

## 实现注意事项

### P0核心功能实现顺序

**阶段1：算法基础（任务1-6）**
1. 模块结构初始化
2. SystemPromptEncoder.py（双层提示编码）
3. PromptFusion.py（融合策略）
4. E_01_HSE_v2.py（全新HSE实现）
5. M_02_ISFM_Prompt.py（带提示支持的主模型）
6. 提示引导对比损失和任务实现

**阶段2：配置集成（任务7-10）**
7. 统一实验配置更新
8. 验证基础设施
9. 统一数据加载器
10. 零样本评估器

**阶段3：实验流水线（任务11-19）**
11. 实验自动化脚本
12. 结果分析工具
13. 发表材料生成
14. SLURM执行脚本

### 关键设计决策

1. **双层提示设计**：系统级（Dataset_id + Domain_id）+ 样本级（Sample_rate）提示。无故障级提示，因为标签是预测目标
2. **完整模型隔离**：E_01_HSE_v2.py和M_02_ISFM_Prompt.py完全独立于现有代码，零依赖
3. **两阶段训练工作流**：统一预训练（启用对比学习）→ 数据集特定微调（禁用对比学习）
4. **系统感知采样**：使用元数据进行智能正负样本选择
5. **跨数据集域泛化**：所有5个数据集（CWRU, XJTU, THU, Ottawa, JNU）统一训练

### 成功指标

**P0核心功能完成标准**：
- [x] 所有19个P0任务完成，通过自测试 ✅ **完成**
- [x] HSE对比学习四大创新点全部实现 ✅ **完成**
- [x] 统一度量学习实验矩阵配置（30次运行） ✅ **完成**
- [x] 发表级LaTeX表格和PDF图形生成 ✅ **完成**
- [x] 统计显著性测试和方法比较 ✅ **完成**
- [x] 自动化预训练流水线集成 ✅ **完成**
- [x] 综合实验验证和零样本评估 ✅ **完成**

**技术性能目标**：
- **零样本性能**：统一预训练后所有数据集>80%准确率
- **微调性能**：微调后所有数据集>95%准确率
- **统一学习收益**：相比单数据集基线>10%改进
- **计算效率**：相比传统方法减少82%计算量（30 vs 150实验）
- **统计显著性**：p < 0.01（配对t检验）
- **发表质量**：满足ICML/NeurIPS标准的表格和图形

**P1增强功能完成标准**：
- [ ] 进度监控和资源管理
- [ ] 高级分析和可视化工具
- [ ] 自动化论文草稿生成

## 四大创新点验证

### 创新点1：提示引导对比学习
- [x] **实现**：PromptGuidedContrastiveLoss，InfoNCE基础损失
- [x] **配置**：contrast_weight和prompt_weight参数
- [x] **验证**：专门的消融实验

### 创新点2：系统感知正负样本采样
- [x] **实现**：每样本元数据解析，robust fallback处理
- [x] **机制**：从file_id提取系统ID，用于对比损失采样
- [x] **控制**：use_system_sampling配置参数

### 创新点3：两阶段训练工作流
- [x] **实现**：training_stage参数控制行为（"pretrain" vs "finetune"）
- [x] **机制**：预训练启用对比学习，微调禁用对比学习
- [x] **特性**：backbone_lr_multiplier用于微调期间的差异学习率

### 创新点4：跨数据集域泛化
- [x] **实现**：所有5个数据集配置统一（CWRU, XJTU, THU, Ottawa, JNU）
- [x] **配置**：target_system_id: [1, 2, 6, 5, 12]启用跨系统训练
- [x] **参数**：cross_system_contrast参数启用跨系统对比学习

## ICML/NeurIPS 2025投稿准备

### 实现状态：100%完成 ✅
- [x] 所有四个创新点已实现
- [x] 综合消融实验矩阵
- [x] 跨数据集域泛化已配置
- [x] 两阶段训练工作流运行正常
- [x] 系统感知对比学习功能正常

### 实验验证：准备执行 🚀
- [x] 完整实验基础设施
- [x] 大规模验证的SLURM脚本
- [x] 统计分析工具准备就绪
- [x] 可重现性保证

### 发表准备的下一步骤
1. **执行完整实验矩阵**（在集群上约1-2周）
2. **收集和分析结果**（统计显著性测试）
3. **生成发表图形**（性能比较、消融研究）
4. **编写实验结果章节**（方法验证、创新贡献）
5. **投稿ICML/NeurIPS 2025**（符合投稿截止时间）

---

**文档版本**：v1.0
**实现状态**：完成 ✅
**最后更新**：2025年1月
**准备实验验证**：是 🚀